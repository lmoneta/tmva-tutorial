{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tmva_logo.gif\" height=\"20%\" width=\"20%\">\n",
    "\n",
    "# TMVA Classification Example Using a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Factory\n",
    "\n",
    "Create the Factory class. Later you can choose the methods\n",
    "whose performance you'd like to investigate. \n",
    "\n",
    "The factory is the major TMVA object you have to interact with. Here is the list of parameters you need to pass\n",
    "\n",
    " - The first argument is the base of the name of all the output\n",
    "weightfiles in the directory weight/ that will be created with the \n",
    "method parameters \n",
    "\n",
    " - The second argument is the output file for the training results\n",
    "  \n",
    " - The third argument is a string option defining some general configuration for the TMVA session. For example all TMVA output can be suppressed by removing the \"!\" (not) in front of the \"Silent\" argument in the option string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.19/01\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from ROOT import TMVA\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT.TMVA.Tools.Instance()\n",
    "TMVA.PyMethodBase.PyInitialize()\n",
    "\n",
    "## For PYMVA methods\n",
    "TMVA.PyMethodBase.PyInitialize();\n",
    "\n",
    "\n",
    "outputFile = ROOT.TFile.Open(\"CNN_ClassificationOutput.root\", \"RECREATE\")\n",
    "\n",
    "factory = ROOT.TMVA.Factory(\"TMVA_CNN_Classification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare DataLoader(s)\n",
    "\n",
    "The next step is to declare the DataLoader class that deals with input variables \n",
    "\n",
    "Define the input variables that shall be used for the MVA training\n",
    "note that you may also use variable expressions, which can be parsed by TTree::Draw( \"expression\" )]\n",
    "\n",
    "In this case the input data consists of an image of 16x16 pixels. Each single pixel is a branch in a ROOT TTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "*Tree    :sig_tree  : signal_tree                                            *\n",
      "*Entries :    10000 : Total =         2601382 bytes  File  Size =    2572423 *\n",
      "*        :          : Tree compression factor =   1.00                       *\n",
      "******************************************************************************\n",
      "*Br    0 :var0      : var0/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    1 :var1      : var1/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    2 :var2      : var2/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    3 :var3      : var3/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    4 :var4      : var4/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    5 :var5      : var5/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    6 :var6      : var6/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    7 :var7      : var7/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    8 :var8      : var8/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    9 :var9      : var9/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   10 :var10     : var10/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   11 :var11     : var11/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   12 :var12     : var12/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   13 :var13     : var13/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   14 :var14     : var14/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   15 :var15     : var15/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   16 :var16     : var16/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   17 :var17     : var17/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   18 :var18     : var18/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   19 :var19     : var19/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   20 :var20     : var20/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   21 :var21     : var21/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   22 :var22     : var22/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   23 :var23     : var23/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   24 :var24     : var24/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   25 :var25     : var25/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   26 :var26     : var26/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   27 :var27     : var27/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   28 :var28     : var28/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   29 :var29     : var29/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   30 :var30     : var30/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   31 :var31     : var31/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   32 :var32     : var32/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   33 :var33     : var33/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   34 :var34     : var34/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   35 :var35     : var35/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   36 :var36     : var36/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   37 :var37     : var37/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   38 :var38     : var38/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   39 :var39     : var39/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   40 :var40     : var40/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   41 :var41     : var41/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   42 :var42     : var42/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   43 :var43     : var43/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   44 :var44     : var44/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   45 :var45     : var45/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   46 :var46     : var46/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   47 :var47     : var47/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   48 :var48     : var48/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   49 :var49     : var49/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   50 :var50     : var50/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   51 :var51     : var51/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   52 :var52     : var52/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   53 :var53     : var53/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   54 :var54     : var54/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   55 :var55     : var55/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   56 :var56     : var56/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   57 :var57     : var57/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   58 :var58     : var58/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   59 :var59     : var59/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   60 :var60     : var60/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   61 :var61     : var61/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   62 :var62     : var62/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   63 :var63     : var63/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "inputFileName = \"images_data.root\"\n",
    "\n",
    "inputFile = ROOT.TFile.Open( inputFileName )\n",
    "\n",
    "# retrieve input trees\n",
    "\n",
    "signalTree     = inputFile.Get(\"sig_tree\")\n",
    "backgroundTree = inputFile.Get(\"bkg_tree\")\n",
    "\n",
    "signalTree.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree sig_tree of type Signal with 10000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree bkg_tree of type Background with 10000 events\n"
     ]
    }
   ],
   "source": [
    "loader = ROOT.TMVA.DataLoader(\"dataset\")\n",
    "\n",
    "### global event weights per tree (see below for setting event-wise weights)\n",
    "signalWeight     = 1.0\n",
    "backgroundWeight = 1.0\n",
    "   \n",
    "### You can add an arbitrary number of signal or background trees\n",
    "loader.AddSignalTree    ( signalTree,     signalWeight     )\n",
    "loader.AddBackgroundTree( backgroundTree, backgroundWeight )\n",
    "\n",
    "imgSize = 8 * 8; \n",
    "for  i in range(0,imgSize):\n",
    "    varName = \"var\"+str(i)\n",
    "    loader.AddVariable(varName,'F');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset(s)\n",
    "\n",
    "Define input data file and signal and background trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Apply additional cuts on the signal and background samples (can be different)\n",
    "mycuts = ROOT.TCut(\"\")   ## for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "mycutb = ROOT.TCut(\"\")   ## for example: TCut mycutb = \"abs(var1)<0.5\";\n",
    "\n",
    "\n",
    "loader.PrepareTrainingAndTestTree( mycuts, mycutb,\n",
    "                                  \"nTrain_Signal=5000:nTrain_Background=5000:SplitMode=Random:\"\n",
    "                                   \"NormMode=NumEvents:!V\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Booking Methods\n",
    "\n",
    "Here we book the TMVA methods. We book a DNN and a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Booking Deep Neural Network\n",
    "\n",
    "Here we book the new DNN of TMVA. If using master version you can use the new DL method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ROOT.TMVA::MethodDL object (\"DL_DENSE\") at 0x703f210>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_DENSE\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIER::Architecture=CPU:InputLayout=1|1|64:BatchLayout=1|32|64:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=Optimizer=ADAM,LearningRate=1e-3,Momentum=0.,Regularization=None,WeightDecay=1e-4,DropConfig=0.+0.+0.+0.,MaxEpochs=30,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIER::Architecture=CPU:InputLayout=1|1|64:BatchLayout=1|32|64:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=Optimizer=ADAM,LearningRate=1e-3,Momentum=0.,Regularization=None,WeightDecay=1e-4,DropConfig=0.+0.+0.+0.,MaxEpochs=30,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"G\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|1|64\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"1|32|64\" [The Layout of the batch]\n",
      "                         :     Layout: \"DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIER\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"Optimizer=ADAM,LearningRate=1e-3,Momentum=0.,Regularization=None,WeightDecay=1e-4,DropConfig=0.+0.+0.+0.,MaxEpochs=30,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "DL_DENSE                 : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var0' <---> Output : variable 'var0'\n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "                         : Input : variable 'var5' <---> Output : variable 'var5'\n",
      "                         : Input : variable 'var6' <---> Output : variable 'var6'\n",
      "                         : Input : variable 'var7' <---> Output : variable 'var7'\n",
      "                         : Input : variable 'var8' <---> Output : variable 'var8'\n",
      "                         : Input : variable 'var9' <---> Output : variable 'var9'\n",
      "                         : Input : variable 'var10' <---> Output : variable 'var10'\n",
      "                         : Input : variable 'var11' <---> Output : variable 'var11'\n",
      "                         : Input : variable 'var12' <---> Output : variable 'var12'\n",
      "                         : Input : variable 'var13' <---> Output : variable 'var13'\n",
      "                         : Input : variable 'var14' <---> Output : variable 'var14'\n",
      "                         : Input : variable 'var15' <---> Output : variable 'var15'\n",
      "                         : Input : variable 'var16' <---> Output : variable 'var16'\n",
      "                         : Input : variable 'var17' <---> Output : variable 'var17'\n",
      "                         : Input : variable 'var18' <---> Output : variable 'var18'\n",
      "                         : Input : variable 'var19' <---> Output : variable 'var19'\n",
      "                         : Input : variable 'var20' <---> Output : variable 'var20'\n",
      "                         : Input : variable 'var21' <---> Output : variable 'var21'\n",
      "                         : Input : variable 'var22' <---> Output : variable 'var22'\n",
      "                         : Input : variable 'var23' <---> Output : variable 'var23'\n",
      "                         : Input : variable 'var24' <---> Output : variable 'var24'\n",
      "                         : Input : variable 'var25' <---> Output : variable 'var25'\n",
      "                         : Input : variable 'var26' <---> Output : variable 'var26'\n",
      "                         : Input : variable 'var27' <---> Output : variable 'var27'\n",
      "                         : Input : variable 'var28' <---> Output : variable 'var28'\n",
      "                         : Input : variable 'var29' <---> Output : variable 'var29'\n",
      "                         : Input : variable 'var30' <---> Output : variable 'var30'\n",
      "                         : Input : variable 'var31' <---> Output : variable 'var31'\n",
      "                         : Input : variable 'var32' <---> Output : variable 'var32'\n",
      "                         : Input : variable 'var33' <---> Output : variable 'var33'\n",
      "                         : Input : variable 'var34' <---> Output : variable 'var34'\n",
      "                         : Input : variable 'var35' <---> Output : variable 'var35'\n",
      "                         : Input : variable 'var36' <---> Output : variable 'var36'\n",
      "                         : Input : variable 'var37' <---> Output : variable 'var37'\n",
      "                         : Input : variable 'var38' <---> Output : variable 'var38'\n",
      "                         : Input : variable 'var39' <---> Output : variable 'var39'\n",
      "                         : Input : variable 'var40' <---> Output : variable 'var40'\n",
      "                         : Input : variable 'var41' <---> Output : variable 'var41'\n",
      "                         : Input : variable 'var42' <---> Output : variable 'var42'\n",
      "                         : Input : variable 'var43' <---> Output : variable 'var43'\n",
      "                         : Input : variable 'var44' <---> Output : variable 'var44'\n",
      "                         : Input : variable 'var45' <---> Output : variable 'var45'\n",
      "                         : Input : variable 'var46' <---> Output : variable 'var46'\n",
      "                         : Input : variable 'var47' <---> Output : variable 'var47'\n",
      "                         : Input : variable 'var48' <---> Output : variable 'var48'\n",
      "                         : Input : variable 'var49' <---> Output : variable 'var49'\n",
      "                         : Input : variable 'var50' <---> Output : variable 'var50'\n",
      "                         : Input : variable 'var51' <---> Output : variable 'var51'\n",
      "                         : Input : variable 'var52' <---> Output : variable 'var52'\n",
      "                         : Input : variable 'var53' <---> Output : variable 'var53'\n",
      "                         : Input : variable 'var54' <---> Output : variable 'var54'\n",
      "                         : Input : variable 'var55' <---> Output : variable 'var55'\n",
      "                         : Input : variable 'var56' <---> Output : variable 'var56'\n",
      "                         : Input : variable 'var57' <---> Output : variable 'var57'\n",
      "                         : Input : variable 'var58' <---> Output : variable 'var58'\n",
      "                         : Input : variable 'var59' <---> Output : variable 'var59'\n",
      "                         : Input : variable 'var60' <---> Output : variable 'var60'\n",
      "                         : Input : variable 'var61' <---> Output : variable 'var61'\n",
      "                         : Input : variable 'var62' <---> Output : variable 'var62'\n",
      "                         : Input : variable 'var63' <---> Output : variable 'var63'\n",
      "                         : Will use now the CPU architecture !\n"
     ]
    }
   ],
   "source": [
    "inputLayoutString = \"InputLayout=1|1|64\"; \n",
    "batchLayoutString= \"BatchLayout=1|32|64\";\n",
    "layoutString = (\"Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\")\n",
    "\n",
    "training1  = \"Optimizer=ADAM,LearningRate=1e-3,Momentum=0.,Regularization=None,WeightDecay=1e-4,\"\n",
    "training1 += \"DropConfig=0.+0.+0.+0.,MaxEpochs=30,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1\"\n",
    "trainingStrategyString = \"TrainingStrategy=\" + training1\n",
    "\n",
    "\n",
    "dnnOptions = \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIER::Architecture=CPU\"\n",
    "\n",
    "dnnOptions +=  \":\" + inputLayoutString\n",
    "dnnOptions +=  \":\" + batchLayoutString\n",
    "dnnOptions +=  \":\" + layoutString\n",
    "dnnOptions +=  \":\" + trainingStrategyString\n",
    "\n",
    "#we can now book the method\n",
    "              \n",
    "factory.BookMethod(loader, ROOT.TMVA.Types.kDL, \"DL_DENSE\", dnnOptions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Convolutional Neural Network in TMVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_CNN\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|8|8:BatchLayout=128|1|64:Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|8|8:BatchLayout=128|1|64:Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|8|8\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"128|1|64\" [The Layout of the batch]\n",
      "                         :     Layout: \"CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "                         : Will use now the CPU architecture !\n"
     ]
    }
   ],
   "source": [
    "#input layout \n",
    "inputLayoutString = \"InputLayout=1|8|8\"\n",
    "                                                                                                \n",
    "## Batch Layout                                                                                                                                     \n",
    "batchLayoutString = \"BatchLayout=128|1|64\"\n",
    "                                                   \n",
    "\n",
    "layoutString = (\"Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,\"\n",
    "            \"RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR\")\n",
    "                                                                                                                                              \n",
    "\n",
    "\n",
    "##Training strategies.                                                                                                                          \n",
    "training1 = (\"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"\n",
    "                     \"ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,\"\n",
    "                     \"MaxEpochs=20,WeightDecay=1e-4,Regularization=None,\"\n",
    "                     \"Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0\")\n",
    " \n",
    "trainingStrategyString = \"TrainingStrategy=\" + training1\n",
    "    \n",
    "## General Options.                                                                                                                              \n",
    "cnnOptions = (\"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"\n",
    "                       \"WeightInitialization=XAVIERUNIFORM\");\n",
    "\n",
    "cnnOptions +=  \":\" + inputLayoutString\n",
    "cnnOptions +=  \":\" + batchLayoutString\n",
    "cnnOptions +=  \":\" + layoutString\n",
    "cnnOptions +=  \":\" + trainingStrategyString\n",
    "cnnOptions +=  \":Architecture=CPU\"\n",
    "\n",
    "##book CNN\n",
    "factory.BookMethod(loader, ROOT.TMVA.Types.kDL, \"DL_CNN\", cnnOptions);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Convolutional Neural Network in Keras using a generated model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## to use tensorflow backend\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD\n",
    "#from keras.initializers import TruncatedNormal\n",
    "#from keras import initializations\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape\n",
    "#from keras.callbacks import ReduceLROnPlateau\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 8, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 10)          100       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 10)          910       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                10304     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 11,444\n",
      "Trainable params: 11,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 18:14:10.773613: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-06-17 18:14:10.777020: I tensorflow/stream_executor/platform/default/dso_loader.cc:161] successfully opened CUDA library libcuda.so.1 locally\n",
      "2019-06-17 18:14:10.878266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1010] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-17 18:14:10.878658: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x9c35b10 executing computations on platform CUDA. Devices:\n",
      "2019-06-17 18:14:10.878668: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): GeForce RTX 2070, Compute Capability 7.5\n",
      "2019-06-17 18:14:10.896766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\n",
      "2019-06-17 18:14:10.898553: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x9ce0a10 executing computations on platform Host. Devices:\n",
      "2019-06-17 18:14:10.898582: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-06-17 18:14:10.898875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1434] Found device 0 with properties: \n",
      "name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:02:00.0\n",
      "totalMemory: 7.76GiB freeMemory: 5.25GiB\n",
      "2019-06-17 18:14:10.898899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1513] Adding visible gpu devices: 0\n",
      "2019-06-17 18:14:10.899022: I tensorflow/stream_executor/platform/default/dso_loader.cc:161] successfully opened CUDA library libcudart.so.10.0 locally\n",
      "2019-06-17 18:14:10.900461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-17 18:14:10.900480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:991]      0 \n",
      "2019-06-17 18:14:10.900489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1004] 0:   N \n",
      "2019-06-17 18:14:10.900721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1116] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5078 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:02:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Reshape((8,8, 1), input_shape=(64,)))\n",
    "model.add(Conv2D(10, kernel_size=(3,3), kernel_initializer='TruncatedNormal', activation='relu', padding='same' ) )\n",
    "model.add(Conv2D(10, kernel_size=(3,3), kernel_initializer='TruncatedNormal', activation='relu', padding='same' ) )\n",
    "#stride for maxpool is equal to pool size\n",
    "model.add(MaxPooling2D(pool_size=(2, 2) ))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "model.save('model_cnn.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mPyKeras\u001b[0m\n",
      "                         : \n",
      "                         : Using TensorFlow backend - setting special configuration options \n",
      "                         : Load model from file: model_cnn.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 18:14:11.248633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1513] Adding visible gpu devices: 0\n",
      "2019-06-17 18:14:11.248654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-17 18:14:11.248658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:991]      0 \n",
      "2019-06-17 18:14:11.248661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1004] 0:   N \n",
      "2019-06-17 18:14:11.248747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1116] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5078 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:02:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "factory.BookMethod(loader, ROOT.TMVA.Types.kPyKeras, \n",
    "                       \"PyKeras\",\"H:!V:VarTransform=None:FilenameModel=model_cnn.h5:\"\n",
    "                       \"FilenameTrainedModel=trained_model_cnn.h5:NumEpochs=20:BatchSize=128\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_1_1/convolution}}]]\n\t [[training/Adam/gradients/conv2d_2_1/convolution_grad/ShapeN/_136]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1439\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1440\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    545\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_1_1/convolution}}]]\n\t [[training/Adam/gradients/conv2d_2_1/convolution_grad/ShapeN/_136]]"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "void TMVA::Factory::TrainAllMethods() =>\n    FATAL error (C++ exception of type runtime_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3414a18455aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainAllMethods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: void TMVA::Factory::TrainAllMethods() =>\n    FATAL error (C++ exception of type runtime_error)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 5000\n",
      "                         : Signal     -- testing events             : 5000\n",
      "                         : Signal     -- training and testing events: 10000\n",
      "                         : Background -- training events            : 5000\n",
      "                         : Background -- testing events             : 5000\n",
      "                         : Background -- training and testing events: 10000\n",
      "                         : \n",
      "DataSetInfo              : Correlation matrix (Signal):\n",
      "                         : ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                         :             var0    var1    var2    var3    var4    var5    var6    var7    var8    var9   var10   var11   var12   var13   var14   var15   var16   var17   var18   var19   var20   var21   var22   var23   var24   var25   var26   var27   var28   var29   var30   var31   var32   var33   var34   var35   var36   var37   var38   var39   var40   var41   var42   var43   var44   var45   var46   var47   var48   var49   var50   var51   var52   var53   var54   var55   var56   var57   var58   var59   var60   var61   var62   var63\n",
      "                         :    var0:  +1.000  +0.267  +0.286  +0.206  +0.107  -0.007  -0.057  -0.084  +0.266  +0.319  +0.299  +0.226  +0.087  -0.069  -0.115  -0.107  +0.290  +0.295  +0.305  +0.166  +0.032  -0.081  -0.177  -0.184  +0.274  +0.278  +0.260  +0.139  -0.059  -0.196  -0.236  -0.203  +0.206  +0.216  +0.166  +0.030  -0.163  -0.259  -0.278  -0.225  +0.155  +0.133  +0.072  -0.061  -0.206  -0.282  -0.304  -0.247  +0.090  +0.059  +0.003  -0.121  -0.224  -0.260  -0.253  -0.240  +0.043  +0.026  -0.043  -0.131  -0.213  -0.244  -0.218  -0.192\n",
      "                         :    var1:  +0.267  +1.000  +0.374  +0.294  +0.178  +0.052  -0.040  -0.067  +0.321  +0.384  +0.384  +0.292  +0.175  -0.002  -0.077  -0.132  +0.335  +0.362  +0.364  +0.248  +0.081  -0.093  -0.186  -0.174  +0.279  +0.324  +0.289  +0.186  -0.070  -0.193  -0.244  -0.233  +0.215  +0.218  +0.169  +0.029  -0.151  -0.289  -0.318  -0.271  +0.145  +0.123  +0.034  -0.115  -0.265  -0.350  -0.342  -0.309  +0.078  +0.029  -0.055  -0.179  -0.299  -0.327  -0.335  -0.290  -0.011  -0.009  -0.090  -0.190  -0.276  -0.308  -0.287  -0.238\n",
      "                         :    var2:  +0.286  +0.374  +1.000  +0.346  +0.238  +0.131  +0.038  -0.008  +0.306  +0.389  +0.384  +0.354  +0.231  +0.085  -0.012  -0.083  +0.290  +0.345  +0.377  +0.278  +0.165  -0.009  -0.095  -0.121  +0.244  +0.271  +0.263  +0.186  -0.004  -0.130  -0.182  -0.189  +0.144  +0.168  +0.116  -0.022  -0.184  -0.257  -0.269  -0.246  +0.078  +0.049  -0.033  -0.170  -0.293  -0.334  -0.316  -0.287  -0.006  -0.051  -0.121  -0.230  -0.329  -0.361  -0.329  -0.283  -0.056  -0.068  -0.151  -0.275  -0.308  -0.337  -0.309  -0.221\n",
      "                         :    var3:  +0.206  +0.294  +0.346  +1.000  +0.319  +0.243  +0.162  +0.089  +0.205  +0.308  +0.341  +0.361  +0.313  +0.214  +0.119  +0.061  +0.175  +0.233  +0.268  +0.284  +0.232  +0.140  +0.060  +0.008  +0.110  +0.133  +0.153  +0.137  +0.066  -0.003  -0.044  -0.051  +0.024  +0.018  -0.035  -0.072  -0.137  -0.138  -0.138  -0.136  -0.059  -0.121  -0.163  -0.217  -0.284  -0.264  -0.223  -0.186  -0.120  -0.175  -0.241  -0.331  -0.348  -0.330  -0.283  -0.234  -0.139  -0.198  -0.264  -0.319  -0.334  -0.311  -0.258  -0.188\n",
      "                         :    var4:  +0.107  +0.178  +0.238  +0.319  +1.000  +0.349  +0.292  +0.203  +0.059  +0.132  +0.202  +0.304  +0.361  +0.350  +0.284  +0.203  +0.021  +0.048  +0.128  +0.217  +0.290  +0.285  +0.219  +0.191  -0.059  -0.042  -0.003  +0.060  +0.121  +0.163  +0.152  +0.121  -0.123  -0.168  -0.174  -0.146  -0.089  -0.025  +0.020  +0.019  -0.190  -0.240  -0.273  -0.279  -0.237  -0.135  -0.091  -0.046  -0.233  -0.268  -0.324  -0.367  -0.322  -0.236  -0.140  -0.117  -0.197  -0.282  -0.327  -0.360  -0.316  -0.251  -0.157  -0.111\n",
      "                         :    var5:  -0.007  +0.052  +0.131  +0.243  +0.349  +1.000  +0.350  +0.273  -0.040  -0.012  +0.079  +0.228  +0.352  +0.392  +0.371  +0.296  -0.104  -0.079  +0.008  +0.155  +0.309  +0.362  +0.322  +0.279  -0.177  -0.183  -0.128  -0.020  +0.149  +0.253  +0.261  +0.241  -0.218  -0.273  -0.256  -0.181  -0.002  +0.103  +0.150  +0.161  -0.272  -0.320  -0.311  -0.283  -0.165  -0.036  +0.050  +0.068  -0.257  -0.324  -0.355  -0.338  -0.249  -0.136  -0.035  -0.012  -0.221  -0.305  -0.335  -0.324  -0.246  -0.156  -0.081  -0.050\n",
      "                         :    var6:  -0.057  -0.040  +0.038  +0.162  +0.292  +0.350  +1.000  +0.291  -0.111  -0.094  -0.027  +0.145  +0.305  +0.398  +0.382  +0.345  -0.169  -0.157  -0.083  +0.096  +0.260  +0.357  +0.364  +0.330  -0.236  -0.236  -0.202  -0.071  +0.162  +0.296  +0.310  +0.300  -0.264  -0.295  -0.293  -0.205  -0.004  +0.158  +0.233  +0.229  -0.282  -0.327  -0.337  -0.264  -0.103  +0.038  +0.114  +0.122  -0.282  -0.326  -0.342  -0.305  -0.168  -0.058  +0.056  +0.073  -0.219  -0.280  -0.317  -0.281  -0.195  -0.090  -0.014  +0.007\n",
      "                         :    var7:  -0.084  -0.067  -0.008  +0.089  +0.203  +0.273  +0.291  +1.000  -0.125  -0.134  -0.061  +0.082  +0.208  +0.297  +0.329  +0.265  -0.167  -0.163  -0.109  +0.022  +0.193  +0.303  +0.307  +0.282  -0.210  -0.222  -0.197  -0.094  +0.127  +0.251  +0.282  +0.263  -0.219  -0.278  -0.273  -0.171  +0.026  +0.174  +0.207  +0.221  -0.235  -0.257  -0.276  -0.202  -0.048  +0.055  +0.150  +0.153  -0.210  -0.265  -0.256  -0.222  -0.097  -0.012  +0.076  +0.089  -0.181  -0.200  -0.216  -0.201  -0.115  -0.033  +0.021  +0.053\n",
      "                         :    var8:  +0.266  +0.321  +0.306  +0.205  +0.059  -0.040  -0.111  -0.125  +1.000  +0.373  +0.347  +0.218  +0.045  -0.121  -0.177  -0.172  +0.353  +0.372  +0.336  +0.193  -0.021  -0.180  -0.240  -0.229  +0.316  +0.360  +0.314  +0.167  -0.093  -0.273  -0.287  -0.273  +0.280  +0.295  +0.226  +0.072  -0.204  -0.301  -0.352  -0.290  +0.218  +0.207  +0.135  -0.034  -0.238  -0.318  -0.337  -0.294  +0.174  +0.125  +0.056  -0.081  -0.235  -0.296  -0.313  -0.266  +0.087  +0.063  +0.010  -0.099  -0.207  -0.262  -0.264  -0.196\n",
      "                         :    var9:  +0.319  +0.384  +0.389  +0.308  +0.132  -0.012  -0.094  -0.134  +0.373  +1.000  +0.416  +0.308  +0.106  -0.066  -0.176  -0.185  +0.380  +0.430  +0.417  +0.269  +0.028  -0.159  -0.241  -0.250  +0.360  +0.394  +0.343  +0.219  -0.077  -0.264  -0.318  -0.308  +0.274  +0.314  +0.237  +0.067  -0.207  -0.349  -0.382  -0.333  +0.204  +0.200  +0.109  -0.065  -0.287  -0.380  -0.385  -0.354  +0.124  +0.094  +0.017  -0.145  -0.300  -0.365  -0.381  -0.324  +0.058  +0.040  -0.058  -0.171  -0.292  -0.343  -0.330  -0.269\n",
      "                         :   var10:  +0.299  +0.384  +0.384  +0.341  +0.202  +0.079  -0.027  -0.061  +0.347  +0.416  +1.000  +0.356  +0.193  +0.026  -0.089  -0.126  +0.319  +0.382  +0.395  +0.312  +0.095  -0.078  -0.178  -0.186  +0.283  +0.336  +0.312  +0.220  -0.031  -0.206  -0.261  -0.243  +0.209  +0.228  +0.164  +0.023  -0.189  -0.322  -0.333  -0.297  +0.148  +0.111  +0.015  -0.122  -0.316  -0.382  -0.378  -0.328  +0.064  +0.019  -0.061  -0.208  -0.317  -0.380  -0.375  -0.321  -0.012  -0.037  -0.111  -0.243  -0.322  -0.342  -0.324  -0.278\n",
      "                         :   var11:  +0.226  +0.292  +0.354  +0.361  +0.304  +0.228  +0.145  +0.082  +0.218  +0.308  +0.356  +1.000  +0.314  +0.178  +0.097  +0.010  +0.192  +0.247  +0.301  +0.301  +0.228  +0.090  +0.019  -0.022  +0.126  +0.160  +0.181  +0.157  +0.034  -0.021  -0.081  -0.104  +0.049  +0.045  +0.012  -0.038  -0.138  -0.197  -0.196  -0.172  -0.008  -0.063  -0.124  -0.219  -0.324  -0.273  -0.261  -0.229  -0.090  -0.137  -0.188  -0.303  -0.333  -0.329  -0.298  -0.243  -0.121  -0.155  -0.228  -0.307  -0.344  -0.325  -0.269  -0.212\n",
      "                         :   var12:  +0.087  +0.175  +0.231  +0.313  +0.361  +0.352  +0.305  +0.208  +0.045  +0.106  +0.193  +0.314  +1.000  +0.339  +0.290  +0.196  -0.016  +0.034  +0.123  +0.222  +0.300  +0.279  +0.237  +0.188  -0.064  -0.066  -0.032  +0.063  +0.137  +0.170  +0.142  +0.137  -0.146  -0.179  -0.183  -0.157  -0.059  +0.007  +0.043  +0.036  -0.201  -0.246  -0.289  -0.274  -0.238  -0.131  -0.057  -0.026  -0.245  -0.281  -0.326  -0.368  -0.305  -0.215  -0.125  -0.088  -0.232  -0.301  -0.332  -0.351  -0.302  -0.246  -0.156  -0.106\n",
      "                         :   var13:  -0.069  -0.002  +0.085  +0.214  +0.350  +0.392  +0.398  +0.297  -0.121  -0.066  +0.026  +0.178  +0.339  +1.000  +0.417  +0.351  -0.199  -0.157  -0.068  +0.119  +0.313  +0.404  +0.387  +0.361  -0.256  -0.242  -0.197  -0.044  +0.184  +0.326  +0.343  +0.305  -0.300  -0.345  -0.341  -0.221  +0.010  +0.184  +0.223  +0.222  -0.331  -0.376  -0.380  -0.297  -0.126  +0.053  +0.128  +0.145  -0.339  -0.371  -0.393  -0.344  -0.208  -0.070  +0.034  +0.068  -0.272  -0.336  -0.351  -0.334  -0.217  -0.108  -0.015  -0.007\n",
      "                         :   var14:  -0.115  -0.077  -0.012  +0.119  +0.284  +0.371  +0.382  +0.329  -0.177  -0.176  -0.089  +0.097  +0.290  +0.417  +1.000  +0.352  -0.235  -0.238  -0.154  +0.043  +0.272  +0.401  +0.435  +0.399  -0.298  -0.312  -0.251  -0.117  +0.168  +0.341  +0.396  +0.358  -0.315  -0.380  -0.361  -0.207  +0.044  +0.252  +0.304  +0.287  -0.327  -0.397  -0.359  -0.259  -0.068  +0.117  +0.192  +0.216  -0.312  -0.384  -0.365  -0.312  -0.148  -0.000  +0.118  +0.130  -0.280  -0.314  -0.311  -0.273  -0.151  -0.023  +0.062  +0.052\n",
      "                         :   var15:  -0.107  -0.132  -0.083  +0.061  +0.203  +0.296  +0.345  +0.265  -0.172  -0.185  -0.126  +0.010  +0.196  +0.351  +0.352  +1.000  -0.245  -0.246  -0.197  -0.026  +0.196  +0.339  +0.387  +0.367  -0.274  -0.306  -0.252  -0.152  +0.153  +0.323  +0.375  +0.346  -0.270  -0.345  -0.324  -0.221  +0.070  +0.255  +0.312  +0.299  -0.313  -0.343  -0.320  -0.212  -0.032  +0.151  +0.227  +0.238  -0.267  -0.328  -0.306  -0.231  -0.087  +0.050  +0.155  +0.174  -0.215  -0.265  -0.253  -0.204  -0.097  +0.006  +0.103  +0.094\n",
      "                         :   var16:  +0.290  +0.335  +0.290  +0.175  +0.021  -0.104  -0.169  -0.167  +0.353  +0.380  +0.319  +0.192  -0.016  -0.199  -0.235  -0.245  +1.000  +0.412  +0.367  +0.191  -0.081  -0.266  -0.314  -0.303  +0.385  +0.405  +0.354  +0.180  -0.120  -0.332  -0.372  -0.322  +0.353  +0.372  +0.297  +0.104  -0.174  -0.361  -0.405  -0.350  +0.299  +0.295  +0.201  +0.020  -0.229  -0.354  -0.388  -0.356  +0.224  +0.224  +0.133  -0.022  -0.197  -0.311  -0.351  -0.311  +0.147  +0.148  +0.049  -0.054  -0.187  -0.270  -0.289  -0.233\n",
      "                         :   var17:  +0.295  +0.362  +0.345  +0.233  +0.048  -0.079  -0.157  -0.163  +0.372  +0.430  +0.382  +0.247  +0.034  -0.157  -0.238  -0.246  +0.412  +1.000  +0.407  +0.221  -0.024  -0.252  -0.323  -0.312  +0.402  +0.432  +0.382  +0.228  -0.141  -0.340  -0.400  -0.353  +0.346  +0.396  +0.301  +0.097  -0.218  -0.379  -0.436  -0.399  +0.289  +0.279  +0.185  +0.015  -0.262  -0.386  -0.414  -0.402  +0.218  +0.203  +0.107  -0.061  -0.246  -0.347  -0.403  -0.343  +0.128  +0.110  +0.032  -0.072  -0.232  -0.326  -0.340  -0.297\n",
      "                         :   var18:  +0.305  +0.364  +0.377  +0.268  +0.128  +0.008  -0.083  -0.109  +0.336  +0.417  +0.395  +0.301  +0.123  -0.068  -0.154  -0.197  +0.367  +0.407  +1.000  +0.244  +0.064  -0.153  -0.242  -0.247  +0.365  +0.367  +0.343  +0.222  -0.055  -0.256  -0.312  -0.303  +0.282  +0.305  +0.249  +0.068  -0.199  -0.345  -0.384  -0.342  +0.208  +0.212  +0.119  -0.050  -0.283  -0.400  -0.399  -0.360  +0.117  +0.111  +0.017  -0.146  -0.306  -0.370  -0.370  -0.352  +0.063  +0.044  -0.045  -0.154  -0.289  -0.353  -0.338  -0.257\n",
      "                         :   var19:  +0.166  +0.248  +0.278  +0.284  +0.217  +0.155  +0.096  +0.022  +0.193  +0.269  +0.312  +0.301  +0.222  +0.119  +0.043  -0.026  +0.191  +0.221  +0.244  +1.000  +0.165  +0.049  -0.031  -0.060  +0.143  +0.161  +0.173  +0.157  +0.017  -0.064  -0.107  -0.117  +0.066  +0.069  +0.046  -0.020  -0.124  -0.179  -0.177  -0.179  +0.014  -0.005  -0.054  -0.151  -0.241  -0.268  -0.260  -0.220  -0.034  -0.049  -0.123  -0.216  -0.279  -0.286  -0.266  -0.223  -0.076  -0.115  -0.163  -0.239  -0.295  -0.292  -0.272  -0.196\n",
      "                         :   var20:  +0.032  +0.081  +0.165  +0.232  +0.290  +0.309  +0.260  +0.193  -0.021  +0.028  +0.095  +0.228  +0.300  +0.313  +0.272  +0.196  -0.081  -0.024  +0.064  +0.165  +1.000  +0.286  +0.241  +0.179  -0.134  -0.106  -0.075  +0.034  +0.119  +0.185  +0.167  +0.139  -0.173  -0.202  -0.195  -0.123  -0.042  +0.069  +0.081  +0.091  -0.220  -0.262  -0.255  -0.222  -0.130  -0.058  +0.021  +0.027  -0.239  -0.290  -0.305  -0.299  -0.219  -0.130  -0.066  -0.025  -0.220  -0.262  -0.294  -0.289  -0.232  -0.163  -0.093  -0.066\n",
      "                         :   var21:  -0.081  -0.093  -0.009  +0.140  +0.285  +0.362  +0.357  +0.303  -0.180  -0.159  -0.078  +0.090  +0.279  +0.404  +0.401  +0.339  -0.266  -0.252  -0.153  +0.049  +0.286  +1.000  +0.416  +0.376  -0.312  -0.328  -0.262  -0.106  +0.212  +0.360  +0.383  +0.339  -0.332  -0.387  -0.368  -0.206  +0.051  +0.249  +0.296  +0.295  -0.355  -0.417  -0.371  -0.265  -0.038  +0.122  +0.203  +0.227  -0.332  -0.389  -0.395  -0.284  -0.130  +0.021  +0.128  +0.162  -0.267  -0.355  -0.327  -0.268  -0.151  -0.016  +0.060  +0.070\n",
      "                         :   var22:  -0.177  -0.186  -0.095  +0.060  +0.219  +0.322  +0.364  +0.307  -0.240  -0.241  -0.178  +0.019  +0.237  +0.387  +0.435  +0.387  -0.314  -0.323  -0.242  -0.031  +0.241  +0.416  +1.000  +0.405  -0.363  -0.375  -0.330  -0.153  +0.170  +0.412  +0.451  +0.409  -0.387  -0.446  -0.398  -0.240  +0.102  +0.303  +0.387  +0.371  -0.382  -0.417  -0.392  -0.243  +0.025  +0.216  +0.298  +0.301  -0.358  -0.383  -0.374  -0.258  -0.058  +0.098  +0.211  +0.216  -0.288  -0.319  -0.303  -0.231  -0.078  +0.052  +0.147  +0.147\n",
      "                         :   var23:  -0.184  -0.174  -0.121  +0.008  +0.191  +0.279  +0.330  +0.282  -0.229  -0.250  -0.186  -0.022  +0.188  +0.361  +0.399  +0.367  -0.303  -0.312  -0.247  -0.060  +0.179  +0.376  +0.405  +1.000  -0.360  -0.370  -0.324  -0.135  +0.169  +0.356  +0.430  +0.387  -0.353  -0.402  -0.367  -0.200  +0.097  +0.305  +0.385  +0.360  -0.338  -0.385  -0.360  -0.210  +0.037  +0.225  +0.294  +0.309  -0.307  -0.346  -0.325  -0.222  -0.012  +0.122  +0.226  +0.241  -0.254  -0.292  -0.259  -0.188  -0.048  +0.084  +0.149  +0.151\n",
      "                         :   var24:  +0.274  +0.279  +0.244  +0.110  -0.059  -0.177  -0.236  -0.210  +0.316  +0.360  +0.283  +0.126  -0.064  -0.256  -0.298  -0.274  +0.385  +0.402  +0.365  +0.143  -0.134  -0.312  -0.363  -0.360  +1.000  +0.427  +0.374  +0.178  -0.155  -0.370  -0.419  -0.366  +0.369  +0.420  +0.356  +0.135  -0.191  -0.394  -0.422  -0.377  +0.347  +0.362  +0.263  +0.091  -0.193  -0.347  -0.375  -0.362  +0.271  +0.292  +0.214  +0.036  -0.160  -0.289  -0.338  -0.307  +0.205  +0.218  +0.136  +0.028  -0.123  -0.239  -0.277  -0.234\n",
      "                         :   var25:  +0.278  +0.324  +0.271  +0.133  -0.042  -0.183  -0.236  -0.222  +0.360  +0.394  +0.336  +0.160  -0.066  -0.242  -0.312  -0.306  +0.405  +0.432  +0.367  +0.161  -0.106  -0.328  -0.375  -0.370  +0.427  +1.000  +0.407  +0.207  -0.171  -0.385  -0.440  -0.395  +0.402  +0.433  +0.371  +0.151  -0.196  -0.408  -0.456  -0.420  +0.370  +0.366  +0.285  +0.070  -0.209  -0.379  -0.423  -0.387  +0.301  +0.307  +0.223  +0.045  -0.170  -0.323  -0.384  -0.347  +0.186  +0.212  +0.155  +0.026  -0.163  -0.252  -0.312  -0.275\n",
      "                         :   var26:  +0.260  +0.289  +0.263  +0.153  -0.003  -0.128  -0.202  -0.197  +0.314  +0.343  +0.312  +0.181  -0.032  -0.197  -0.251  -0.252  +0.354  +0.382  +0.343  +0.173  -0.075  -0.262  -0.330  -0.324  +0.374  +0.407  +1.000  +0.201  -0.125  -0.337  -0.374  -0.349  +0.336  +0.371  +0.330  +0.153  -0.188  -0.368  -0.415  -0.369  +0.312  +0.307  +0.241  +0.066  -0.192  -0.364  -0.386  -0.357  +0.218  +0.235  +0.185  +0.006  -0.192  -0.319  -0.364  -0.333  +0.167  +0.179  +0.090  -0.011  -0.166  -0.252  -0.301  -0.281\n",
      "                         :   var27:  +0.139  +0.186  +0.186  +0.137  +0.060  -0.020  -0.071  -0.094  +0.167  +0.219  +0.220  +0.157  +0.063  -0.044  -0.117  -0.152  +0.180  +0.228  +0.222  +0.157  +0.034  -0.106  -0.153  -0.135  +0.178  +0.207  +0.201  +1.000  -0.018  -0.140  -0.205  -0.214  +0.141  +0.153  +0.146  +0.046  -0.115  -0.184  -0.218  -0.212  +0.118  +0.101  +0.059  -0.002  -0.157  -0.202  -0.248  -0.229  +0.059  +0.073  +0.015  -0.078  -0.143  -0.193  -0.226  -0.207  +0.021  +0.035  -0.001  -0.090  -0.141  -0.186  -0.210  -0.161\n",
      "                         :   var28:  -0.059  -0.070  -0.004  +0.066  +0.121  +0.149  +0.162  +0.127  -0.093  -0.077  -0.031  +0.034  +0.137  +0.184  +0.168  +0.153  -0.120  -0.141  -0.055  +0.017  +0.119  +0.212  +0.170  +0.169  -0.155  -0.171  -0.125  -0.018  +1.000  +0.160  +0.182  +0.141  -0.176  -0.198  -0.176  -0.100  +0.042  +0.127  +0.144  +0.139  -0.199  -0.224  -0.180  -0.127  +0.002  +0.082  +0.108  +0.092  -0.172  -0.223  -0.181  -0.136  -0.043  +0.016  +0.074  +0.069  -0.155  -0.184  -0.152  -0.142  -0.069  -0.024  +0.045  +0.037\n",
      "                         :   var29:  -0.196  -0.193  -0.130  -0.003  +0.163  +0.253  +0.296  +0.251  -0.273  -0.264  -0.206  -0.021  +0.170  +0.326  +0.341  +0.323  -0.332  -0.340  -0.256  -0.064  +0.185  +0.360  +0.412  +0.356  -0.370  -0.385  -0.337  -0.140  +0.160  +1.000  +0.411  +0.378  -0.367  -0.426  -0.378  -0.194  +0.137  +0.319  +0.378  +0.348  -0.370  -0.409  -0.359  -0.178  +0.062  +0.254  +0.317  +0.307  -0.337  -0.359  -0.322  -0.177  +0.026  +0.150  +0.265  +0.248  -0.255  -0.280  -0.269  -0.162  -0.013  +0.118  +0.180  +0.168\n",
      "                         :   var30:  -0.236  -0.244  -0.182  -0.044  +0.152  +0.261  +0.310  +0.282  -0.287  -0.318  -0.261  -0.081  +0.142  +0.343  +0.396  +0.375  -0.372  -0.400  -0.312  -0.107  +0.167  +0.383  +0.451  +0.430  -0.419  -0.440  -0.374  -0.205  +0.182  +0.411  +1.000  +0.440  -0.418  -0.466  -0.432  -0.220  +0.142  +0.359  +0.456  +0.436  -0.402  -0.444  -0.372  -0.202  +0.097  +0.307  +0.385  +0.377  -0.351  -0.376  -0.338  -0.194  +0.050  +0.207  +0.310  +0.296  -0.265  -0.306  -0.258  -0.169  +0.004  +0.158  +0.231  +0.227\n",
      "                         :   var31:  -0.203  -0.233  -0.189  -0.051  +0.121  +0.241  +0.300  +0.263  -0.273  -0.308  -0.243  -0.104  +0.137  +0.305  +0.358  +0.346  -0.322  -0.353  -0.303  -0.117  +0.139  +0.339  +0.409  +0.387  -0.366  -0.395  -0.349  -0.214  +0.141  +0.378  +0.440  +1.000  -0.373  -0.418  -0.387  -0.223  +0.106  +0.345  +0.421  +0.399  -0.357  -0.398  -0.347  -0.161  +0.083  +0.292  +0.367  +0.353  -0.323  -0.330  -0.297  -0.160  +0.033  +0.202  +0.306  +0.302  -0.247  -0.273  -0.223  -0.148  +0.037  +0.154  +0.237  +0.213\n",
      "                         :   var32:  +0.206  +0.215  +0.144  +0.024  -0.123  -0.218  -0.264  -0.219  +0.280  +0.274  +0.209  +0.049  -0.146  -0.300  -0.315  -0.270  +0.353  +0.346  +0.282  +0.066  -0.173  -0.332  -0.387  -0.353  +0.369  +0.402  +0.336  +0.141  -0.176  -0.367  -0.418  -0.373  +1.000  +0.421  +0.367  +0.167  -0.179  -0.358  -0.397  -0.373  +0.377  +0.401  +0.334  +0.136  -0.136  -0.303  -0.356  -0.324  +0.330  +0.352  +0.277  +0.128  -0.104  -0.228  -0.310  -0.282  +0.259  +0.280  +0.212  +0.104  -0.058  -0.194  -0.249  -0.223\n",
      "                         :   var33:  +0.216  +0.218  +0.168  +0.018  -0.168  -0.273  -0.295  -0.278  +0.295  +0.314  +0.228  +0.045  -0.179  -0.345  -0.380  -0.345  +0.372  +0.396  +0.305  +0.069  -0.202  -0.387  -0.446  -0.402  +0.420  +0.433  +0.371  +0.153  -0.198  -0.426  -0.466  -0.418  +0.421  +1.000  +0.400  +0.190  -0.151  -0.385  -0.444  -0.431  +0.424  +0.441  +0.380  +0.183  -0.111  -0.336  -0.389  -0.361  +0.365  +0.391  +0.333  +0.177  -0.070  -0.242  -0.330  -0.304  +0.282  +0.310  +0.268  +0.137  -0.042  -0.193  -0.275  -0.238\n",
      "                         :   var34:  +0.166  +0.169  +0.116  -0.035  -0.174  -0.256  -0.293  -0.273  +0.226  +0.237  +0.164  +0.012  -0.183  -0.341  -0.361  -0.324  +0.297  +0.301  +0.249  +0.046  -0.195  -0.368  -0.398  -0.367  +0.356  +0.371  +0.330  +0.146  -0.176  -0.378  -0.432  -0.387  +0.367  +0.400  +1.000  +0.191  -0.117  -0.327  -0.390  -0.360  +0.381  +0.388  +0.364  +0.178  -0.076  -0.274  -0.326  -0.312  +0.311  +0.348  +0.342  +0.184  -0.030  -0.169  -0.278  -0.265  +0.241  +0.302  +0.257  +0.173  -0.007  -0.122  -0.203  -0.208\n",
      "                         :   var35:  +0.030  +0.029  -0.022  -0.072  -0.146  -0.181  -0.205  -0.171  +0.072  +0.067  +0.023  -0.038  -0.157  -0.221  -0.207  -0.221  +0.104  +0.097  +0.068  -0.020  -0.123  -0.206  -0.240  -0.200  +0.135  +0.151  +0.153  +0.046  -0.100  -0.194  -0.220  -0.223  +0.167  +0.190  +0.191  +1.000  -0.018  -0.154  -0.191  -0.191  +0.178  +0.192  +0.212  +0.127  +0.034  -0.089  -0.129  -0.118  +0.165  +0.202  +0.203  +0.153  +0.052  -0.040  -0.108  -0.111  +0.141  +0.174  +0.173  +0.134  +0.075  -0.001  -0.077  -0.074\n",
      "                         :   var36:  -0.163  -0.151  -0.184  -0.137  -0.089  -0.002  -0.004  +0.026  -0.204  -0.207  -0.189  -0.138  -0.059  +0.010  +0.044  +0.070  -0.174  -0.218  -0.199  -0.124  -0.042  +0.051  +0.102  +0.097  -0.191  -0.196  -0.188  -0.115  +0.042  +0.137  +0.142  +0.106  -0.179  -0.151  -0.117  -0.018  +1.000  +0.169  +0.192  +0.160  -0.142  -0.121  -0.083  +0.014  +0.143  +0.190  +0.197  +0.168  -0.100  -0.099  -0.030  +0.060  +0.153  +0.196  +0.204  +0.168  -0.055  -0.072  -0.009  +0.065  +0.136  +0.171  +0.191  +0.116\n",
      "                         :   var37:  -0.259  -0.289  -0.257  -0.138  -0.025  +0.103  +0.158  +0.174  -0.301  -0.349  -0.322  -0.197  +0.007  +0.184  +0.252  +0.255  -0.361  -0.379  -0.345  -0.179  +0.069  +0.249  +0.303  +0.305  -0.394  -0.408  -0.368  -0.184  +0.127  +0.319  +0.359  +0.345  -0.358  -0.385  -0.327  -0.154  +0.169  +1.000  +0.391  +0.363  -0.329  -0.319  -0.255  -0.057  +0.191  +0.349  +0.369  +0.359  -0.245  -0.251  -0.188  -0.015  +0.167  +0.292  +0.346  +0.308  -0.182  -0.203  -0.129  -0.011  +0.153  +0.258  +0.298  +0.236\n",
      "                         :   var38:  -0.278  -0.318  -0.269  -0.138  +0.020  +0.150  +0.233  +0.207  -0.352  -0.382  -0.333  -0.196  +0.043  +0.223  +0.304  +0.312  -0.405  -0.436  -0.384  -0.177  +0.081  +0.296  +0.387  +0.385  -0.422  -0.456  -0.415  -0.218  +0.144  +0.378  +0.456  +0.421  -0.397  -0.444  -0.390  -0.191  +0.192  +0.391  +1.000  +0.443  -0.379  -0.400  -0.321  -0.124  +0.194  +0.379  +0.450  +0.410  -0.300  -0.322  -0.262  -0.073  +0.175  +0.320  +0.406  +0.372  -0.228  -0.242  -0.181  -0.057  +0.138  +0.266  +0.322  +0.278\n",
      "                         :   var39:  -0.225  -0.271  -0.246  -0.136  +0.019  +0.161  +0.229  +0.221  -0.290  -0.333  -0.297  -0.172  +0.036  +0.222  +0.287  +0.299  -0.350  -0.399  -0.342  -0.179  +0.091  +0.295  +0.371  +0.360  -0.377  -0.420  -0.369  -0.212  +0.139  +0.348  +0.436  +0.399  -0.373  -0.431  -0.360  -0.191  +0.160  +0.363  +0.443  +1.000  -0.353  -0.370  -0.316  -0.136  +0.151  +0.332  +0.418  +0.394  -0.275  -0.320  -0.245  -0.093  +0.126  +0.273  +0.364  +0.343  -0.207  -0.240  -0.182  -0.052  +0.114  +0.243  +0.305  +0.260\n",
      "                         :   var40:  +0.155  +0.145  +0.078  -0.059  -0.190  -0.272  -0.282  -0.235  +0.218  +0.204  +0.148  -0.008  -0.201  -0.331  -0.327  -0.313  +0.299  +0.289  +0.208  +0.014  -0.220  -0.355  -0.382  -0.338  +0.347  +0.370  +0.312  +0.118  -0.199  -0.370  -0.402  -0.357  +0.377  +0.424  +0.381  +0.178  -0.142  -0.329  -0.379  -0.353  +1.000  +0.424  +0.361  +0.197  -0.078  -0.248  -0.312  -0.309  +0.369  +0.378  +0.332  +0.191  -0.013  -0.167  -0.270  -0.253  +0.294  +0.331  +0.285  +0.170  +0.004  -0.114  -0.217  -0.187\n",
      "                         :   var41:  +0.133  +0.123  +0.049  -0.121  -0.240  -0.320  -0.327  -0.257  +0.207  +0.200  +0.111  -0.063  -0.246  -0.376  -0.397  -0.343  +0.295  +0.279  +0.212  -0.005  -0.262  -0.417  -0.417  -0.385  +0.362  +0.366  +0.307  +0.101  -0.224  -0.409  -0.444  -0.398  +0.401  +0.441  +0.388  +0.192  -0.121  -0.319  -0.400  -0.370  +0.424  +1.000  +0.422  +0.243  -0.030  -0.248  -0.319  -0.309  +0.383  +0.430  +0.400  +0.272  +0.012  -0.139  -0.261  -0.245  +0.314  +0.371  +0.328  +0.240  +0.060  -0.103  -0.186  -0.159\n",
      "                         :   var42:  +0.072  +0.034  -0.033  -0.163  -0.273  -0.311  -0.337  -0.276  +0.135  +0.109  +0.015  -0.124  -0.289  -0.380  -0.359  -0.320  +0.201  +0.185  +0.119  -0.054  -0.255  -0.371  -0.392  -0.360  +0.263  +0.285  +0.241  +0.059  -0.180  -0.359  -0.372  -0.347  +0.334  +0.380  +0.364  +0.212  -0.083  -0.255  -0.321  -0.316  +0.361  +0.422  +1.000  +0.265  +0.042  -0.146  -0.237  -0.241  +0.367  +0.409  +0.403  +0.289  +0.097  -0.051  -0.164  -0.185  +0.302  +0.359  +0.351  +0.275  +0.121  -0.012  -0.103  -0.126\n",
      "                         :   var43:  -0.061  -0.115  -0.170  -0.217  -0.279  -0.283  -0.264  -0.202  -0.034  -0.065  -0.122  -0.219  -0.274  -0.297  -0.259  -0.212  +0.020  +0.015  -0.050  -0.151  -0.222  -0.265  -0.243  -0.210  +0.091  +0.070  +0.066  -0.002  -0.127  -0.178  -0.202  -0.161  +0.136  +0.183  +0.178  +0.127  +0.014  -0.057  -0.124  -0.136  +0.197  +0.243  +0.265  +1.000  +0.161  +0.034  -0.044  -0.092  +0.201  +0.261  +0.293  +0.284  +0.205  +0.123  +0.017  -0.002  +0.204  +0.245  +0.272  +0.310  +0.212  +0.136  +0.059  +0.032\n",
      "                         :   var44:  -0.206  -0.265  -0.293  -0.284  -0.237  -0.165  -0.103  -0.048  -0.238  -0.287  -0.316  -0.324  -0.238  -0.126  -0.068  -0.032  -0.229  -0.262  -0.283  -0.241  -0.130  -0.038  +0.025  +0.037  -0.193  -0.209  -0.192  -0.157  +0.002  +0.062  +0.097  +0.083  -0.136  -0.111  -0.076  +0.034  +0.143  +0.191  +0.194  +0.151  -0.078  -0.030  +0.042  +0.161  +1.000  +0.278  +0.224  +0.196  -0.029  +0.032  +0.107  +0.223  +0.299  +0.320  +0.275  +0.220  +0.019  +0.071  +0.139  +0.228  +0.294  +0.298  +0.261  +0.194\n",
      "                         :   var45:  -0.282  -0.350  -0.334  -0.264  -0.135  -0.036  +0.038  +0.055  -0.318  -0.380  -0.382  -0.273  -0.131  +0.053  +0.117  +0.151  -0.354  -0.386  -0.400  -0.268  -0.058  +0.122  +0.216  +0.225  -0.347  -0.379  -0.364  -0.202  +0.082  +0.254  +0.307  +0.292  -0.303  -0.336  -0.274  -0.089  +0.190  +0.349  +0.379  +0.332  -0.248  -0.248  -0.146  +0.034  +0.278  +1.000  +0.421  +0.368  -0.174  -0.160  -0.074  +0.083  +0.296  +0.383  +0.413  +0.356  -0.107  -0.085  -0.007  +0.123  +0.261  +0.352  +0.373  +0.291\n",
      "                         :   var46:  -0.304  -0.342  -0.316  -0.223  -0.091  +0.050  +0.114  +0.150  -0.337  -0.385  -0.378  -0.261  -0.057  +0.128  +0.192  +0.227  -0.388  -0.414  -0.399  -0.260  +0.021  +0.203  +0.298  +0.294  -0.375  -0.423  -0.386  -0.248  +0.108  +0.317  +0.385  +0.367  -0.356  -0.389  -0.326  -0.129  +0.197  +0.369  +0.450  +0.418  -0.312  -0.319  -0.237  -0.044  +0.224  +0.421  +1.000  +0.414  -0.235  -0.238  -0.156  +0.044  +0.235  +0.365  +0.425  +0.391  -0.154  -0.162  -0.084  +0.056  +0.239  +0.334  +0.365  +0.312\n",
      "                         :   var47:  -0.247  -0.309  -0.287  -0.186  -0.046  +0.068  +0.122  +0.153  -0.294  -0.354  -0.328  -0.229  -0.026  +0.145  +0.216  +0.238  -0.356  -0.402  -0.360  -0.220  +0.027  +0.227  +0.301  +0.309  -0.362  -0.387  -0.357  -0.229  +0.092  +0.307  +0.377  +0.353  -0.324  -0.361  -0.312  -0.118  +0.168  +0.359  +0.410  +0.394  -0.309  -0.309  -0.241  -0.092  +0.196  +0.368  +0.414  +1.000  -0.246  -0.244  -0.165  -0.013  +0.190  +0.305  +0.395  +0.368  -0.147  -0.172  -0.114  +0.022  +0.175  +0.293  +0.353  +0.294\n",
      "                         :   var48:  +0.090  +0.078  -0.006  -0.120  -0.233  -0.257  -0.282  -0.210  +0.174  +0.124  +0.064  -0.090  -0.245  -0.339  -0.312  -0.267  +0.224  +0.218  +0.117  -0.034  -0.239  -0.332  -0.358  -0.307  +0.271  +0.301  +0.218  +0.059  -0.172  -0.337  -0.351  -0.323  +0.330  +0.365  +0.311  +0.165  -0.100  -0.245  -0.300  -0.275  +0.369  +0.383  +0.367  +0.201  -0.029  -0.174  -0.235  -0.246  +1.000  +0.378  +0.349  +0.246  +0.054  -0.100  -0.170  -0.195  +0.284  +0.332  +0.323  +0.215  +0.076  -0.059  -0.126  -0.124\n",
      "                         :   var49:  +0.059  +0.029  -0.051  -0.175  -0.268  -0.324  -0.326  -0.265  +0.125  +0.094  +0.019  -0.137  -0.281  -0.371  -0.384  -0.328  +0.224  +0.203  +0.111  -0.049  -0.290  -0.389  -0.383  -0.346  +0.292  +0.307  +0.235  +0.073  -0.223  -0.359  -0.376  -0.330  +0.352  +0.391  +0.348  +0.202  -0.099  -0.251  -0.322  -0.320  +0.378  +0.430  +0.409  +0.261  +0.032  -0.160  -0.238  -0.244  +0.378  +1.000  +0.410  +0.285  +0.116  -0.063  -0.177  -0.169  +0.327  +0.364  +0.367  +0.285  +0.119  -0.026  -0.108  -0.112\n",
      "                         :   var50:  +0.003  -0.055  -0.121  -0.241  -0.324  -0.355  -0.342  -0.256  +0.056  +0.017  -0.061  -0.188  -0.326  -0.393  -0.365  -0.306  +0.133  +0.107  +0.017  -0.123  -0.305  -0.395  -0.374  -0.325  +0.214  +0.223  +0.185  +0.015  -0.181  -0.322  -0.338  -0.297  +0.277  +0.333  +0.342  +0.203  -0.030  -0.188  -0.262  -0.245  +0.332  +0.400  +0.403  +0.293  +0.107  -0.074  -0.156  -0.165  +0.349  +0.410  +1.000  +0.348  +0.186  +0.046  -0.086  -0.124  +0.309  +0.374  +0.408  +0.348  +0.227  +0.054  -0.031  -0.057\n",
      "                         :   var51:  -0.121  -0.179  -0.230  -0.331  -0.367  -0.338  -0.305  -0.222  -0.081  -0.145  -0.208  -0.303  -0.368  -0.344  -0.312  -0.231  -0.022  -0.061  -0.146  -0.216  -0.299  -0.284  -0.258  -0.222  +0.036  +0.045  +0.006  -0.078  -0.136  -0.177  -0.194  -0.160  +0.128  +0.177  +0.184  +0.153  +0.060  -0.015  -0.073  -0.093  +0.191  +0.272  +0.289  +0.284  +0.223  +0.083  +0.044  -0.013  +0.246  +0.285  +0.348  +1.000  +0.296  +0.207  +0.104  +0.081  +0.235  +0.299  +0.364  +0.383  +0.327  +0.230  +0.129  +0.069\n",
      "                         :   var52:  -0.224  -0.299  -0.329  -0.348  -0.322  -0.249  -0.168  -0.097  -0.235  -0.300  -0.317  -0.333  -0.305  -0.208  -0.148  -0.087  -0.197  -0.246  -0.306  -0.279  -0.219  -0.130  -0.058  -0.012  -0.160  -0.170  -0.192  -0.143  -0.043  +0.026  +0.050  +0.033  -0.104  -0.070  -0.030  +0.052  +0.153  +0.167  +0.175  +0.126  -0.013  +0.012  +0.097  +0.205  +0.299  +0.296  +0.235  +0.190  +0.054  +0.116  +0.186  +0.296  +1.000  +0.339  +0.285  +0.217  +0.095  +0.143  +0.222  +0.313  +0.359  +0.353  +0.288  +0.229\n",
      "                         :   var53:  -0.260  -0.327  -0.361  -0.330  -0.236  -0.136  -0.058  -0.012  -0.296  -0.365  -0.380  -0.329  -0.215  -0.070  -0.000  +0.050  -0.311  -0.347  -0.370  -0.286  -0.130  +0.021  +0.098  +0.122  -0.289  -0.323  -0.319  -0.193  +0.016  +0.150  +0.207  +0.202  -0.228  -0.242  -0.169  -0.040  +0.196  +0.292  +0.320  +0.273  -0.167  -0.139  -0.051  +0.123  +0.320  +0.383  +0.365  +0.305  -0.100  -0.063  +0.046  +0.207  +0.339  +1.000  +0.407  +0.319  -0.006  -0.001  +0.087  +0.227  +0.333  +0.366  +0.367  +0.287\n",
      "                         :   var54:  -0.253  -0.335  -0.329  -0.283  -0.140  -0.035  +0.056  +0.076  -0.313  -0.381  -0.375  -0.298  -0.125  +0.034  +0.118  +0.155  -0.351  -0.403  -0.370  -0.266  -0.066  +0.128  +0.211  +0.226  -0.338  -0.384  -0.364  -0.226  +0.074  +0.265  +0.310  +0.306  -0.310  -0.330  -0.278  -0.108  +0.204  +0.346  +0.406  +0.364  -0.270  -0.261  -0.164  +0.017  +0.275  +0.413  +0.425  +0.395  -0.170  -0.177  -0.086  +0.104  +0.285  +0.407  +1.000  +0.375  -0.105  -0.096  -0.017  +0.134  +0.273  +0.368  +0.378  +0.323\n",
      "                         :   var55:  -0.240  -0.290  -0.283  -0.234  -0.117  -0.012  +0.073  +0.089  -0.266  -0.324  -0.321  -0.243  -0.088  +0.068  +0.130  +0.174  -0.311  -0.343  -0.352  -0.223  -0.025  +0.162  +0.216  +0.241  -0.307  -0.347  -0.333  -0.207  +0.069  +0.248  +0.296  +0.302  -0.282  -0.304  -0.265  -0.111  +0.168  +0.308  +0.372  +0.343  -0.253  -0.245  -0.185  -0.002  +0.220  +0.356  +0.391  +0.368  -0.195  -0.169  -0.124  +0.081  +0.217  +0.319  +0.375  +1.000  -0.118  -0.122  -0.053  +0.072  +0.210  +0.308  +0.340  +0.283\n",
      "                         :   var56:  +0.043  -0.011  -0.056  -0.139  -0.197  -0.221  -0.219  -0.181  +0.087  +0.058  -0.012  -0.121  -0.232  -0.272  -0.280  -0.215  +0.147  +0.128  +0.063  -0.076  -0.220  -0.267  -0.288  -0.254  +0.205  +0.186  +0.167  +0.021  -0.155  -0.255  -0.265  -0.247  +0.259  +0.282  +0.241  +0.141  -0.055  -0.182  -0.228  -0.207  +0.294  +0.314  +0.302  +0.204  +0.019  -0.107  -0.154  -0.147  +0.284  +0.327  +0.309  +0.235  +0.095  -0.006  -0.105  -0.118  +1.000  +0.290  +0.276  +0.228  +0.111  -0.000  -0.087  -0.060\n",
      "                         :   var57:  +0.026  -0.009  -0.068  -0.198  -0.282  -0.305  -0.280  -0.200  +0.063  +0.040  -0.037  -0.155  -0.301  -0.336  -0.314  -0.265  +0.148  +0.110  +0.044  -0.115  -0.262  -0.355  -0.319  -0.292  +0.218  +0.212  +0.179  +0.035  -0.184  -0.280  -0.306  -0.273  +0.280  +0.310  +0.302  +0.174  -0.072  -0.203  -0.242  -0.240  +0.331  +0.371  +0.359  +0.245  +0.071  -0.085  -0.162  -0.172  +0.332  +0.364  +0.374  +0.299  +0.143  -0.001  -0.096  -0.122  +0.290  +1.000  +0.349  +0.280  +0.176  +0.030  -0.055  -0.069\n",
      "                         :   var58:  -0.043  -0.090  -0.151  -0.264  -0.327  -0.335  -0.317  -0.216  +0.010  -0.058  -0.111  -0.228  -0.332  -0.351  -0.311  -0.253  +0.049  +0.032  -0.045  -0.163  -0.294  -0.327  -0.303  -0.259  +0.136  +0.155  +0.090  -0.001  -0.152  -0.269  -0.258  -0.223  +0.212  +0.268  +0.257  +0.173  -0.009  -0.129  -0.181  -0.182  +0.285  +0.328  +0.351  +0.272  +0.139  -0.007  -0.084  -0.114  +0.323  +0.367  +0.408  +0.364  +0.222  +0.087  -0.017  -0.053  +0.276  +0.349  +1.000  +0.353  +0.241  +0.111  +0.026  -0.010\n",
      "                         :   var59:  -0.131  -0.190  -0.275  -0.319  -0.360  -0.324  -0.281  -0.201  -0.099  -0.171  -0.243  -0.307  -0.351  -0.334  -0.273  -0.204  -0.054  -0.072  -0.154  -0.239  -0.289  -0.268  -0.231  -0.188  +0.028  +0.026  -0.011  -0.090  -0.142  -0.162  -0.169  -0.148  +0.104  +0.137  +0.173  +0.134  +0.065  -0.011  -0.057  -0.052  +0.170  +0.240  +0.275  +0.310  +0.228  +0.123  +0.056  +0.022  +0.215  +0.285  +0.348  +0.383  +0.313  +0.227  +0.134  +0.072  +0.228  +0.280  +0.353  +1.000  +0.337  +0.242  +0.151  +0.082\n",
      "                         :   var60:  -0.213  -0.276  -0.308  -0.334  -0.316  -0.246  -0.195  -0.115  -0.207  -0.292  -0.322  -0.344  -0.302  -0.217  -0.151  -0.097  -0.187  -0.232  -0.289  -0.295  -0.232  -0.151  -0.078  -0.048  -0.123  -0.163  -0.166  -0.141  -0.069  -0.013  +0.004  +0.037  -0.058  -0.042  -0.007  +0.075  +0.136  +0.153  +0.138  +0.114  +0.004  +0.060  +0.121  +0.212  +0.294  +0.261  +0.239  +0.175  +0.076  +0.119  +0.227  +0.327  +0.359  +0.333  +0.273  +0.210  +0.111  +0.176  +0.241  +0.337  +1.000  +0.335  +0.282  +0.179\n",
      "                         :   var61:  -0.244  -0.308  -0.337  -0.311  -0.251  -0.156  -0.090  -0.033  -0.262  -0.343  -0.342  -0.325  -0.246  -0.108  -0.023  +0.006  -0.270  -0.326  -0.353  -0.292  -0.163  -0.016  +0.052  +0.084  -0.239  -0.252  -0.252  -0.186  -0.024  +0.118  +0.158  +0.154  -0.194  -0.193  -0.122  -0.001  +0.171  +0.258  +0.266  +0.243  -0.114  -0.103  -0.012  +0.136  +0.298  +0.352  +0.334  +0.293  -0.059  -0.026  +0.054  +0.230  +0.353  +0.366  +0.368  +0.308  -0.000  +0.030  +0.111  +0.242  +0.335  +1.000  +0.344  +0.274\n",
      "                         :   var62:  -0.218  -0.287  -0.309  -0.258  -0.157  -0.081  -0.014  +0.021  -0.264  -0.330  -0.324  -0.269  -0.156  -0.015  +0.062  +0.103  -0.289  -0.340  -0.338  -0.272  -0.093  +0.060  +0.147  +0.149  -0.277  -0.312  -0.301  -0.210  +0.045  +0.180  +0.231  +0.237  -0.249  -0.275  -0.203  -0.077  +0.191  +0.298  +0.322  +0.305  -0.217  -0.186  -0.103  +0.059  +0.261  +0.373  +0.365  +0.353  -0.126  -0.108  -0.031  +0.129  +0.288  +0.367  +0.378  +0.340  -0.087  -0.055  +0.026  +0.151  +0.282  +0.344  +1.000  +0.282\n",
      "                         :   var63:  -0.192  -0.238  -0.221  -0.188  -0.111  -0.050  +0.007  +0.053  -0.196  -0.269  -0.278  -0.212  -0.106  -0.007  +0.052  +0.094  -0.233  -0.297  -0.257  -0.196  -0.066  +0.070  +0.147  +0.151  -0.234  -0.275  -0.281  -0.161  +0.037  +0.168  +0.227  +0.213  -0.223  -0.238  -0.208  -0.074  +0.116  +0.236  +0.278  +0.260  -0.187  -0.159  -0.126  +0.032  +0.194  +0.291  +0.312  +0.294  -0.124  -0.112  -0.057  +0.069  +0.229  +0.287  +0.323  +0.283  -0.060  -0.069  -0.010  +0.082  +0.179  +0.274  +0.282  +1.000\n",
      "                         : ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "DataSetInfo              : Correlation matrix (Background):\n",
      "                         : ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                         :             var0    var1    var2    var3    var4    var5    var6    var7    var8    var9   var10   var11   var12   var13   var14   var15   var16   var17   var18   var19   var20   var21   var22   var23   var24   var25   var26   var27   var28   var29   var30   var31   var32   var33   var34   var35   var36   var37   var38   var39   var40   var41   var42   var43   var44   var45   var46   var47   var48   var49   var50   var51   var52   var53   var54   var55   var56   var57   var58   var59   var60   var61   var62   var63\n",
      "                         :    var0:  +1.000  +0.285  +0.268  +0.235  +0.144  +0.053  +0.002  -0.033  +0.293  +0.318  +0.303  +0.225  +0.155  +0.040  -0.030  -0.068  +0.280  +0.312  +0.294  +0.231  +0.071  -0.057  -0.117  -0.131  +0.264  +0.254  +0.232  +0.118  +0.010  -0.126  -0.197  -0.192  +0.165  +0.168  +0.107  -0.019  -0.150  -0.236  -0.253  -0.231  +0.104  +0.082  -0.030  -0.098  -0.217  -0.256  -0.262  -0.244  +0.032  -0.019  -0.071  -0.166  -0.233  -0.252  -0.242  -0.231  -0.006  -0.061  -0.139  -0.159  -0.220  -0.233  -0.225  -0.164\n",
      "                         :    var1:  +0.285  +1.000  +0.349  +0.312  +0.241  +0.151  +0.061  +0.005  +0.335  +0.378  +0.371  +0.331  +0.233  +0.109  +0.009  -0.016  +0.298  +0.342  +0.337  +0.287  +0.150  +0.021  -0.047  -0.103  +0.251  +0.277  +0.231  +0.137  -0.001  -0.110  -0.153  -0.183  +0.160  +0.129  +0.087  -0.049  -0.162  -0.236  -0.279  -0.220  +0.053  +0.012  -0.077  -0.188  -0.288  -0.322  -0.338  -0.283  -0.010  -0.076  -0.156  -0.254  -0.314  -0.349  -0.328  -0.271  -0.040  -0.122  -0.180  -0.239  -0.307  -0.317  -0.280  -0.232\n",
      "                         :    var2:  +0.268  +0.349  +1.000  +0.380  +0.326  +0.220  +0.142  +0.068  +0.308  +0.396  +0.398  +0.379  +0.324  +0.207  +0.093  +0.042  +0.268  +0.334  +0.352  +0.303  +0.231  +0.113  +0.030  -0.025  +0.213  +0.222  +0.215  +0.161  +0.076  -0.066  -0.106  -0.120  +0.102  +0.079  +0.012  -0.087  -0.185  -0.253  -0.228  -0.212  -0.000  -0.066  -0.150  -0.251  -0.339  -0.339  -0.329  -0.265  -0.082  -0.144  -0.220  -0.327  -0.375  -0.355  -0.317  -0.274  -0.104  -0.209  -0.251  -0.315  -0.364  -0.331  -0.312  -0.236\n",
      "                         :    var3:  +0.235  +0.312  +0.380  +1.000  +0.353  +0.291  +0.234  +0.181  +0.227  +0.315  +0.359  +0.387  +0.366  +0.277  +0.200  +0.157  +0.189  +0.253  +0.295  +0.314  +0.285  +0.204  +0.144  +0.080  +0.118  +0.115  +0.139  +0.107  +0.090  +0.028  +0.015  -0.018  +0.003  -0.029  -0.079  -0.123  -0.143  -0.160  -0.146  -0.129  -0.094  -0.158  -0.246  -0.293  -0.315  -0.305  -0.245  -0.202  -0.165  -0.224  -0.307  -0.387  -0.401  -0.345  -0.290  -0.230  -0.166  -0.257  -0.315  -0.355  -0.373  -0.322  -0.291  -0.186\n",
      "                         :    var4:  +0.144  +0.241  +0.326  +0.353  +1.000  +0.388  +0.303  +0.229  +0.157  +0.214  +0.310  +0.358  +0.377  +0.366  +0.300  +0.246  +0.075  +0.136  +0.216  +0.282  +0.349  +0.299  +0.252  +0.188  -0.013  +0.020  +0.042  +0.092  +0.140  +0.146  +0.146  +0.104  -0.118  -0.145  -0.155  -0.162  -0.125  -0.087  -0.043  -0.010  -0.196  -0.236  -0.332  -0.331  -0.297  -0.227  -0.175  -0.116  -0.233  -0.279  -0.358  -0.396  -0.370  -0.298  -0.238  -0.179  -0.224  -0.292  -0.341  -0.368  -0.357  -0.308  -0.256  -0.156\n",
      "                         :    var5:  +0.053  +0.151  +0.220  +0.291  +0.388  +1.000  +0.351  +0.270  +0.035  +0.095  +0.194  +0.289  +0.368  +0.407  +0.381  +0.318  -0.041  +0.021  +0.097  +0.225  +0.342  +0.364  +0.329  +0.285  -0.113  -0.100  -0.070  +0.032  +0.156  +0.232  +0.226  +0.204  -0.218  -0.226  -0.248  -0.165  -0.083  +0.024  +0.075  +0.086  -0.271  -0.313  -0.343  -0.337  -0.233  -0.146  -0.081  -0.009  -0.269  -0.335  -0.374  -0.380  -0.295  -0.223  -0.142  -0.080  -0.221  -0.294  -0.341  -0.338  -0.307  -0.243  -0.169  -0.106\n",
      "                         :    var6:  +0.002  +0.061  +0.142  +0.234  +0.303  +0.351  +1.000  +0.279  -0.015  +0.031  +0.112  +0.210  +0.325  +0.394  +0.353  +0.328  -0.108  -0.047  +0.017  +0.152  +0.280  +0.361  +0.327  +0.311  -0.171  -0.156  -0.090  +0.002  +0.154  +0.234  +0.247  +0.232  -0.235  -0.265  -0.241  -0.167  -0.053  +0.064  +0.120  +0.136  -0.264  -0.316  -0.329  -0.302  -0.176  -0.083  -0.006  +0.041  -0.253  -0.304  -0.323  -0.294  -0.242  -0.141  -0.075  -0.023  -0.205  -0.265  -0.280  -0.280  -0.250  -0.187  -0.100  -0.068\n",
      "                         :    var7:  -0.033  +0.005  +0.068  +0.181  +0.229  +0.270  +0.279  +1.000  -0.077  -0.023  +0.029  +0.145  +0.244  +0.295  +0.298  +0.292  -0.106  -0.072  -0.009  +0.088  +0.223  +0.295  +0.308  +0.269  -0.164  -0.176  -0.111  -0.031  +0.122  +0.229  +0.263  +0.242  -0.222  -0.255  -0.237  -0.140  -0.034  +0.092  +0.155  +0.172  -0.243  -0.258  -0.274  -0.228  -0.131  -0.004  +0.065  +0.099  -0.231  -0.260  -0.277  -0.253  -0.175  -0.090  -0.015  +0.012  -0.201  -0.210  -0.229  -0.214  -0.171  -0.107  -0.048  +0.002\n",
      "                         :    var8:  +0.293  +0.335  +0.308  +0.227  +0.157  +0.035  -0.015  -0.077  +1.000  +0.366  +0.358  +0.274  +0.148  +0.020  -0.084  -0.102  +0.339  +0.368  +0.359  +0.242  +0.075  -0.084  -0.155  -0.181  +0.331  +0.339  +0.259  +0.170  -0.023  -0.170  -0.239  -0.243  +0.252  +0.211  +0.147  -0.007  -0.166  -0.292  -0.313  -0.280  +0.167  +0.121  +0.019  -0.099  -0.252  -0.343  -0.351  -0.307  +0.067  +0.002  -0.069  -0.176  -0.269  -0.330  -0.315  -0.273  +0.022  -0.046  -0.100  -0.181  -0.259  -0.280  -0.288  -0.240\n",
      "                         :    var9:  +0.318  +0.378  +0.396  +0.315  +0.214  +0.095  +0.031  -0.023  +0.366  +1.000  +0.422  +0.355  +0.214  +0.079  -0.045  -0.078  +0.373  +0.416  +0.402  +0.319  +0.123  -0.033  -0.111  -0.156  +0.344  +0.346  +0.316  +0.176  -0.002  -0.165  -0.228  -0.257  +0.238  +0.208  +0.129  -0.030  -0.213  -0.322  -0.343  -0.313  +0.122  +0.057  -0.018  -0.157  -0.309  -0.382  -0.385  -0.350  +0.036  -0.026  -0.111  -0.237  -0.331  -0.383  -0.376  -0.313  +0.007  -0.092  -0.158  -0.243  -0.309  -0.337  -0.332  -0.258\n",
      "                         :   var10:  +0.303  +0.371  +0.398  +0.359  +0.310  +0.194  +0.112  +0.029  +0.358  +0.422  +1.000  +0.405  +0.281  +0.183  +0.051  -0.017  +0.312  +0.381  +0.396  +0.340  +0.211  +0.056  -0.021  -0.079  +0.256  +0.294  +0.261  +0.178  +0.034  -0.091  -0.174  -0.181  +0.157  +0.132  +0.070  -0.056  -0.185  -0.291  -0.298  -0.278  +0.041  -0.002  -0.120  -0.224  -0.338  -0.395  -0.379  -0.297  -0.036  -0.104  -0.191  -0.314  -0.380  -0.400  -0.370  -0.330  -0.068  -0.165  -0.234  -0.307  -0.365  -0.386  -0.344  -0.264\n",
      "                         :   var11:  +0.225  +0.331  +0.379  +0.387  +0.358  +0.289  +0.210  +0.145  +0.274  +0.355  +0.405  +1.000  +0.369  +0.283  +0.181  +0.127  +0.207  +0.277  +0.328  +0.330  +0.291  +0.196  +0.121  +0.064  +0.143  +0.158  +0.161  +0.141  +0.080  +0.033  +0.013  -0.042  +0.028  -0.002  -0.058  -0.100  -0.169  -0.190  -0.173  -0.153  -0.112  -0.143  -0.228  -0.291  -0.354  -0.329  -0.293  -0.231  -0.144  -0.232  -0.289  -0.370  -0.397  -0.372  -0.313  -0.264  -0.150  -0.264  -0.306  -0.368  -0.396  -0.354  -0.316  -0.225\n",
      "                         :   var12:  +0.155  +0.233  +0.324  +0.366  +0.377  +0.368  +0.325  +0.244  +0.148  +0.214  +0.281  +0.369  +1.000  +0.372  +0.315  +0.257  +0.070  +0.135  +0.226  +0.274  +0.335  +0.317  +0.261  +0.213  -0.017  +0.006  +0.042  +0.078  +0.170  +0.161  +0.150  +0.112  -0.147  -0.162  -0.186  -0.170  -0.125  -0.080  -0.023  -0.004  -0.218  -0.249  -0.320  -0.344  -0.303  -0.231  -0.166  -0.119  -0.257  -0.299  -0.374  -0.398  -0.378  -0.307  -0.226  -0.172  -0.246  -0.298  -0.367  -0.379  -0.381  -0.310  -0.250  -0.152\n",
      "                         :   var13:  +0.040  +0.109  +0.207  +0.277  +0.366  +0.407  +0.394  +0.295  +0.020  +0.079  +0.183  +0.283  +0.372  +1.000  +0.420  +0.362  -0.082  -0.017  +0.080  +0.210  +0.357  +0.404  +0.386  +0.339  -0.163  -0.140  -0.105  +0.026  +0.177  +0.279  +0.290  +0.261  -0.268  -0.285  -0.307  -0.193  -0.043  +0.058  +0.114  +0.152  -0.322  -0.356  -0.395  -0.353  -0.247  -0.104  -0.035  +0.021  -0.322  -0.379  -0.411  -0.395  -0.328  -0.202  -0.121  -0.058  -0.275  -0.347  -0.377  -0.354  -0.318  -0.227  -0.150  -0.090\n",
      "                         :   var14:  -0.030  +0.009  +0.093  +0.200  +0.300  +0.381  +0.353  +0.298  -0.084  -0.045  +0.051  +0.181  +0.315  +0.420  +1.000  +0.370  -0.152  -0.114  -0.041  +0.129  +0.320  +0.389  +0.405  +0.367  -0.237  -0.213  -0.186  -0.036  +0.178  +0.306  +0.350  +0.323  -0.324  -0.325  -0.328  -0.190  -0.020  +0.155  +0.223  +0.227  -0.337  -0.376  -0.364  -0.307  -0.165  -0.004  +0.087  +0.120  -0.306  -0.364  -0.379  -0.312  -0.212  -0.089  -0.013  +0.030  -0.255  -0.296  -0.340  -0.294  -0.230  -0.134  -0.057  -0.005\n",
      "                         :   var15:  -0.068  -0.016  +0.042  +0.157  +0.246  +0.318  +0.328  +0.292  -0.102  -0.078  -0.017  +0.127  +0.257  +0.362  +0.370  +1.000  -0.177  -0.153  -0.098  +0.082  +0.256  +0.363  +0.383  +0.364  -0.253  -0.251  -0.196  -0.031  +0.149  +0.281  +0.347  +0.319  -0.279  -0.319  -0.285  -0.167  -0.006  +0.148  +0.215  +0.247  -0.306  -0.347  -0.326  -0.263  -0.099  +0.042  +0.107  +0.170  -0.281  -0.315  -0.317  -0.260  -0.178  -0.058  +0.009  +0.068  -0.200  -0.261  -0.271  -0.248  -0.175  -0.082  -0.027  +0.004\n",
      "                         :   var16:  +0.280  +0.298  +0.268  +0.189  +0.075  -0.041  -0.108  -0.106  +0.339  +0.373  +0.312  +0.207  +0.070  -0.082  -0.152  -0.177  +1.000  +0.403  +0.346  +0.210  -0.004  -0.154  -0.242  -0.270  +0.390  +0.377  +0.309  +0.149  -0.090  -0.236  -0.302  -0.310  +0.341  +0.319  +0.227  +0.042  -0.170  -0.324  -0.380  -0.339  +0.246  +0.211  +0.117  -0.055  -0.228  -0.337  -0.377  -0.351  +0.157  +0.124  +0.034  -0.102  -0.231  -0.303  -0.331  -0.295  +0.090  +0.030  -0.031  -0.112  -0.204  -0.249  -0.293  -0.219\n",
      "                         :   var17:  +0.312  +0.342  +0.334  +0.253  +0.136  +0.021  -0.047  -0.072  +0.368  +0.416  +0.381  +0.277  +0.135  -0.017  -0.114  -0.153  +0.403  +1.000  +0.394  +0.262  +0.044  -0.129  -0.216  -0.255  +0.379  +0.392  +0.341  +0.159  -0.048  -0.245  -0.314  -0.313  +0.308  +0.292  +0.214  +0.047  -0.182  -0.360  -0.386  -0.359  +0.215  +0.189  +0.051  -0.100  -0.249  -0.387  -0.403  -0.380  +0.114  +0.066  -0.023  -0.169  -0.279  -0.366  -0.363  -0.324  +0.060  -0.006  -0.075  -0.163  -0.269  -0.298  -0.335  -0.263\n",
      "                         :   var18:  +0.294  +0.337  +0.352  +0.295  +0.216  +0.097  +0.017  -0.009  +0.359  +0.402  +0.396  +0.328  +0.226  +0.080  -0.041  -0.098  +0.346  +0.394  +1.000  +0.302  +0.131  -0.037  -0.130  -0.164  +0.311  +0.342  +0.305  +0.147  -0.008  -0.178  -0.253  -0.243  +0.229  +0.211  +0.153  -0.027  -0.177  -0.321  -0.345  -0.319  +0.125  +0.096  -0.011  -0.143  -0.291  -0.365  -0.388  -0.340  +0.030  -0.007  -0.101  -0.227  -0.313  -0.368  -0.353  -0.320  -0.009  -0.092  -0.139  -0.232  -0.314  -0.340  -0.324  -0.274\n",
      "                         :   var19:  +0.231  +0.287  +0.303  +0.314  +0.282  +0.225  +0.152  +0.088  +0.242  +0.319  +0.340  +0.330  +0.274  +0.210  +0.129  +0.082  +0.210  +0.262  +0.302  +1.000  +0.235  +0.141  +0.058  +0.011  +0.147  +0.179  +0.182  +0.138  +0.069  -0.021  -0.045  -0.094  +0.067  +0.042  -0.014  -0.071  -0.155  -0.192  -0.194  -0.174  -0.030  -0.074  -0.167  -0.218  -0.287  -0.311  -0.296  -0.231  -0.086  -0.166  -0.219  -0.289  -0.342  -0.358  -0.307  -0.249  -0.121  -0.203  -0.263  -0.292  -0.341  -0.332  -0.299  -0.218\n",
      "                         :   var20:  +0.071  +0.150  +0.231  +0.285  +0.349  +0.342  +0.280  +0.223  +0.075  +0.123  +0.211  +0.291  +0.335  +0.357  +0.320  +0.256  -0.004  +0.044  +0.131  +0.235  +1.000  +0.312  +0.279  +0.234  -0.078  -0.069  -0.003  +0.072  +0.150  +0.185  +0.177  +0.142  -0.179  -0.193  -0.206  -0.151  -0.080  +0.009  +0.024  +0.049  -0.253  -0.265  -0.309  -0.299  -0.238  -0.152  -0.103  -0.048  -0.235  -0.317  -0.346  -0.344  -0.309  -0.225  -0.168  -0.088  -0.229  -0.305  -0.325  -0.334  -0.321  -0.249  -0.182  -0.115\n",
      "                         :   var21:  -0.057  +0.021  +0.113  +0.204  +0.299  +0.364  +0.361  +0.295  -0.084  -0.033  +0.056  +0.196  +0.317  +0.404  +0.389  +0.363  -0.154  -0.129  -0.037  +0.141  +0.312  +1.000  +0.394  +0.364  -0.253  -0.248  -0.173  -0.016  +0.165  +0.312  +0.342  +0.299  -0.316  -0.324  -0.333  -0.182  -0.026  +0.143  +0.218  +0.213  -0.346  -0.375  -0.377  -0.316  -0.145  -0.004  +0.073  +0.125  -0.320  -0.352  -0.381  -0.322  -0.230  -0.090  -0.012  +0.046  -0.275  -0.322  -0.340  -0.292  -0.234  -0.143  -0.055  -0.005\n",
      "                         :   var22:  -0.117  -0.047  +0.030  +0.144  +0.252  +0.329  +0.327  +0.308  -0.155  -0.111  -0.021  +0.121  +0.261  +0.386  +0.405  +0.383  -0.242  -0.216  -0.130  +0.058  +0.279  +0.394  +1.000  +0.395  -0.312  -0.294  -0.243  -0.075  +0.173  +0.339  +0.401  +0.366  -0.368  -0.381  -0.358  -0.189  +0.003  +0.225  +0.303  +0.302  -0.396  -0.402  -0.393  -0.282  -0.083  +0.075  +0.188  +0.216  -0.348  -0.381  -0.349  -0.278  -0.137  -0.034  +0.066  +0.117  -0.266  -0.306  -0.300  -0.252  -0.163  -0.072  +0.027  +0.058\n",
      "                         :   var23:  -0.131  -0.103  -0.025  +0.080  +0.188  +0.285  +0.311  +0.269  -0.181  -0.156  -0.079  +0.064  +0.213  +0.339  +0.367  +0.364  -0.270  -0.255  -0.164  +0.011  +0.234  +0.364  +0.395  +1.000  -0.317  -0.336  -0.245  -0.083  +0.160  +0.325  +0.388  +0.367  -0.386  -0.386  -0.344  -0.171  +0.047  +0.231  +0.316  +0.335  -0.359  -0.378  -0.331  -0.251  -0.041  +0.116  +0.218  +0.245  -0.315  -0.330  -0.302  -0.225  -0.094  +0.045  +0.099  +0.149  -0.223  -0.251  -0.258  -0.190  -0.107  -0.015  +0.075  +0.105\n",
      "                         :   var24:  +0.264  +0.251  +0.213  +0.118  -0.013  -0.113  -0.171  -0.164  +0.331  +0.344  +0.256  +0.143  -0.017  -0.163  -0.237  -0.253  +0.390  +0.379  +0.311  +0.147  -0.078  -0.253  -0.312  -0.317  +1.000  +0.417  +0.326  +0.143  -0.125  -0.306  -0.387  -0.364  +0.383  +0.379  +0.303  +0.088  -0.146  -0.327  -0.401  -0.384  +0.324  +0.307  +0.187  +0.035  -0.163  -0.320  -0.360  -0.355  +0.225  +0.235  +0.145  -0.002  -0.149  -0.276  -0.319  -0.299  +0.143  +0.126  +0.069  -0.017  -0.132  -0.226  -0.257  -0.213\n",
      "                         :   var25:  +0.254  +0.277  +0.222  +0.115  +0.020  -0.100  -0.156  -0.176  +0.339  +0.346  +0.294  +0.158  +0.006  -0.140  -0.213  -0.251  +0.377  +0.392  +0.342  +0.179  -0.069  -0.248  -0.294  -0.336  +0.417  +1.000  +0.343  +0.153  -0.109  -0.301  -0.396  -0.362  +0.381  +0.387  +0.307  +0.083  -0.157  -0.365  -0.411  -0.409  +0.337  +0.306  +0.196  +0.035  -0.187  -0.343  -0.407  -0.389  +0.226  +0.209  +0.115  -0.021  -0.191  -0.295  -0.329  -0.330  +0.149  +0.111  +0.053  -0.047  -0.177  -0.249  -0.278  -0.261\n",
      "                         :   var26:  +0.232  +0.231  +0.215  +0.139  +0.042  -0.070  -0.090  -0.111  +0.259  +0.316  +0.261  +0.161  +0.042  -0.105  -0.186  -0.196  +0.309  +0.341  +0.305  +0.182  -0.003  -0.173  -0.243  -0.245  +0.326  +0.343  +1.000  +0.133  -0.084  -0.236  -0.321  -0.291  +0.309  +0.282  +0.258  +0.059  -0.143  -0.309  -0.351  -0.340  +0.250  +0.226  +0.116  -0.001  -0.193  -0.302  -0.345  -0.349  +0.178  +0.126  +0.053  -0.056  -0.181  -0.278  -0.310  -0.295  +0.112  +0.051  +0.004  -0.075  -0.162  -0.233  -0.272  -0.223\n",
      "                         :   var27:  +0.118  +0.137  +0.161  +0.107  +0.092  +0.032  +0.002  -0.031  +0.170  +0.176  +0.178  +0.141  +0.078  +0.026  -0.036  -0.031  +0.149  +0.159  +0.147  +0.138  +0.072  -0.016  -0.075  -0.083  +0.143  +0.153  +0.133  +1.000  +0.021  -0.076  -0.124  -0.128  +0.071  +0.088  +0.058  +0.014  -0.097  -0.146  -0.143  -0.152  +0.048  +0.036  +0.007  -0.070  -0.142  -0.167  -0.190  -0.191  +0.001  +0.010  -0.053  -0.095  -0.173  -0.179  -0.206  -0.173  -0.034  -0.066  -0.094  -0.117  -0.156  -0.180  -0.185  -0.139\n",
      "                         :   var28:  +0.010  -0.001  +0.076  +0.090  +0.140  +0.156  +0.154  +0.122  -0.023  -0.002  +0.034  +0.080  +0.170  +0.177  +0.178  +0.149  -0.090  -0.048  -0.008  +0.069  +0.150  +0.165  +0.173  +0.160  -0.125  -0.109  -0.084  +0.021  +1.000  +0.144  +0.169  +0.122  -0.173  -0.177  -0.158  -0.083  +0.017  +0.063  +0.109  +0.100  -0.177  -0.215  -0.186  -0.139  -0.074  -0.004  +0.044  +0.044  -0.210  -0.179  -0.206  -0.149  -0.104  -0.054  -0.004  -0.004  -0.140  -0.168  -0.184  -0.178  -0.107  -0.084  -0.042  +0.001\n",
      "                         :   var29:  -0.126  -0.110  -0.066  +0.028  +0.146  +0.232  +0.234  +0.229  -0.170  -0.165  -0.091  +0.033  +0.161  +0.279  +0.306  +0.281  -0.236  -0.245  -0.178  -0.021  +0.185  +0.312  +0.339  +0.325  -0.306  -0.301  -0.236  -0.076  +0.144  +1.000  +0.343  +0.320  -0.332  -0.341  -0.321  -0.143  +0.066  +0.242  +0.287  +0.294  -0.329  -0.341  -0.297  -0.184  +0.002  +0.140  +0.191  +0.211  -0.272  -0.295  -0.290  -0.187  -0.031  +0.064  +0.134  +0.159  -0.201  -0.245  -0.219  -0.157  -0.063  +0.021  +0.085  +0.098\n",
      "                         :   var30:  -0.197  -0.153  -0.106  +0.015  +0.146  +0.226  +0.247  +0.263  -0.239  -0.228  -0.174  +0.013  +0.150  +0.290  +0.350  +0.347  -0.302  -0.314  -0.253  -0.045  +0.177  +0.342  +0.401  +0.388  -0.387  -0.396  -0.321  -0.124  +0.169  +0.343  +1.000  +0.425  -0.403  -0.407  -0.355  -0.169  +0.084  +0.308  +0.372  +0.364  -0.404  -0.390  -0.335  -0.206  +0.031  +0.221  +0.297  +0.310  -0.329  -0.322  -0.289  -0.186  -0.025  +0.121  +0.206  +0.222  -0.246  -0.257  -0.233  -0.145  -0.036  +0.065  +0.148  +0.149\n",
      "                         :   var31:  -0.192  -0.183  -0.120  -0.018  +0.104  +0.204  +0.232  +0.242  -0.243  -0.257  -0.181  -0.042  +0.112  +0.261  +0.323  +0.319  -0.310  -0.313  -0.243  -0.094  +0.142  +0.299  +0.366  +0.367  -0.364  -0.362  -0.291  -0.128  +0.122  +0.320  +0.425  +1.000  -0.385  -0.379  -0.334  -0.155  +0.082  +0.298  +0.374  +0.386  -0.344  -0.339  -0.309  -0.184  +0.043  +0.226  +0.297  +0.311  -0.279  -0.288  -0.269  -0.122  +0.017  +0.143  +0.209  +0.223  -0.206  -0.221  -0.184  -0.110  -0.004  +0.084  +0.153  +0.156\n",
      "                         :   var32:  +0.165  +0.160  +0.102  +0.003  -0.118  -0.218  -0.235  -0.222  +0.252  +0.238  +0.157  +0.028  -0.147  -0.268  -0.324  -0.279  +0.341  +0.308  +0.229  +0.067  -0.179  -0.316  -0.368  -0.386  +0.383  +0.381  +0.309  +0.071  -0.173  -0.332  -0.403  -0.385  +1.000  +0.396  +0.349  +0.139  -0.110  -0.325  -0.371  -0.380  +0.387  +0.383  +0.310  +0.142  -0.087  -0.258  -0.325  -0.329  +0.327  +0.320  +0.269  +0.130  -0.052  -0.186  -0.248  -0.273  +0.246  +0.243  +0.202  +0.078  -0.009  -0.123  -0.184  -0.194\n",
      "                         :   var33:  +0.168  +0.129  +0.079  -0.029  -0.145  -0.226  -0.265  -0.255  +0.211  +0.208  +0.132  -0.002  -0.162  -0.285  -0.325  -0.319  +0.319  +0.292  +0.211  +0.042  -0.193  -0.324  -0.381  -0.386  +0.379  +0.387  +0.282  +0.088  -0.177  -0.341  -0.407  -0.379  +0.396  +1.000  +0.364  +0.151  -0.094  -0.301  -0.377  -0.365  +0.401  +0.375  +0.323  +0.191  -0.083  -0.243  -0.311  -0.297  +0.324  +0.316  +0.279  +0.157  -0.017  -0.167  -0.222  -0.249  +0.243  +0.252  +0.214  +0.123  -0.003  -0.104  -0.179  -0.174\n",
      "                         :   var34:  +0.107  +0.087  +0.012  -0.079  -0.155  -0.248  -0.241  -0.237  +0.147  +0.129  +0.070  -0.058  -0.186  -0.307  -0.328  -0.285  +0.227  +0.214  +0.153  -0.014  -0.206  -0.333  -0.358  -0.344  +0.303  +0.307  +0.258  +0.058  -0.158  -0.321  -0.355  -0.334  +0.349  +0.364  +1.000  +0.155  -0.091  -0.255  -0.311  -0.318  +0.351  +0.357  +0.332  +0.195  -0.004  -0.174  -0.240  -0.247  +0.302  +0.308  +0.287  +0.173  +0.045  -0.106  -0.167  -0.203  +0.254  +0.244  +0.237  +0.137  +0.062  -0.050  -0.129  -0.119\n",
      "                         :   var35:  -0.019  -0.049  -0.087  -0.123  -0.162  -0.165  -0.167  -0.140  -0.007  -0.030  -0.056  -0.100  -0.170  -0.193  -0.190  -0.167  +0.042  +0.047  -0.027  -0.071  -0.151  -0.182  -0.189  -0.171  +0.088  +0.083  +0.059  +0.014  -0.083  -0.143  -0.169  -0.155  +0.139  +0.151  +0.155  +1.000  +0.008  -0.063  -0.100  -0.137  +0.155  +0.155  +0.170  +0.145  +0.079  +0.002  -0.029  -0.081  +0.161  +0.164  +0.175  +0.152  +0.086  +0.044  -0.024  -0.023  +0.105  +0.150  +0.134  +0.137  +0.091  +0.057  +0.030  -0.001\n",
      "                         :   var36:  -0.150  -0.162  -0.185  -0.143  -0.125  -0.083  -0.053  -0.034  -0.166  -0.213  -0.185  -0.169  -0.125  -0.043  -0.020  -0.006  -0.170  -0.182  -0.177  -0.155  -0.080  -0.026  +0.003  +0.047  -0.146  -0.157  -0.143  -0.097  +0.017  +0.066  +0.084  +0.082  -0.110  -0.094  -0.091  +0.008  +1.000  +0.136  +0.139  +0.140  -0.074  -0.053  +0.025  +0.076  +0.159  +0.176  +0.165  +0.145  -0.022  -0.007  +0.032  +0.104  +0.160  +0.195  +0.173  +0.153  -0.017  +0.008  +0.062  +0.110  +0.153  +0.158  +0.145  +0.112\n",
      "                         :   var37:  -0.236  -0.236  -0.253  -0.160  -0.087  +0.024  +0.064  +0.092  -0.292  -0.322  -0.291  -0.190  -0.080  +0.058  +0.155  +0.148  -0.324  -0.360  -0.321  -0.192  +0.009  +0.143  +0.225  +0.231  -0.327  -0.365  -0.309  -0.146  +0.063  +0.242  +0.308  +0.298  -0.325  -0.301  -0.255  -0.063  +0.136  +1.000  +0.347  +0.353  -0.251  -0.254  -0.145  +0.005  +0.192  +0.321  +0.359  +0.336  -0.183  -0.161  -0.095  +0.030  +0.171  +0.286  +0.296  +0.290  -0.139  -0.080  -0.047  +0.034  +0.164  +0.228  +0.260  +0.218\n",
      "                         :   var38:  -0.253  -0.279  -0.228  -0.146  -0.043  +0.075  +0.120  +0.155  -0.313  -0.343  -0.298  -0.173  -0.023  +0.114  +0.223  +0.215  -0.380  -0.386  -0.345  -0.194  +0.024  +0.218  +0.303  +0.316  -0.401  -0.411  -0.351  -0.143  +0.109  +0.287  +0.372  +0.374  -0.371  -0.377  -0.311  -0.100  +0.139  +0.347  +1.000  +0.409  -0.325  -0.310  -0.211  -0.045  +0.177  +0.333  +0.383  +0.373  -0.237  -0.220  -0.136  -0.008  +0.157  +0.273  +0.334  +0.312  -0.162  -0.136  -0.104  +0.010  +0.130  +0.219  +0.277  +0.253\n",
      "                         :   var39:  -0.231  -0.220  -0.212  -0.129  -0.010  +0.086  +0.136  +0.172  -0.280  -0.313  -0.278  -0.153  -0.004  +0.152  +0.227  +0.247  -0.339  -0.359  -0.319  -0.174  +0.049  +0.213  +0.302  +0.335  -0.384  -0.409  -0.340  -0.152  +0.100  +0.294  +0.364  +0.386  -0.380  -0.365  -0.318  -0.137  +0.140  +0.353  +0.409  +1.000  -0.324  -0.315  -0.235  -0.089  +0.151  +0.316  +0.395  +0.364  -0.254  -0.225  -0.177  -0.033  +0.139  +0.277  +0.319  +0.302  -0.183  -0.158  -0.119  +0.001  +0.120  +0.214  +0.261  +0.221\n",
      "                         :   var40:  +0.104  +0.053  -0.000  -0.094  -0.196  -0.271  -0.264  -0.243  +0.167  +0.122  +0.041  -0.112  -0.218  -0.322  -0.337  -0.306  +0.246  +0.215  +0.125  -0.030  -0.253  -0.346  -0.396  -0.359  +0.324  +0.337  +0.250  +0.048  -0.177  -0.329  -0.404  -0.344  +0.387  +0.401  +0.351  +0.155  -0.074  -0.251  -0.325  -0.324  +1.000  +0.418  +0.349  +0.235  +0.001  -0.156  -0.248  -0.248  +0.359  +0.372  +0.336  +0.218  +0.066  -0.079  -0.164  -0.180  +0.267  +0.317  +0.288  +0.194  +0.064  -0.026  -0.087  -0.137\n",
      "                         :   var41:  +0.082  +0.012  -0.066  -0.158  -0.236  -0.313  -0.316  -0.258  +0.121  +0.057  -0.002  -0.143  -0.249  -0.356  -0.376  -0.347  +0.211  +0.189  +0.096  -0.074  -0.265  -0.375  -0.402  -0.378  +0.307  +0.306  +0.226  +0.036  -0.215  -0.341  -0.390  -0.339  +0.383  +0.375  +0.357  +0.155  -0.053  -0.254  -0.310  -0.315  +0.418  +1.000  +0.377  +0.269  +0.050  -0.126  -0.222  -0.246  +0.376  +0.393  +0.376  +0.269  +0.106  -0.041  -0.116  -0.149  +0.301  +0.331  +0.334  +0.243  +0.129  +0.018  -0.068  -0.091\n",
      "                         :   var42:  -0.030  -0.077  -0.150  -0.246  -0.332  -0.343  -0.329  -0.274  +0.019  -0.018  -0.120  -0.228  -0.320  -0.395  -0.364  -0.326  +0.117  +0.051  -0.011  -0.167  -0.309  -0.377  -0.393  -0.331  +0.187  +0.196  +0.116  +0.007  -0.186  -0.297  -0.335  -0.309  +0.310  +0.323  +0.332  +0.170  +0.025  -0.145  -0.211  -0.235  +0.349  +0.377  +1.000  +0.306  +0.142  -0.021  -0.088  -0.145  +0.338  +0.375  +0.405  +0.336  +0.225  +0.068  -0.009  -0.073  +0.304  +0.354  +0.374  +0.298  +0.218  +0.111  +0.027  -0.019\n",
      "                         :   var43:  -0.098  -0.188  -0.251  -0.293  -0.331  -0.337  -0.302  -0.228  -0.099  -0.157  -0.224  -0.291  -0.344  -0.353  -0.307  -0.263  -0.055  -0.100  -0.143  -0.218  -0.299  -0.316  -0.282  -0.251  +0.035  +0.035  -0.001  -0.070  -0.139  -0.184  -0.206  -0.184  +0.142  +0.191  +0.195  +0.145  +0.076  +0.005  -0.045  -0.089  +0.235  +0.269  +0.306  +1.000  +0.241  +0.116  +0.072  +0.032  +0.228  +0.302  +0.352  +0.357  +0.283  +0.226  +0.123  +0.071  +0.229  +0.286  +0.342  +0.323  +0.290  +0.216  +0.157  +0.097\n",
      "                         :   var44:  -0.217  -0.288  -0.339  -0.315  -0.297  -0.233  -0.176  -0.131  -0.252  -0.309  -0.338  -0.354  -0.303  -0.247  -0.165  -0.099  -0.228  -0.249  -0.291  -0.287  -0.238  -0.145  -0.083  -0.041  -0.163  -0.187  -0.193  -0.142  -0.074  +0.002  +0.031  +0.043  -0.087  -0.083  -0.004  +0.079  +0.159  +0.192  +0.177  +0.151  +0.001  +0.050  +0.142  +0.241  +1.000  +0.298  +0.278  +0.220  +0.062  +0.116  +0.196  +0.289  +0.341  +0.344  +0.301  +0.248  +0.088  +0.151  +0.219  +0.284  +0.346  +0.323  +0.307  +0.199\n",
      "                         :   var45:  -0.256  -0.322  -0.339  -0.305  -0.227  -0.146  -0.083  -0.004  -0.343  -0.382  -0.395  -0.329  -0.231  -0.104  -0.004  +0.042  -0.337  -0.387  -0.365  -0.311  -0.152  -0.004  +0.075  +0.116  -0.320  -0.343  -0.302  -0.167  -0.004  +0.140  +0.221  +0.226  -0.258  -0.243  -0.174  +0.002  +0.176  +0.321  +0.333  +0.316  -0.156  -0.126  -0.021  +0.116  +0.298  +1.000  +0.416  +0.363  -0.076  -0.026  +0.071  +0.215  +0.343  +0.402  +0.389  +0.358  -0.031  +0.037  +0.108  +0.211  +0.312  +0.350  +0.369  +0.277\n",
      "                         :   var46:  -0.262  -0.338  -0.329  -0.245  -0.175  -0.081  -0.006  +0.065  -0.351  -0.385  -0.379  -0.293  -0.166  -0.035  +0.087  +0.107  -0.377  -0.403  -0.388  -0.296  -0.103  +0.073  +0.188  +0.218  -0.360  -0.407  -0.345  -0.190  +0.044  +0.191  +0.297  +0.297  -0.325  -0.311  -0.240  -0.029  +0.165  +0.359  +0.383  +0.395  -0.248  -0.222  -0.088  +0.072  +0.278  +0.416  +1.000  +0.409  -0.155  -0.115  -0.022  +0.139  +0.312  +0.392  +0.407  +0.381  -0.085  -0.051  +0.031  +0.162  +0.284  +0.337  +0.379  +0.309\n",
      "                         :   var47:  -0.244  -0.283  -0.265  -0.202  -0.116  -0.009  +0.041  +0.099  -0.307  -0.350  -0.297  -0.231  -0.119  +0.021  +0.120  +0.170  -0.351  -0.380  -0.340  -0.231  -0.048  +0.125  +0.216  +0.245  -0.355  -0.389  -0.349  -0.191  +0.044  +0.211  +0.310  +0.311  -0.329  -0.297  -0.247  -0.081  +0.145  +0.336  +0.373  +0.364  -0.248  -0.246  -0.145  +0.032  +0.220  +0.363  +0.409  +1.000  -0.179  -0.148  -0.072  +0.076  +0.237  +0.339  +0.374  +0.350  -0.120  -0.078  -0.017  +0.101  +0.210  +0.287  +0.327  +0.257\n",
      "                         :   var48:  +0.032  -0.010  -0.082  -0.165  -0.233  -0.269  -0.253  -0.231  +0.067  +0.036  -0.036  -0.144  -0.257  -0.322  -0.306  -0.281  +0.157  +0.114  +0.030  -0.086  -0.235  -0.320  -0.348  -0.315  +0.225  +0.226  +0.178  +0.001  -0.210  -0.272  -0.329  -0.279  +0.327  +0.324  +0.302  +0.161  -0.022  -0.183  -0.237  -0.254  +0.359  +0.376  +0.338  +0.228  +0.062  -0.076  -0.155  -0.179  +1.000  +0.344  +0.333  +0.247  +0.117  -0.008  -0.082  -0.116  +0.266  +0.298  +0.313  +0.229  +0.134  +0.026  -0.040  -0.076\n",
      "                         :   var49:  -0.019  -0.076  -0.144  -0.224  -0.279  -0.335  -0.304  -0.260  +0.002  -0.026  -0.104  -0.232  -0.299  -0.379  -0.364  -0.315  +0.124  +0.066  -0.007  -0.166  -0.317  -0.352  -0.381  -0.330  +0.235  +0.209  +0.126  +0.010  -0.179  -0.295  -0.322  -0.288  +0.320  +0.316  +0.308  +0.164  -0.007  -0.161  -0.220  -0.225  +0.372  +0.393  +0.375  +0.302  +0.116  -0.026  -0.115  -0.148  +0.344  +1.000  +0.397  +0.337  +0.202  +0.065  -0.021  -0.077  +0.295  +0.358  +0.363  +0.304  +0.213  +0.108  +0.023  -0.036\n",
      "                         :   var50:  -0.071  -0.156  -0.220  -0.307  -0.358  -0.374  -0.323  -0.277  -0.069  -0.111  -0.191  -0.289  -0.374  -0.411  -0.379  -0.317  +0.034  -0.023  -0.101  -0.219  -0.346  -0.381  -0.349  -0.302  +0.145  +0.115  +0.053  -0.053  -0.206  -0.290  -0.289  -0.269  +0.269  +0.279  +0.287  +0.175  +0.032  -0.095  -0.136  -0.177  +0.336  +0.376  +0.405  +0.352  +0.196  +0.071  -0.022  -0.072  +0.333  +0.397  +1.000  +0.389  +0.289  +0.156  +0.085  +0.015  +0.284  +0.382  +0.403  +0.368  +0.302  +0.198  +0.100  +0.033\n",
      "                         :   var51:  -0.166  -0.254  -0.327  -0.387  -0.396  -0.380  -0.294  -0.253  -0.176  -0.237  -0.314  -0.370  -0.398  -0.395  -0.312  -0.260  -0.102  -0.169  -0.227  -0.289  -0.344  -0.322  -0.278  -0.225  -0.002  -0.021  -0.056  -0.095  -0.149  -0.187  -0.186  -0.122  +0.130  +0.157  +0.173  +0.152  +0.104  +0.030  -0.008  -0.033  +0.218  +0.269  +0.336  +0.357  +0.289  +0.215  +0.139  +0.076  +0.247  +0.337  +0.389  +1.000  +0.401  +0.304  +0.216  +0.129  +0.252  +0.351  +0.397  +0.413  +0.379  +0.318  +0.231  +0.139\n",
      "                         :   var52:  -0.233  -0.314  -0.375  -0.401  -0.370  -0.295  -0.242  -0.175  -0.269  -0.331  -0.380  -0.397  -0.378  -0.328  -0.212  -0.178  -0.231  -0.279  -0.313  -0.342  -0.309  -0.230  -0.137  -0.094  -0.149  -0.191  -0.181  -0.173  -0.104  -0.031  -0.025  +0.017  -0.052  -0.017  +0.045  +0.086  +0.160  +0.171  +0.157  +0.139  +0.066  +0.106  +0.225  +0.283  +0.341  +0.343  +0.312  +0.237  +0.117  +0.202  +0.289  +0.401  +1.000  +0.404  +0.343  +0.264  +0.146  +0.247  +0.304  +0.366  +0.412  +0.385  +0.337  +0.262\n",
      "                         :   var53:  -0.252  -0.349  -0.355  -0.345  -0.298  -0.223  -0.141  -0.090  -0.330  -0.383  -0.400  -0.372  -0.307  -0.202  -0.089  -0.058  -0.303  -0.366  -0.368  -0.358  -0.225  -0.090  -0.034  +0.045  -0.276  -0.295  -0.278  -0.179  -0.054  +0.064  +0.121  +0.143  -0.186  -0.167  -0.106  +0.044  +0.195  +0.286  +0.273  +0.277  -0.079  -0.041  +0.068  +0.226  +0.344  +0.402  +0.392  +0.339  -0.008  +0.065  +0.156  +0.304  +0.404  +1.000  +0.406  +0.359  +0.012  +0.124  +0.200  +0.311  +0.393  +0.405  +0.384  +0.316\n",
      "                         :   var54:  -0.242  -0.328  -0.317  -0.290  -0.238  -0.142  -0.075  -0.015  -0.315  -0.376  -0.370  -0.313  -0.226  -0.121  -0.013  +0.009  -0.331  -0.363  -0.353  -0.307  -0.168  -0.012  +0.066  +0.099  -0.319  -0.329  -0.310  -0.206  -0.004  +0.134  +0.206  +0.209  -0.248  -0.222  -0.167  -0.024  +0.173  +0.296  +0.334  +0.319  -0.164  -0.116  -0.009  +0.123  +0.301  +0.389  +0.407  +0.374  -0.082  -0.021  +0.085  +0.216  +0.343  +0.406  +1.000  +0.364  -0.016  +0.027  +0.123  +0.246  +0.329  +0.361  +0.364  +0.313\n",
      "                         :   var55:  -0.231  -0.271  -0.274  -0.230  -0.179  -0.080  -0.023  +0.012  -0.273  -0.313  -0.330  -0.264  -0.172  -0.058  +0.030  +0.068  -0.295  -0.324  -0.320  -0.249  -0.088  +0.046  +0.117  +0.149  -0.299  -0.330  -0.295  -0.173  -0.004  +0.159  +0.222  +0.223  -0.273  -0.249  -0.203  -0.023  +0.153  +0.290  +0.312  +0.302  -0.180  -0.149  -0.073  +0.071  +0.248  +0.358  +0.381  +0.350  -0.116  -0.077  +0.015  +0.129  +0.264  +0.359  +0.364  +1.000  -0.070  -0.021  +0.053  +0.163  +0.250  +0.314  +0.337  +0.260\n",
      "                         :   var56:  -0.006  -0.040  -0.104  -0.166  -0.224  -0.221  -0.205  -0.201  +0.022  +0.007  -0.068  -0.150  -0.246  -0.275  -0.255  -0.200  +0.090  +0.060  -0.009  -0.121  -0.229  -0.275  -0.266  -0.223  +0.143  +0.149  +0.112  -0.034  -0.140  -0.201  -0.246  -0.206  +0.246  +0.243  +0.254  +0.105  -0.017  -0.139  -0.162  -0.183  +0.267  +0.301  +0.304  +0.229  +0.088  -0.031  -0.085  -0.120  +0.266  +0.295  +0.284  +0.252  +0.146  +0.012  -0.016  -0.070  +1.000  +0.274  +0.264  +0.217  +0.150  +0.067  -0.010  -0.019\n",
      "                         :   var57:  -0.061  -0.122  -0.209  -0.257  -0.292  -0.294  -0.265  -0.210  -0.046  -0.092  -0.165  -0.264  -0.298  -0.347  -0.296  -0.261  +0.030  -0.006  -0.092  -0.203  -0.305  -0.322  -0.306  -0.251  +0.126  +0.111  +0.051  -0.066  -0.168  -0.245  -0.257  -0.221  +0.243  +0.252  +0.244  +0.150  +0.008  -0.080  -0.136  -0.158  +0.317  +0.331  +0.354  +0.286  +0.151  +0.037  -0.051  -0.078  +0.298  +0.358  +0.382  +0.351  +0.247  +0.124  +0.027  -0.021  +0.274  +1.000  +0.364  +0.311  +0.265  +0.159  +0.070  +0.014\n",
      "                         :   var58:  -0.139  -0.180  -0.251  -0.315  -0.341  -0.341  -0.280  -0.229  -0.100  -0.158  -0.234  -0.306  -0.367  -0.377  -0.340  -0.271  -0.031  -0.075  -0.139  -0.263  -0.325  -0.340  -0.300  -0.258  +0.069  +0.053  +0.004  -0.094  -0.184  -0.219  -0.233  -0.184  +0.202  +0.214  +0.237  +0.134  +0.062  -0.047  -0.104  -0.119  +0.288  +0.334  +0.374  +0.342  +0.219  +0.108  +0.031  -0.017  +0.313  +0.363  +0.403  +0.397  +0.304  +0.200  +0.123  +0.053  +0.264  +0.364  +1.000  +0.372  +0.316  +0.214  +0.138  +0.070\n",
      "                         :   var59:  -0.159  -0.239  -0.315  -0.355  -0.368  -0.338  -0.280  -0.214  -0.181  -0.243  -0.307  -0.368  -0.379  -0.354  -0.294  -0.248  -0.112  -0.163  -0.232  -0.292  -0.334  -0.292  -0.252  -0.190  -0.017  -0.047  -0.075  -0.117  -0.178  -0.157  -0.145  -0.110  +0.078  +0.123  +0.137  +0.137  +0.110  +0.034  +0.010  +0.001  +0.194  +0.243  +0.298  +0.323  +0.284  +0.211  +0.162  +0.101  +0.229  +0.304  +0.368  +0.413  +0.366  +0.311  +0.246  +0.163  +0.217  +0.311  +0.372  +1.000  +0.378  +0.317  +0.235  +0.153\n",
      "                         :   var60:  -0.220  -0.307  -0.364  -0.373  -0.357  -0.307  -0.250  -0.171  -0.259  -0.309  -0.365  -0.396  -0.381  -0.318  -0.230  -0.175  -0.204  -0.269  -0.314  -0.341  -0.321  -0.234  -0.163  -0.107  -0.132  -0.177  -0.162  -0.156  -0.107  -0.063  -0.036  -0.004  -0.009  -0.003  +0.062  +0.091  +0.153  +0.164  +0.130  +0.120  +0.064  +0.129  +0.218  +0.290  +0.346  +0.312  +0.284  +0.210  +0.134  +0.213  +0.302  +0.379  +0.412  +0.393  +0.329  +0.250  +0.150  +0.265  +0.316  +0.378  +1.000  +0.370  +0.317  +0.239\n",
      "                         :   var61:  -0.233  -0.317  -0.331  -0.322  -0.308  -0.243  -0.187  -0.107  -0.280  -0.337  -0.386  -0.354  -0.310  -0.227  -0.134  -0.082  -0.249  -0.298  -0.340  -0.332  -0.249  -0.143  -0.072  -0.015  -0.226  -0.249  -0.233  -0.180  -0.084  +0.021  +0.065  +0.084  -0.123  -0.104  -0.050  +0.057  +0.158  +0.228  +0.219  +0.214  -0.026  +0.018  +0.111  +0.216  +0.323  +0.350  +0.337  +0.287  +0.026  +0.108  +0.198  +0.318  +0.385  +0.405  +0.361  +0.314  +0.067  +0.159  +0.214  +0.317  +0.370  +1.000  +0.376  +0.281\n",
      "                         :   var62:  -0.225  -0.280  -0.312  -0.291  -0.256  -0.169  -0.100  -0.048  -0.288  -0.332  -0.344  -0.316  -0.250  -0.150  -0.057  -0.027  -0.293  -0.335  -0.324  -0.299  -0.182  -0.055  +0.027  +0.075  -0.257  -0.278  -0.272  -0.185  -0.042  +0.085  +0.148  +0.153  -0.184  -0.179  -0.129  +0.030  +0.145  +0.260  +0.277  +0.261  -0.087  -0.068  +0.027  +0.157  +0.307  +0.369  +0.379  +0.327  -0.040  +0.023  +0.100  +0.231  +0.337  +0.384  +0.364  +0.337  -0.010  +0.070  +0.138  +0.235  +0.317  +0.376  +1.000  +0.274\n",
      "                         :   var63:  -0.164  -0.232  -0.236  -0.186  -0.156  -0.106  -0.068  +0.002  -0.240  -0.258  -0.264  -0.225  -0.152  -0.090  -0.005  +0.004  -0.219  -0.263  -0.274  -0.218  -0.115  -0.005  +0.058  +0.105  -0.213  -0.261  -0.223  -0.139  +0.001  +0.098  +0.149  +0.156  -0.194  -0.174  -0.119  -0.001  +0.112  +0.218  +0.253  +0.221  -0.137  -0.091  -0.019  +0.097  +0.199  +0.277  +0.309  +0.257  -0.076  -0.036  +0.033  +0.139  +0.262  +0.316  +0.313  +0.260  -0.019  +0.014  +0.070  +0.153  +0.239  +0.281  +0.274  +1.000\n",
      "                         : ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "DataSetFactory           : [dataset] :  \n",
      "                         : \n",
      "Factory                  : [dataset] : Create Transformation \"I\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var0' <---> Output : variable 'var0'\n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "                         : Input : variable 'var5' <---> Output : variable 'var5'\n",
      "                         : Input : variable 'var6' <---> Output : variable 'var6'\n",
      "                         : Input : variable 'var7' <---> Output : variable 'var7'\n",
      "                         : Input : variable 'var8' <---> Output : variable 'var8'\n",
      "                         : Input : variable 'var9' <---> Output : variable 'var9'\n",
      "                         : Input : variable 'var10' <---> Output : variable 'var10'\n",
      "                         : Input : variable 'var11' <---> Output : variable 'var11'\n",
      "                         : Input : variable 'var12' <---> Output : variable 'var12'\n",
      "                         : Input : variable 'var13' <---> Output : variable 'var13'\n",
      "                         : Input : variable 'var14' <---> Output : variable 'var14'\n",
      "                         : Input : variable 'var15' <---> Output : variable 'var15'\n",
      "                         : Input : variable 'var16' <---> Output : variable 'var16'\n",
      "                         : Input : variable 'var17' <---> Output : variable 'var17'\n",
      "                         : Input : variable 'var18' <---> Output : variable 'var18'\n",
      "                         : Input : variable 'var19' <---> Output : variable 'var19'\n",
      "                         : Input : variable 'var20' <---> Output : variable 'var20'\n",
      "                         : Input : variable 'var21' <---> Output : variable 'var21'\n",
      "                         : Input : variable 'var22' <---> Output : variable 'var22'\n",
      "                         : Input : variable 'var23' <---> Output : variable 'var23'\n",
      "                         : Input : variable 'var24' <---> Output : variable 'var24'\n",
      "                         : Input : variable 'var25' <---> Output : variable 'var25'\n",
      "                         : Input : variable 'var26' <---> Output : variable 'var26'\n",
      "                         : Input : variable 'var27' <---> Output : variable 'var27'\n",
      "                         : Input : variable 'var28' <---> Output : variable 'var28'\n",
      "                         : Input : variable 'var29' <---> Output : variable 'var29'\n",
      "                         : Input : variable 'var30' <---> Output : variable 'var30'\n",
      "                         : Input : variable 'var31' <---> Output : variable 'var31'\n",
      "                         : Input : variable 'var32' <---> Output : variable 'var32'\n",
      "                         : Input : variable 'var33' <---> Output : variable 'var33'\n",
      "                         : Input : variable 'var34' <---> Output : variable 'var34'\n",
      "                         : Input : variable 'var35' <---> Output : variable 'var35'\n",
      "                         : Input : variable 'var36' <---> Output : variable 'var36'\n",
      "                         : Input : variable 'var37' <---> Output : variable 'var37'\n",
      "                         : Input : variable 'var38' <---> Output : variable 'var38'\n",
      "                         : Input : variable 'var39' <---> Output : variable 'var39'\n",
      "                         : Input : variable 'var40' <---> Output : variable 'var40'\n",
      "                         : Input : variable 'var41' <---> Output : variable 'var41'\n",
      "                         : Input : variable 'var42' <---> Output : variable 'var42'\n",
      "                         : Input : variable 'var43' <---> Output : variable 'var43'\n",
      "                         : Input : variable 'var44' <---> Output : variable 'var44'\n",
      "                         : Input : variable 'var45' <---> Output : variable 'var45'\n",
      "                         : Input : variable 'var46' <---> Output : variable 'var46'\n",
      "                         : Input : variable 'var47' <---> Output : variable 'var47'\n",
      "                         : Input : variable 'var48' <---> Output : variable 'var48'\n",
      "                         : Input : variable 'var49' <---> Output : variable 'var49'\n",
      "                         : Input : variable 'var50' <---> Output : variable 'var50'\n",
      "                         : Input : variable 'var51' <---> Output : variable 'var51'\n",
      "                         : Input : variable 'var52' <---> Output : variable 'var52'\n",
      "                         : Input : variable 'var53' <---> Output : variable 'var53'\n",
      "                         : Input : variable 'var54' <---> Output : variable 'var54'\n",
      "                         : Input : variable 'var55' <---> Output : variable 'var55'\n",
      "                         : Input : variable 'var56' <---> Output : variable 'var56'\n",
      "                         : Input : variable 'var57' <---> Output : variable 'var57'\n",
      "                         : Input : variable 'var58' <---> Output : variable 'var58'\n",
      "                         : Input : variable 'var59' <---> Output : variable 'var59'\n",
      "                         : Input : variable 'var60' <---> Output : variable 'var60'\n",
      "                         : Input : variable 'var61' <---> Output : variable 'var61'\n",
      "                         : Input : variable 'var62' <---> Output : variable 'var62'\n",
      "                         : Input : variable 'var63' <---> Output : variable 'var63'\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:     2.4323     3.8630   [    -10.257     22.057 ]\n",
      "                         :     var1:     3.9627     4.4650   [    -10.122     25.831 ]\n",
      "                         :     var2:     5.4794     4.8725   [    -8.1906     29.836 ]\n",
      "                         :     var3:     6.5490     5.0368   [    -9.7689     29.230 ]\n",
      "                         :     var4:     6.4897     5.0083   [    -11.476     27.242 ]\n",
      "                         :     var5:     5.5051     4.8667   [    -7.5238     30.122 ]\n",
      "                         :     var6:     3.9918     4.5749   [    -11.141     28.512 ]\n",
      "                         :     var7:     2.4703     3.8798   [    -9.8602     22.021 ]\n",
      "                         :     var8:     3.7059     4.4063   [    -9.7199     27.343 ]\n",
      "                         :     var9:     6.0613     5.1470   [    -9.2157     29.457 ]\n",
      "                         :    var10:     8.3576     5.4924   [    -8.2847     30.470 ]\n",
      "                         :    var11:     9.7592     5.4900   [    -6.4768     32.336 ]\n",
      "                         :    var12:     9.6933     5.4783   [    -8.2850     31.239 ]\n",
      "                         :    var13:     8.3248     5.5687   [    -7.3403     36.270 ]\n",
      "                         :    var14:     6.0560     5.1065   [    -9.2506     30.755 ]\n",
      "                         :    var15:     3.6508     4.4111   [    -12.546     22.584 ]\n",
      "                         :    var16:     4.8265     4.7593   [    -11.709     25.905 ]\n",
      "                         :    var17:     7.9222     5.5350   [    -8.2664     32.881 ]\n",
      "                         :    var18:     10.901     5.7474   [    -7.3453     35.900 ]\n",
      "                         :    var19:     12.854     5.4604   [    -5.4607     34.438 ]\n",
      "                         :    var20:     12.906     5.5766   [    -4.2162     34.453 ]\n",
      "                         :    var21:     10.965     5.8446   [    -6.3943     36.072 ]\n",
      "                         :    var22:     7.9054     5.5204   [    -7.9329     35.488 ]\n",
      "                         :    var23:     4.8375     4.7729   [    -10.919     23.259 ]\n",
      "                         :    var24:     5.6867     5.0012   [    -9.8326     27.530 ]\n",
      "                         :    var25:     9.0772     5.6819   [    -7.8932     32.554 ]\n",
      "                         :    var26:     12.562     5.6847   [    -4.3404     38.462 ]\n",
      "                         :    var27:     14.825     5.1680   [    -1.4311     37.430 ]\n",
      "                         :    var28:     14.731     5.1689   [    -2.8283     35.169 ]\n",
      "                         :    var29:     12.518     5.6598   [    -4.0975     36.999 ]\n",
      "                         :    var30:     9.0170     5.6967   [    -10.813     31.782 ]\n",
      "                         :    var31:     5.6330     5.0257   [    -9.6496     30.010 ]\n",
      "                         :    var32:     5.5739     4.9879   [    -11.560     26.953 ]\n",
      "                         :    var33:     9.1757     5.6492   [    -7.8908     33.206 ]\n",
      "                         :    var34:     12.627     5.6557   [    -5.9139     36.718 ]\n",
      "                         :    var35:     14.652     5.1028   [    -2.6615     34.607 ]\n",
      "                         :    var36:     14.779     5.1843   [    -2.8380     35.026 ]\n",
      "                         :    var37:     12.554     5.5964   [    -4.7197     33.836 ]\n",
      "                         :    var38:     9.0812     5.6938   [    -9.4451     32.626 ]\n",
      "                         :    var39:     5.6233     4.9971   [    -9.8782     27.415 ]\n",
      "                         :    var40:     4.9276     4.7854   [    -10.422     25.623 ]\n",
      "                         :    var41:     7.8189     5.5261   [    -8.4661     34.692 ]\n",
      "                         :    var42:     11.010     5.7812   [    -7.3053     36.124 ]\n",
      "                         :    var43:     12.902     5.4537   [    -6.0367     43.293 ]\n",
      "                         :    var44:     12.877     5.5252   [    -4.2441     34.631 ]\n",
      "                         :    var45:     11.014     5.7658   [    -5.3868     34.427 ]\n",
      "                         :    var46:     7.9269     5.5660   [    -8.9838     29.830 ]\n",
      "                         :    var47:     4.8651     4.7856   [    -9.0932     27.598 ]\n",
      "                         :    var48:     3.7239     4.3873   [    -10.844     25.228 ]\n",
      "                         :    var49:     6.0798     5.0591   [    -8.1885     29.845 ]\n",
      "                         :    var50:     8.2995     5.4137   [    -7.5161     32.722 ]\n",
      "                         :    var51:     9.8403     5.5363   [    -6.6423     32.436 ]\n",
      "                         :    var52:     9.8072     5.4962   [    -8.3466     33.869 ]\n",
      "                         :    var53:     8.3199     5.4493   [    -9.7019     35.304 ]\n",
      "                         :    var54:     6.0523     5.0862   [    -9.1295     32.443 ]\n",
      "                         :    var55:     3.6869     4.3417   [    -8.7073     27.256 ]\n",
      "                         :    var56:     2.4803     3.8967   [    -11.497     22.620 ]\n",
      "                         :    var57:     4.0231     4.5292   [    -8.6827     26.215 ]\n",
      "                         :    var58:     5.5256     4.8462   [    -10.942     30.791 ]\n",
      "                         :    var59:     6.5213     5.0135   [    -8.9191     29.350 ]\n",
      "                         :    var60:     6.5675     5.0285   [    -9.9130     28.476 ]\n",
      "                         :    var61:     5.5765     4.8790   [    -9.6182     29.674 ]\n",
      "                         :    var62:     4.0368     4.5263   [    -11.569     23.585 ]\n",
      "                         :    var63:     2.5323     3.8614   [    -10.527     22.465 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \u001b[32m\n",
      "                         : <PlotVariables> Will not produce scatter plots ==> \n",
      "                         : |  The number of 64 input variables and 0 target values would require 2016 two-dimensional\n",
      "                         : |  histograms, which would occupy the computer's memory. Note that this\n",
      "                         : |  suppression does not have any consequences for your analysis, other\n",
      "                         : |  than not disposing of these scatter plots. You can modify the maximum\n",
      "                         : |  number of input variables allowed to generate scatter plots in your\n",
      "                         : |  script via the command line:\n",
      "                         : |  \"(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;\"\u001b[0m\n",
      "                         : \n",
      "                         : Some more output\n",
      "                         : Ranking input variables (method unspecific)...\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : ------------------------------\n",
      "                         : Rank : Variable  : Separation\n",
      "                         : ------------------------------\n",
      "                         :    1 : var31     : 1.549e-02\n",
      "                         :    2 : var4      : 1.510e-02\n",
      "                         :    3 : var39     : 1.348e-02\n",
      "                         :    4 : var59     : 1.257e-02\n",
      "                         :    5 : var11     : 1.254e-02\n",
      "                         :    6 : var24     : 1.143e-02\n",
      "                         :    7 : var32     : 1.110e-02\n",
      "                         :    8 : var60     : 1.097e-02\n",
      "                         :    9 : var38     : 1.033e-02\n",
      "                         :   10 : var3      : 1.018e-02\n",
      "                         :   11 : var23     : 1.018e-02\n",
      "                         :   12 : var16     : 9.936e-03\n",
      "                         :   13 : var40     : 9.754e-03\n",
      "                         :   14 : var47     : 9.667e-03\n",
      "                         :   15 : var61     : 8.764e-03\n",
      "                         :   16 : var30     : 8.681e-03\n",
      "                         :   17 : var33     : 8.675e-03\n",
      "                         :   18 : var2      : 8.608e-03\n",
      "                         :   19 : var12     : 8.266e-03\n",
      "                         :   20 : var51     : 8.209e-03\n",
      "                         :   21 : var52     : 7.558e-03\n",
      "                         :   22 : var25     : 7.553e-03\n",
      "                         :   23 : var41     : 7.429e-03\n",
      "                         :   24 : var58     : 7.218e-03\n",
      "                         :   25 : var46     : 6.884e-03\n",
      "                         :   26 : var20     : 6.747e-03\n",
      "                         :   27 : var37     : 6.639e-03\n",
      "                         :   28 : var53     : 6.322e-03\n",
      "                         :   29 : var15     : 6.032e-03\n",
      "                         :   30 : var43     : 5.932e-03\n",
      "                         :   31 : var5      : 5.777e-03\n",
      "                         :   32 : var26     : 5.675e-03\n",
      "                         :   33 : var50     : 5.519e-03\n",
      "                         :   34 : var48     : 5.465e-03\n",
      "                         :   35 : var13     : 5.391e-03\n",
      "                         :   36 : var34     : 5.260e-03\n",
      "                         :   37 : var10     : 5.192e-03\n",
      "                         :   38 : var8      : 5.087e-03\n",
      "                         :   39 : var55     : 5.085e-03\n",
      "                         :   40 : var22     : 5.001e-03\n",
      "                         :   41 : var19     : 4.940e-03\n",
      "                         :   42 : var27     : 4.856e-03\n",
      "                         :   43 : var45     : 4.439e-03\n",
      "                         :   44 : var57     : 4.390e-03\n",
      "                         :   45 : var54     : 4.208e-03\n",
      "                         :   46 : var62     : 4.115e-03\n",
      "                         :   47 : var44     : 3.945e-03\n",
      "                         :   48 : var9      : 3.896e-03\n",
      "                         :   49 : var21     : 3.869e-03\n",
      "                         :   50 : var17     : 3.854e-03\n",
      "                         :   51 : var7      : 3.849e-03\n",
      "                         :   52 : var1      : 3.797e-03\n",
      "                         :   53 : var29     : 3.788e-03\n",
      "                         :   54 : var35     : 3.780e-03\n",
      "                         :   55 : var36     : 3.574e-03\n",
      "                         :   56 : var42     : 3.494e-03\n",
      "                         :   57 : var14     : 3.100e-03\n",
      "                         :   58 : var49     : 3.016e-03\n",
      "                         :   59 : var0      : 2.904e-03\n",
      "                         :   60 : var56     : 2.888e-03\n",
      "                         :   61 : var63     : 2.808e-03\n",
      "                         :   62 : var18     : 2.719e-03\n",
      "                         :   63 : var6      : 2.643e-03\n",
      "                         :   64 : var28     : 2.389e-03\n",
      "                         : ------------------------------\n",
      "Factory                  : Train method: DL_DENSE for Classification\n",
      "                         : \n",
      "                         : Preparing the Gaussian transformation...\n",
      "TFHandler_DL_DENSE       : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:  0.0058610    0.99711   [    -3.1847     5.7307 ]\n",
      "                         :     var1:  0.0057942    0.99695   [    -3.1847     5.7307 ]\n",
      "                         :     var2:  0.0060132    0.99817   [    -3.1847     5.7307 ]\n",
      "                         :     var3:  0.0060355    0.99815   [    -3.1847     5.7307 ]\n",
      "                         :     var4:  0.0065503     1.0001   [    -3.1847     5.7307 ]\n",
      "                         :     var5:  0.0056561    0.99698   [    -3.1847     5.7307 ]\n",
      "                         :     var6:  0.0071681     1.0028   [    -3.1847     5.7307 ]\n",
      "                         :     var7:  0.0065171     1.0005   [    -3.1847     5.7307 ]\n",
      "                         :     var8:  0.0059253    0.99747   [    -3.1847     5.7307 ]\n",
      "                         :     var9:  0.0066121     1.0010   [    -3.1847     5.7307 ]\n",
      "                         :    var10:  0.0065015     1.0004   [    -3.1847     5.7307 ]\n",
      "                         :    var11:  0.0064784     1.0008   [    -3.1847     5.7307 ]\n",
      "                         :    var12:  0.0067411     1.0014   [    -3.1847     5.7307 ]\n",
      "                         :    var13:  0.0059507    0.99810   [    -3.1847     5.7307 ]\n",
      "                         :    var14:  0.0070676     1.0025   [    -3.1847     5.7307 ]\n",
      "                         :    var15:  0.0061379    0.99810   [    -3.1847     5.7307 ]\n",
      "                         :    var16:  0.0065638     1.0003   [    -3.1847     5.7307 ]\n",
      "                         :    var17:  0.0058684    0.99716   [    -3.1847     5.7307 ]\n",
      "                         :    var18:  0.0063133    0.99922   [    -3.1847     5.7307 ]\n",
      "                         :    var19:  0.0065700     1.0004   [    -3.1847     5.7307 ]\n",
      "                         :    var20:  0.0066059     1.0007   [    -3.1847     5.7307 ]\n",
      "                         :    var21:  0.0062780    0.99938   [    -3.1847     5.7307 ]\n",
      "                         :    var22:  0.0064581     1.0003   [    -3.1847     5.7307 ]\n",
      "                         :    var23:  0.0073309     1.0038   [    -3.1847     5.7307 ]\n",
      "                         :    var24:  0.0063286    0.99916   [    -3.1847     5.7307 ]\n",
      "                         :    var25:  0.0062579    0.99904   [    -3.1847     5.7307 ]\n",
      "                         :    var26:  0.0057227    0.99696   [    -3.1847     5.7307 ]\n",
      "                         :    var27:  0.0062714    0.99930   [    -3.1847     5.7307 ]\n",
      "                         :    var28:  0.0063833    0.99946   [    -3.1847     5.7307 ]\n",
      "                         :    var29:  0.0061613    0.99898   [    -3.1847     5.7307 ]\n",
      "                         :    var30:  0.0065878     1.0004   [    -3.1847     5.7307 ]\n",
      "                         :    var31:  0.0059921    0.99788   [    -3.1847     5.7307 ]\n",
      "                         :    var32:  0.0061175    0.99802   [    -3.1847     5.7307 ]\n",
      "                         :    var33:  0.0068559     1.0015   [    -3.1847     5.7307 ]\n",
      "                         :    var34:  0.0063764    0.99921   [    -3.1847     5.7307 ]\n",
      "                         :    var35:  0.0061553    0.99833   [    -3.1847     5.7307 ]\n",
      "                         :    var36:  0.0065405     1.0006   [    -3.1847     5.7307 ]\n",
      "                         :    var37:  0.0065571     1.0005   [    -3.1847     5.7307 ]\n",
      "                         :    var38:  0.0073183     1.0034   [    -3.1847     5.7307 ]\n",
      "                         :    var39:  0.0063159    0.99897   [    -3.1847     5.7307 ]\n",
      "                         :    var40:  0.0065798     1.0005   [    -3.1847     5.7307 ]\n",
      "                         :    var41:  0.0061950    0.99865   [    -3.1847     5.7307 ]\n",
      "                         :    var42:  0.0060802    0.99827   [    -3.1847     5.7307 ]\n",
      "                         :    var43:  0.0057171    0.99680   [    -3.1847     5.7307 ]\n",
      "                         :    var44:  0.0066068     1.0009   [    -3.1847     5.7307 ]\n",
      "                         :    var45:  0.0062815    0.99917   [    -3.1847     5.7307 ]\n",
      "                         :    var46:  0.0069578     1.0019   [    -3.1847     5.7307 ]\n",
      "                         :    var47:  0.0063784    0.99968   [    -3.1847     5.7307 ]\n",
      "                         :    var48:  0.0060611    0.99819   [    -3.1847     5.7307 ]\n",
      "                         :    var49:  0.0062194    0.99939   [    -3.1847     5.7307 ]\n",
      "                         :    var50:  0.0061665    0.99889   [    -3.1847     5.7307 ]\n",
      "                         :    var51:  0.0060511    0.99818   [    -3.1847     5.7307 ]\n",
      "                         :    var52:  0.0064034    0.99948   [    -3.1847     5.7307 ]\n",
      "                         :    var53:  0.0057530    0.99664   [    -3.1847     5.7307 ]\n",
      "                         :    var54:  0.0059697    0.99799   [    -3.1847     5.7307 ]\n",
      "                         :    var55:  0.0065414     1.0003   [    -3.1847     5.7307 ]\n",
      "                         :    var56:  0.0060559    0.99780   [    -3.1847     5.7307 ]\n",
      "                         :    var57:  0.0066520     1.0007   [    -3.1847     5.7307 ]\n",
      "                         :    var58:  0.0060056    0.99810   [    -3.1847     5.7307 ]\n",
      "                         :    var59:  0.0063135    0.99967   [    -3.1847     5.7307 ]\n",
      "                         :    var60:  0.0066761     1.0006   [    -3.1847     5.7307 ]\n",
      "                         :    var61:  0.0057496    0.99669   [    -3.1847     5.7307 ]\n",
      "                         :    var62:  0.0063415    0.99935   [    -3.1847     5.7307 ]\n",
      "                         :    var63:  0.0060406    0.99807   [    -3.1847     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Start of deep neural network training on CPU using (for ROOT-IMT) nthreads = 1\n",
      "                         : \n",
      "TFHandler_DL_DENSE       : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:  0.0058610    0.99711   [    -3.1847     5.7307 ]\n",
      "                         :     var1:  0.0057942    0.99695   [    -3.1847     5.7307 ]\n",
      "                         :     var2:  0.0060132    0.99817   [    -3.1847     5.7307 ]\n",
      "                         :     var3:  0.0060355    0.99815   [    -3.1847     5.7307 ]\n",
      "                         :     var4:  0.0065503     1.0001   [    -3.1847     5.7307 ]\n",
      "                         :     var5:  0.0056561    0.99698   [    -3.1847     5.7307 ]\n",
      "                         :     var6:  0.0071681     1.0028   [    -3.1847     5.7307 ]\n",
      "                         :     var7:  0.0065171     1.0005   [    -3.1847     5.7307 ]\n",
      "                         :     var8:  0.0059253    0.99747   [    -3.1847     5.7307 ]\n",
      "                         :     var9:  0.0066121     1.0010   [    -3.1847     5.7307 ]\n",
      "                         :    var10:  0.0065015     1.0004   [    -3.1847     5.7307 ]\n",
      "                         :    var11:  0.0064784     1.0008   [    -3.1847     5.7307 ]\n",
      "                         :    var12:  0.0067411     1.0014   [    -3.1847     5.7307 ]\n",
      "                         :    var13:  0.0059507    0.99810   [    -3.1847     5.7307 ]\n",
      "                         :    var14:  0.0070676     1.0025   [    -3.1847     5.7307 ]\n",
      "                         :    var15:  0.0061379    0.99810   [    -3.1847     5.7307 ]\n",
      "                         :    var16:  0.0065638     1.0003   [    -3.1847     5.7307 ]\n",
      "                         :    var17:  0.0058684    0.99716   [    -3.1847     5.7307 ]\n",
      "                         :    var18:  0.0063133    0.99922   [    -3.1847     5.7307 ]\n",
      "                         :    var19:  0.0065700     1.0004   [    -3.1847     5.7307 ]\n",
      "                         :    var20:  0.0066059     1.0007   [    -3.1847     5.7307 ]\n",
      "                         :    var21:  0.0062780    0.99938   [    -3.1847     5.7307 ]\n",
      "                         :    var22:  0.0064581     1.0003   [    -3.1847     5.7307 ]\n",
      "                         :    var23:  0.0073309     1.0038   [    -3.1847     5.7307 ]\n",
      "                         :    var24:  0.0063286    0.99916   [    -3.1847     5.7307 ]\n",
      "                         :    var25:  0.0062579    0.99904   [    -3.1847     5.7307 ]\n",
      "                         :    var26:  0.0057227    0.99696   [    -3.1847     5.7307 ]\n",
      "                         :    var27:  0.0062714    0.99930   [    -3.1847     5.7307 ]\n",
      "                         :    var28:  0.0063833    0.99946   [    -3.1847     5.7307 ]\n",
      "                         :    var29:  0.0061613    0.99898   [    -3.1847     5.7307 ]\n",
      "                         :    var30:  0.0065878     1.0004   [    -3.1847     5.7307 ]\n",
      "                         :    var31:  0.0059921    0.99788   [    -3.1847     5.7307 ]\n",
      "                         :    var32:  0.0061175    0.99802   [    -3.1847     5.7307 ]\n",
      "                         :    var33:  0.0068559     1.0015   [    -3.1847     5.7307 ]\n",
      "                         :    var34:  0.0063764    0.99921   [    -3.1847     5.7307 ]\n",
      "                         :    var35:  0.0061553    0.99833   [    -3.1847     5.7307 ]\n",
      "                         :    var36:  0.0065405     1.0006   [    -3.1847     5.7307 ]\n",
      "                         :    var37:  0.0065571     1.0005   [    -3.1847     5.7307 ]\n",
      "                         :    var38:  0.0073183     1.0034   [    -3.1847     5.7307 ]\n",
      "                         :    var39:  0.0063159    0.99897   [    -3.1847     5.7307 ]\n",
      "                         :    var40:  0.0065798     1.0005   [    -3.1847     5.7307 ]\n",
      "                         :    var41:  0.0061950    0.99865   [    -3.1847     5.7307 ]\n",
      "                         :    var42:  0.0060802    0.99827   [    -3.1847     5.7307 ]\n",
      "                         :    var43:  0.0057171    0.99680   [    -3.1847     5.7307 ]\n",
      "                         :    var44:  0.0066068     1.0009   [    -3.1847     5.7307 ]\n",
      "                         :    var45:  0.0062815    0.99917   [    -3.1847     5.7307 ]\n",
      "                         :    var46:  0.0069578     1.0019   [    -3.1847     5.7307 ]\n",
      "                         :    var47:  0.0063784    0.99968   [    -3.1847     5.7307 ]\n",
      "                         :    var48:  0.0060611    0.99819   [    -3.1847     5.7307 ]\n",
      "                         :    var49:  0.0062194    0.99939   [    -3.1847     5.7307 ]\n",
      "                         :    var50:  0.0061665    0.99889   [    -3.1847     5.7307 ]\n",
      "                         :    var51:  0.0060511    0.99818   [    -3.1847     5.7307 ]\n",
      "                         :    var52:  0.0064034    0.99948   [    -3.1847     5.7307 ]\n",
      "                         :    var53:  0.0057530    0.99664   [    -3.1847     5.7307 ]\n",
      "                         :    var54:  0.0059697    0.99799   [    -3.1847     5.7307 ]\n",
      "                         :    var55:  0.0065414     1.0003   [    -3.1847     5.7307 ]\n",
      "                         :    var56:  0.0060559    0.99780   [    -3.1847     5.7307 ]\n",
      "                         :    var57:  0.0066520     1.0007   [    -3.1847     5.7307 ]\n",
      "                         :    var58:  0.0060056    0.99810   [    -3.1847     5.7307 ]\n",
      "                         :    var59:  0.0063135    0.99967   [    -3.1847     5.7307 ]\n",
      "                         :    var60:  0.0066761     1.0006   [    -3.1847     5.7307 ]\n",
      "                         :    var61:  0.0057496    0.99669   [    -3.1847     5.7307 ]\n",
      "                         :    var62:  0.0063415    0.99935   [    -3.1847     5.7307 ]\n",
      "                         :    var63:  0.0060406    0.99807   [    -3.1847     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "dense layer string 64\n",
      "dense layer string TANH\n",
      "dense layer string 64\n",
      "dense layer string TANH\n",
      "dense layer string 64\n",
      "dense layer string TANH\n",
      "dense layer string 64\n",
      "dense layer string TANH\n",
      "dense layer string 1\n",
      "dense layer string LINEAR\n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 5  Input = ( 1, 1, 64 )  Batch size = 32  Loss function = C\n",
      "\tLayer 0\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,    32 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 1\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,    32 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 2\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,    32 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 3\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,    32 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 4\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,    32 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 8000 events for training and 2000 for testing\n",
      "                         : Training phase 1 of 1:  Optimizer ADAM Learning rate = 0.001 regularization 0 minimum error = 0.700282\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.572917     0.59987   0.0816112   0.0280681      149412           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.538109    0.581801   0.0808549   0.0280172      151407           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.520079    0.572355     0.08094   0.0280018      151120           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.510081    0.564322    0.081288   0.0280783      150349           0\n",
      "                         :          5 Minimum Test error found - save the configuration \n",
      "                         :          5 |     0.501746    0.561107   0.0808072   0.0279708      151411           0\n",
      "                         :          6 Minimum Test error found - save the configuration \n",
      "                         :          6 |     0.495357    0.561041   0.0807198   0.0275208      150379           0\n",
      "                         :          7 |     0.490628    0.561421    0.080604   0.0279345      151890           1\n",
      "                         :          8 Minimum Test error found - save the configuration \n",
      "                         :          8 |      0.48957    0.559212   0.0808595   0.0280348      151444           0\n",
      "                         :          9 |     0.484515    0.560547    0.081049   0.0280078      150826           1\n",
      "                         :         10 |     0.479971    0.562245   0.0808416   0.0279757      151326           2\n",
      "                         :         11 |     0.474744    0.563367   0.0813081   0.0280412      150187           3\n",
      "                         :         12 |     0.473604    0.568121    0.081075   0.0279825      150680           4\n",
      "                         :         13 |     0.471069    0.573738   0.0808889   0.0279406      151091           5\n",
      "                         :         14 |     0.466027    0.567819   0.0814312   0.0279458      149574           6\n",
      "                         :         15 |     0.461985    0.570403   0.0810095   0.0278908      150606           7\n",
      "                         :         16 |     0.458519    0.568608   0.0808994    0.028086      151477           8\n",
      "                         :         17 |     0.455361    0.573529   0.0811518   0.0281079      150819           9\n",
      "                         :         18 |     0.452852    0.567844   0.0807618   0.0279118      151372          10\n",
      "                         :         19 |     0.449538    0.571936   0.0813498   0.0284275      151165          11\n",
      "                         : \n",
      "                         : Elapsed time for training with 10000 events: 1.69 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 32\n",
      "                         : \n",
      "dense layer string 64\n",
      "dense layer string TANH\n",
      "dense layer string 64\n",
      "dense layer string TANH\n",
      "dense layer string 64\n",
      "dense layer string TANH\n",
      "dense layer string 64\n",
      "dense layer string TANH\n",
      "dense layer string 1\n",
      "dense layer string LINEAR\n",
      "DL_DENSE                 : [dataset] : Evaluation of DL_DENSE on training sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.0282 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_DENSE.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_DENSE.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DL_CNN for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU using (for ROOT-IMT) nthreads = 1\n",
      "                         : \n",
      "dense layer string 64\n",
      "dense layer string TANH\n",
      "dense layer string 1\n",
      "dense layer string LINEAR\n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 6  Input = ( 1, 8, 8 )  Batch size = 128  Loss function = C\n",
      "\tLayer 0\t CONV LAYER: \t( W = 8 ,  H = 8 ,  D = 10 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 128 , 10 , 64 ) \t Activation Function = Relu\n",
      "\tLayer 1\t CONV LAYER: \t( W = 8 ,  H = 8 ,  D = 10 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 128 , 10 , 64 ) \t Activation Function = Relu\n",
      "\tLayer 2\t POOL Layer: \t( W = 7 ,  H = 7 ,  D = 10 ) \t Filter ( W = 2 ,  H = 2 ) \tOutput = ( 128 , 10 , 49 ) \n",
      "\tLayer 3\t RESHAPE Layer \t Input = ( 10 , 7 , 7 ) \tOutput = ( 1 , 128 , 490 ) \n",
      "\tLayer 4\t DENSE Layer: \t ( Input =   490 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 5\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,   128 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 8000 events for training and 2000 for testing\n",
      "                         : Training phase 1 of 1:  Optimizer ADAM Learning rate = 0.001 regularization 0 minimum error = 0.757474\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |       0.6831    0.686241     1.47946     0.50908     8178.25           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.656533    0.663696      1.6366    0.571671     7452.17           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |       0.6281    0.643726     1.48716    0.510973     8129.58           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.600435    0.619522     1.49676    0.515906     8090.93           0\n",
      "                         :          5 Minimum Test error found - save the configuration \n",
      "                         :          5 |     0.586439    0.611772      1.4974    0.514961     8077.85           0\n",
      "                         :          6 Minimum Test error found - save the configuration \n",
      "                         :          6 |     0.573017    0.601936     1.54743    0.516115     7695.03           0\n",
      "                         :          7 Minimum Test error found - save the configuration \n",
      "                         :          7 |     0.567348     0.60016     1.50086    0.517852     8073.22           0\n",
      "                         :          8 |     0.570993    0.603984     1.50104     0.51675      8062.7           1\n",
      "                         :          9 Minimum Test error found - save the configuration \n",
      "                         :          9 |     0.553884      0.5962     1.50306    0.517749     8054.32           0\n",
      "                         :         10 Minimum Test error found - save the configuration \n",
      "                         :         10 |     0.549928    0.593777     1.51861     0.51776     7929.23           0\n",
      "                         :         11 Minimum Test error found - save the configuration \n",
      "                         :         11 |     0.540885    0.592034      1.5508    0.520602     7703.39           0\n",
      "                         :         12 |     0.537733    0.592229     1.61537    0.518643     7236.08           1\n",
      "                         :         13 Minimum Test error found - save the configuration \n",
      "                         :         13 |     0.532139    0.590646     1.61057    0.519143     7271.19           0\n",
      "                         :         14 Minimum Test error found - save the configuration \n",
      "                         :         14 |      0.52767    0.582445     1.59742    0.518851     7357.93           0\n",
      "                         :         15 |     0.527868    0.587047     1.61246    0.518571     7254.84           1\n",
      "                         :         16 |     0.523042    0.589048     1.57948    0.519172      7484.6           2\n",
      "                         :         17 |     0.529746    0.595345     1.61816    0.524883     7258.91           3\n",
      "                         :         18 |     0.519058    0.586361     1.61496    0.545755     7422.37           4\n",
      "                         :         19 |     0.514636    0.586102     1.63121    0.531559     7216.85           5\n",
      "                         :         20 |     0.512826    0.585341     1.70219    0.615613     7303.66           6\n",
      "                         : \n",
      "                         : Elapsed time for training with 10000 events: 31.4 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 128\n",
      "                         : \n",
      "dense layer string 64\n",
      "dense layer string TANH\n",
      "dense layer string 1\n",
      "dense layer string LINEAR\n",
      "DL_CNN                   : [dataset] : Evaluation of DL_CNN on training sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.541 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_CNN.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_CNN.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: PyKeras for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ PyKeras ] :\u001b[0m\n",
      "                         : \n",
      "                         : Keras is a high-level API for the Theano and Tensorflow packages.\n",
      "                         : This method wraps the training and predictions steps of the Keras\n",
      "                         : Python package for TMVA, so that dataloading, preprocessing and\n",
      "                         : evaluation can be done within the TMVA system. To use this Keras\n",
      "                         : interface, you have to generate a model with Keras first. Then,\n",
      "                         : this model can be loaded and trained in TMVA.\n",
      "                         : \n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "                         : Split TMVA training data in 8000 training events and 2000 validation events\n",
      "                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored\n",
      "<WARNING>                : Failed to run python code: history = model.fit(trainX, trainY, sample_weight=trainWeights, batch_size=batchSize, epochs=numEpochs, verbose=verbose, validation_data=(valX, valY, valWeights), callbacks=callbacks)\n",
      "<WARNING>                : Python error message:\n",
      "\u001b[37;41;1m<FATAL>                         : Failed to train model\u001b[0m\n",
      "***> abort program execution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 18:14:47.174643: I tensorflow/stream_executor/platform/default/dso_loader.cc:161] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "2019-06-17 18:14:47.369240: I tensorflow/stream_executor/platform/default/dso_loader.cc:161] successfully opened CUDA library libcudnn.so.7 locally\n",
      "2019-06-17 18:14:47.762236: E tensorflow/stream_executor/cuda/cuda_dnn.cc:482] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2019-06-17 18:14:47.768434: E tensorflow/stream_executor/cuda/cuda_dnn.cc:482] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n"
     ]
    }
   ],
   "source": [
    "factory.TrainAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Evaluate Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factory.TestAllMethods();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factory.EvaluateAllMethods();    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve\n",
    "We enable JavaScript visualisation for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//%jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1 = factory.GetROCCurve(loader)\n",
    "c1.Draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## close outputfile to save output file\n",
    "outputFile.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
