{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tmva_logo.gif\" height=\"20%\" width=\"20%\">\n",
    "\n",
    "# TMVA Classification Example Using a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Factory\n",
    "\n",
    "Create the Factory class. Later you can choose the methods\n",
    "whose performance you'd like to investigate. \n",
    "\n",
    "The factory is the major TMVA object you have to interact with. Here is the list of parameters you need to pass\n",
    "\n",
    " - The first argument is the base of the name of all the output\n",
    "weightfiles in the directory weight/ that will be created with the \n",
    "method parameters \n",
    "\n",
    " - The second argument is the output file for the training results\n",
    "  \n",
    " - The third argument is a string option defining some general configuration for the TMVA session. For example all TMVA output can be suppressed by removing the \"!\" (not) in front of the \"Silent\" argument in the option string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMVA::Tools::Instance();\n",
    "\n",
    " // for using Keras\n",
    "gSystem->Setenv(\"KERAS_BACKEND\",\"tensorflow\");\n",
    "// for setting openblas in single thread on SWAN\n",
    "gSystem->Setenv(\"OMP_NUM_THREADS\",\"1\"); \n",
    "TMVA::PyMethodBase::PyInitialize();\n",
    "\n",
    "\n",
    "\n",
    "auto outputFile = TFile::Open(\"CNN_ClassificationOutput.root\", \"RECREATE\");\n",
    "\n",
    "TMVA::Factory factory(\"TMVA_CNN_Classification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" ); \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare DataLoader(s)\n",
    "\n",
    "The next step is to declare the DataLoader class that deals with input variables \n",
    "\n",
    "Define the input variables that shall be used for the MVA training\n",
    "note that you may also use variable expressions, which can be parsed by TTree::Draw( \"expression\" )]\n",
    "\n",
    "In this case the input data consists of an image of 16x16 pixels. Each single pixel is a branch in a ROOT TTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMVA::DataLoader * loader = new TMVA::DataLoader(\"dataset\");\n",
    "\n",
    "int imgSize = 8 * 8; \n",
    "for(auto i = 0; i < imgSize; i++)\n",
    " {\n",
    "     loader->AddVariable(Form(\"var%d\",i),'F');\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset(s)\n",
    "\n",
    "Define input data file and signal and background trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree sig_tree of type Signal with 10000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree bkg_tree of type Background with 10000 events\n"
     ]
    }
   ],
   "source": [
    "TString inputFileName = \"images_data.root\";\n",
    "\n",
    "//TString inputFileName = \"tmva_class_example.root\";\n",
    "\n",
    "auto inputFile = TFile::Open( inputFileName );\n",
    "\n",
    "// --- Register the training and test trees\n",
    "\n",
    "TTree *signalTree     = (TTree*)inputFile->Get(\"sig_tree\");\n",
    "TTree *backgroundTree = (TTree*)inputFile->Get(\"bkg_tree\");\n",
    "\n",
    "// global event weights per tree (see below for setting event-wise weights)\n",
    "Double_t signalWeight     = 1.0;\n",
    "Double_t backgroundWeight = 1.0;\n",
    "   \n",
    "// You can add an arbitrary number of signal or background trees\n",
    "loader->AddSignalTree    ( signalTree,     signalWeight     );\n",
    "loader->AddBackgroundTree( backgroundTree, backgroundWeight );\n",
    "\n",
    "\n",
    "// Set individual event weights (the variables must exist in the original TTree)\n",
    "//    for signal    : factory->SetSignalWeightExpression    (\"weight1*weight2\");\n",
    "//    for background: factory->SetBackgroundWeightExpression(\"weight1*weight2\");\n",
    "//loader->SetBackgroundWeightExpression( \"weight\" );\n",
    "\n",
    "// Apply additional cuts on the signal and background samples (can be different)\n",
    "TCut mycuts = \"\"; // for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "TCut mycutb = \"\"; // for example: TCut mycutb = \"abs(var1)<0.5\";\n",
    "\n",
    "// Tell the factory how to use the training and testing events\n",
    "//\n",
    "// If no numbers of events are given, half of the events in the tree are used \n",
    "// for training, and the other half for testing:\n",
    "//    loader->PrepareTrainingAndTestTree( mycut, \"SplitMode=random:!V\" );\n",
    "// To also specify the number of testing events, use:\n",
    "\n",
    "loader->PrepareTrainingAndTestTree( mycuts, mycutb,\n",
    "                                    \"nTrain_Signal=0:nTrain_Background=0:SplitMode=Random:NormMode=NumEvents:!V:!CalcCorrelations\" );\n",
    "\n",
    "\n",
    "\n",
    "//loader->PrepareTrainingAndTestTree(mycuts, mycutb,\n",
    "//                                   \"nTrain_Signal=5000:nTrain_Background=5000:nTest_Signal=5000:nTest_Background=5000:SplitMode=Random:NormMode=NumEvents:!V\" ); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "*Tree    :sig_tree  : signal_tree                                            *\n",
      "*Entries :    10000 : Total =         2601382 bytes  File  Size =    2572423 *\n",
      "*        :          : Tree compression factor =   1.00                       *\n",
      "******************************************************************************\n",
      "*Br    0 :var0      : var0/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    1 :var1      : var1/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    2 :var2      : var2/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    3 :var3      : var3/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    4 :var4      : var4/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    5 :var5      : var5/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    6 :var6      : var6/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    7 :var7      : var7/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    8 :var8      : var8/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    9 :var9      : var9/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   10 :var10     : var10/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   11 :var11     : var11/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   12 :var12     : var12/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   13 :var13     : var13/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   14 :var14     : var14/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   15 :var15     : var15/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   16 :var16     : var16/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   17 :var17     : var17/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   18 :var18     : var18/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   19 :var19     : var19/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   20 :var20     : var20/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   21 :var21     : var21/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   22 :var22     : var22/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   23 :var23     : var23/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   24 :var24     : var24/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   25 :var25     : var25/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   26 :var26     : var26/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   27 :var27     : var27/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   28 :var28     : var28/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   29 :var29     : var29/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   30 :var30     : var30/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   31 :var31     : var31/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   32 :var32     : var32/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   33 :var33     : var33/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   34 :var34     : var34/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   35 :var35     : var35/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   36 :var36     : var36/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   37 :var37     : var37/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   38 :var38     : var38/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   39 :var39     : var39/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   40 :var40     : var40/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   41 :var41     : var41/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   42 :var42     : var42/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   43 :var43     : var43/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   44 :var44     : var44/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   45 :var45     : var45/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   46 :var46     : var46/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   47 :var47     : var47/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   48 :var48     : var48/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   49 :var49     : var49/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   50 :var50     : var50/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   51 :var51     : var51/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   52 :var52     : var52/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   53 :var53     : var53/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   54 :var54     : var54/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   55 :var55     : var55/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   56 :var56     : var56/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   57 :var57     : var57/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   58 :var58     : var58/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   59 :var59     : var59/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   60 :var60     : var60/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   61 :var61     : var61/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   62 :var62     : var62/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   63 :var63     : var63/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "signalTree->Print();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve input data in RTensor and display the images in histograms\n",
    "\n",
    "Here we look a bit in detail at the input data. This part works only from ROOT 6.19 when the RTensor class is available. Comment the code if using an older version of ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTensor from an RDataFrame: signal shape  10000 , 64\n",
      "{ -1.33602, 0.763283, 3.08255, 0.815374, 3.81662, 3.78427, 1.48386, -3.87061, 3.52775, 1.09557, 7.2729, 2.21868, 4.30041, 1.48883, -0.0424709, 2.54318, 4.5934, 6.72167, 14.5167, 0.897466, 7.66562, 4.53779, 7.88184, 9.74405, 0.461908, 3.82695, 11.4029, 17.0113, 16.5522, 7.20274, 3.0214, 6.5347, 1.29067, 6.19094, 11.1869, 19.6573, 14.4336, 10.8884, 17.5525, 2.41406, -2.25424, 17.0368, 12.2523, 14.9787, 14.5866, 21.2678, 14.3112, 1.0875, -1.18294, -0.090627, 12.282, 19.8801, 20.8239, 14.439, 7.0565, 6.84566, 2.38257, 0.955573, 8.58011, 18.4141, 15.4364, 14.0098, 7.34024, 11.7768 }\n",
      "\n",
      "RTensor from an RDataFrame: background shape  10000 , 64\n",
      "{ 2.49465, 1.4486, 5.01446, 5.50642, 5.91146, 2.3508, -2.1928, 2.9917, -2.38139, 2.3669, 8.64252, 1.18982, 11.6599, 6.8741, 6.89608, 6.72187, 6.719, 6.79918, -1.02196, 6.508, 7.37875, 8.59778, 9.79674, 4.28794, 3.3485, 3.04003, 5.16267, 10.7613, 21.3826, 8.01421, 17.7452, 6.13103, 2.28209, 2.74367, 11.5273, 12.519, 13.627, 14.622, 9.79326, 3.13431, -4.06637, -1.89229, 10.7148, 12.607, 17.3665, 19.1926, 12.6434, 9.67554, 2.98344, 3.99151, 11.6107, 14.9112, 15.1564, 1.51657, 10.8333, 10.3266, 1.05594, -1.78092, 7.99795, 9.50336, 6.70046, 5.75394, 16.2055, 11.7857 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ROOT::RDataFrame dfs(*signalTree);\n",
    "ROOT::RDataFrame dfb(*backgroundTree);\n",
    "\n",
    "std::vector<std::string> varNames = dfs.GetColumnNames();\n",
    "\n",
    "auto signalTensor = TMVA::Experimental::AsTensor<float>(dfs);\n",
    "auto backgroundTensor = TMVA::Experimental::AsTensor<float>(dfb);\n",
    "auto shapeS = signalTensor.GetShape();\n",
    "auto shapeB = backgroundTensor.GetShape();\n",
    "   \n",
    "auto firstEventS =  signalTensor.Slice( { {0,1}, {0,64} } );\n",
    "auto firstEventB = backgroundTensor.Slice( { {0,1}, {0,64} } );\n",
    "std::cout << \"RTensor from an RDataFrame: signal shape  \" << shapeS[0] << \" , \" << shapeS[1] << \"\\n\" <<  firstEventS << \"\\n\\n\";\n",
    "std::cout << \"RTensor from an RDataFrame: background shape  \" << shapeB[0] << \" , \" << shapeB[1] << \"\\n\" <<  firstEventB << \"\\n\\n\";\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAHYCAIAAAApvgy/AAAABmJLR0QAAAAAAAD5Q7t/AAAgAElE\nQVR4nO3df6wmV3nY8XN2Q3Bi1wt2gVLitEYldWJCrchrKmHeObN31xJF/sOoMpDIyIgoUo2sKpaq\nWv5xZ2bv0ggJG1WYjYJEHdlSg1Dk/lFSk+x6Z+au3QqvW7mNqVOMsMi2Mhj5J3VxWGD6x5N7OJ55\nz7vz3jtnfrzv96Or1dy588458+57nveZOWfO6KqqFAAAwDz7hq4AAAAYLxIFAADgRaIAAAC8SBQA\nAIAXiQIAAPAiUQAAAF4kCgAAwItEAQAAeJEoAAAALxIFAADgRaIAAAC8SBQAAIAXiYJXmqbGmDRN\ni6JwV7q/7lFRFGmatlnZP1sHW59ujz2coigmUU/0L32jXX9OxtBCrdGGEbcOhJFpq9CQ53ntXUqS\nRP6klIqiqKuCkiRp/hfMXdmzKIrkMO1bIQvtjz1JEvum9cMtcfA3EOPUDIC7aM7SFvI8775+uzI3\nYkRRNHgrsJFTaij1Weqti6Ko5/fZhhH5X+6z6DHjjZijFj7kUy6f124/tb6cYPAYZI/XreFSteo2\no2rDjYw20QFcC5p2e5NIFPI8H7aG7het2zaXDSM9n2+4n5D+Sx8tuh7mM8bYZfcKnns9qigKY4wx\nRhZkvSxIt4VdafeptZbujAVFu9fr7M7tq+xO3O3tylovSbN67npfNYwxURTJS7Iss++GPXa5eJim\nqda6dmh2A6VUWZZzi2i+Oc03yv1T7dDsdWN3J2malmVpq2p/BRZw25Ha+WTW2pea94mt7cR+zmuN\nTu00T7cNug3WLcJtLM140qzV3KpatrXKy91gZSvgltjm2GsVXvCeKKXiOJYMptk23UOTncx9W2Qh\ny7K5YaQWGWrVc9/DPM+bh2bmBepa4EqSRAIguKIwh7wzSZI0k1+1k2/aS/GSLKud3FOW3fXuPu16\n94pcrQi70l72t7tq7qFZDXcnzerV1s897a7t3G7mLtTWu5WsnCuNzXzclusehVsT93SttmdZ6R6R\nXW+XORvAArVPmnum22wyst5+Yu2HrfkRrW3pbmw/me5ra+2lalzqaDYBXzyxO68dqT00tzG6LVc2\ncC8cLjj2uW2w1oqbb7W7czdcuIemdiJt822pxa7azuf+p9gtbRQ9deqU7w1vHnItcI3t0tGASBTm\nqI1RcPvJVONb027vJgru+lpkcV/bJlGYOzzC3YPvK7bWZmz17HpfJ5xbVbeG6o2ZQbPQyulTVG8M\nfL6N3YhQW1l7c+wO3Y3dI2qun5sGYZ2pBtscoihqfs3Mbbl25eKGoJxEwS1l7qdU+RMFu97Wqtk0\nmg251o5sz2ktpNi2c95jt0dUW+/r+HBXuke9+NCqnQSuVkOXLzLMjZCSCrgbLwjU1bz/CM43qqr6\nhWbLgTGmqiq1c5WsLMs4juX6lbuZ20HgrnfTfHeH9hrgspVpLtsipA5yOdFeJbNX9uw28if3UqTd\nZ+2SXcvq2QrIa+M4jqLovEdnK1DbLE3TOI6lJmVZSiCQOrtVXao3IYoieh/QJB9UWbZNw3505U++\npiRhQVbGcayc0/TalvJJtoXaEsuydONDm0+pu0/bkN2dtLlCPjeMWG2O3R5RrRXPbfItw0jt0LTW\nSZIs6M4Qvshg34daP4L7P+7WrRmo4UOiUCcNwN7JIyulP89+whZ/juf2Gkp3fucfTRvpJHFeHHSa\n9ffVx9fxOVdVVVINCZ3NjKpWAffdkwrYzsva2+6rKi0ce2E/n0VRaK2lF9x+EbpNaUFLlw/hgh50\n35f3Uo1rrlq2sXdzj725Te18w/5p75UxxuR5LmEky7Iois6bajQjg7y8ef7mHk4URbUxEOe17Knd\nSmIw4xxZlrVJBdp/gOSzKxcVuv3YSaOylyvc6lm2RHcwkbAjiWraV1LKTdO02rmC5xsjqZz3zWZj\ntvQkSWQMkW32ErPmbtwS+QTak0tZ0pR83yVue3EH5TX3tqAFuX+a+5V/3tZX+y7fe0iZe+y+Wi1o\nxbtm9yZhxDcOWiyODEVRZFnmDshIksSNeMuGhb0f3QogUaiz19Jt4pzu3G7gbhZFkc0nlspMw+Wn\ntaZlD0FO9JWTKNhfmyc9y+ZAyn9S5auhLcLW0K50A4QMlrZ9K/YoWirLkhaOudId8gmRLxL718Lp\nxat9YpsfKpvg1rb0XU6Q7Qvn2rj86373n7c1uS+UWrU4aK+Wx+5b77Zia9kwIvt3I+SCxrsgMsjb\nq5z3UPoj7DnMLu5iIIwoxV0PHrV3yTeiULhDf1VjtGBtiK+7fZvBjO5AKndIlDsc0t2tcgYNuevd\n0UzW3AG97vAf32BGd7xPLUN3X9g8uloFmu95862wR9Gsnvu21Er0HR3WWTMA1oYZNpuS+4mNnDue\nmmNya1uqeQMPmwXJyuZrm6OS3RGCzYZfO9K5FfCFlJbHXtvP3FbsvtVzh3DOPbSqESHdlc1RyXMj\ng31JbU1tPEezeu7b0jz8uUe3bngXvPIdc/8qt/TYDVSLryV3b91+h7l7y3duSbLF1aJDrSZz97Zs\n85j7Xi0oZXEFdr2x3XJuBgYsVmuh7ZuMsPfUVS0+gXP3tmxY6DCMzD32xUe0+D2Zm760r4O7cqnt\nfU6dOrVsNWrnJOuMYLpL7s1Cu2gSoUlSLNVbkPUvePmkbwqaev0xRWrn5sl8yfnOR2uPR9Tm9GnM\npl7/Do3r621a3CtaI/w8uaMCl33tLi4qjMekK4/pyhudFFO3xyNyZ3mZnMiZWwK6mtdvBwAAoLjr\nAQAALECiAAAAvEgUAACAF4kCAADwIlEAAABeJAoAAMCLp0cCi8hjP1cD90IDe7eGMYFEATiP1fh+\nXaXoBgxr3WICXQ8AAMCLRAEAAHiRKAAAAC8SBQAA4EWiAPStKIqhqwBgLJoBYWwhgkQB6FVRFHEc\nD10LAKPQDAhpmo4tRJAoAAAALxIFYAB6R+3XNE0HrReAAdQCgrtmDN0QJArAAPI8lzlb0jSV5KCq\nqjzPsywbuGYAeucGBHdNFEVjOHkgUQAGYIxRSkVRZJeNMUVRrMaMbwCW4gYEd02apmVZDlSpnyNR\nAAZmjKmqyhiTZRkTLQMYmz4ShTRNpa9FUiQALmkgaZrK5YQxdEmGRkwAFpM4kKape5lhKMEThaIo\nsizL8zzP87Is1yEIAkuRPkj54oyiaOW/O4kJwHnFcay1LstyDGMUenp6pI19RVGsfBwEFpCOBlm2\n35FVVa1b0yAmAMoTECQ5GE/T0D0MnnK7XW1xC/pif+2DX+mk3O/dcEUn+1ns8HuDjzQ589q7Qxeh\nlHrl2ctCF7H/7AWhi7ho9ky3Ozx7w/WrMcBQ6z4ae0vLxoSL732yk3IPXH62k/0s9oMX3xm6iLdd\n8lzoIlQvMaGH+Hn5/pe63eE9G+l4mtJetI8Jwa8oSIqUJIlSKssyN0XqKiEAMCELYkJXCQGADgVP\nFGQshr2QkqYpXZLAOiMmANMSfDCjMcbeBjqG+0GBZemVMPS7+HPEBEzd0K25G+2PN3ii4I7oVutx\n6xdWTLUShn4Xf46YgKkbujV3o/3x9jGPgtTJTlEJYM0RE4AJ6W9mxpHc5gFgJIgJwCQwhTMAAPAi\nUQAAAF4kCsAqsA+MsGuWGtUMYMV0GBOGTBS+dfpj9mfAagBt2OcYzb2z6Pbbb//a175mf+35S7oo\nCnlEtb2DYAwPktmFV2+7yv4MXRfgPNYnJvT0rIe5mJkR0xJFkXsvn03V0zT97Gc/++ijj1500UXu\ntIPSVu2W7r/dKoqiLEuttZR79913d15EP5iZEdOyJjGBrgegrbIsjTHGGJlMMMsytTMJsWyQpmmW\nZcYY+VMcx2pn8kEZ4S/LnVdMKpDnuVTm2LFjs9lMTTljACZhTWLCkFcUgMmpNWmJDkVRfOADH7j9\n9ts/97nPJUli27/ayeuVUhIp7NTF3ZISjTFRFJ07d242m21vbyul5F8A4axDTCBRANqKosh9OPLc\nPr/a3ADu6UKe5/IApM7nIrR9pVLikSNHlFJaayZIBoJak5hAogC0JX1+spznufuna6+99vrrr3fD\nhOTysn1VVWmaylVH6TLsXHOKQyY9BEJbk5gw2CPqtdahBzN+74Yrgu5f9PA89TOvvTt0EaqXZ8/v\nP3tB6CIumj3T7Q7P3nD9anzjSni65ZZbvvjFLw5dl/m01qEHMx64/GzQ/YsfvPjO0EW87ZLnQheh\neokJPcTPy/e/1O0O79lIVyYmtDwQBjMC6+L+++8/fvz4H//xHw9dEQBTQqIArIubb7754MGDx48f\nH7oiAEZBa/3pT3/6vJsNOUbBnWeJORWAHow8UXDnWWJOBSC0+++//5Of/OTBgwdvvvnmBZsx4RKA\nsSA5APp08803Hz9+/Pjx44sTBboegDVy5syZgwcPDl0LAGNx8ODBM2fOLN6GRAFYIyQKAJZFogCs\nC631wYMHR3t7JID+tTl5YMIlYF2sxs3fADp05syZW265ZfE2XFEAAGAdtbzKyBUFAADWETMzAgCA\nvRoyUfjW6Y/ZnwGrAYxfURT22TPCGKO1lsfQbW5uypPiTp48qZSS5RDPrg3t1duusj9D1wUYtWZM\nUDuPdFE7T4+0j7feY0wYMlH4tQ9+xf4MWA2gDflilmVpeJ0/GXYBecqcJQ2+qiqpw9bWVlVVd999\n99bWljEmSZKqqrIs6616Xbn43iftz9B1Ac5jVDHBzRuKosiyrKoqY0yapmma7jEm0PUALEECgZuY\n33nnnXfeeacsS5uUbe7e4b62+fI25Lu/Vg15vq2cMZw4cUIpJU+aT9M0yzJ5oO2SBwdgaSOJCcaY\nuQMOpAhjzF5iAokCsARpz/KVrHYu9J0+fXo2m9lwIJn+sWPHlFLb29s2Lhhj4ji2m7UkOYFdtuuj\nKMrzPMuyoigOHz4sNSnLsiiKKIqMMfZVAMIZT0ywJCfQWttLCJIo7DomkCgAbSVJYr+J7crTO9I0\nNca47XZra+uuu+7a3t529yBf7UuVG0WRvMS+0OyQX7XWJ06ckCiQZZmcxChPEAHQlfHEhKaqqpIk\nkf6Roij2EhO4PRJYQhRFcRzneW47CLe3t7/+9a+fPn1avrnnjjCyJMG3X+Rt2EAjY5Hk5ENKybIs\niqKf/OQnSqkjR47I9rZucl1htwcKoJXxxITaZlKojFTYY0wgUQCWkKZpHMe2sd1xxx3SGh9++OE3\nvelNWZbZZj/3tXIesLvhx9IBaV/o9kfW+iaZgRHozXhignLavps3+IYvtKeHiila69A3O3zvhiuC\n7l8cfm/wnuAzr707dBFKqVeevSx0EfvPXhC6iItmz3S7w7M3XL8a37taD9bYW9Jah77Z4cDlZ4Pu\nX/zgxXeGLuJtlzwXugjVS0zoIX5evv+lbnd4z0Y68qbUUvuYwBgFAADgNWTXgzvPElMpAHDnWWIq\nBWAkhkwUSA4AuEgOgBGi6wEAAHiRKAAAAC8SBQAA4EWiAAAAvEgUAACAV/BEQSaadoUuEcCYEROA\naQl+e6Q7kaTWuvZkTADrhpgATEt/XQ+7e+o2MBJyHizLMjd7n89mbD5XRupjG5T7UBk5TR//oyOJ\nCZi0YWNCn/qbcEmer+WucWdmdF2afrOTEvef3d/JfhZ75tcvCV1EDzOuK6Ve3Pid0EU89f33hS7i\n+td+O+j+i6IwxrjfbXfeeadS6jOf+Yza+c6TR8bZR85vbW3JgjxzVl6+7LejfTCd3ZVSqqoqyRXk\nSfNyam6MSZIkTdPxP9yhGRPcmRldb//IE90UeXk3u1nsn132WOgivvqOL4UuQil144W/F7qIm/c9\nFbqIUr0r6P6Higm29DiOay3dPk8ySZKjR48qpR555JFDhw6p3T7zpacrCvKMrNoDLi9Nvzn3p58q\nAbsgjbks//ZJNnI+cfr06dlsJo1T7XypHzt2TCm1vb1to4N9uTxNrj357nfXSGyyyxIR3O3tn5Yq\nqE9zY8LbP/LE3J+B6gic3yAxwaqdQiiliqKwezt69GhVVZubm0ePHl38tOvFekoUsizb3WOwgfFI\nkqQsy6IooiiyK0/vkJMD97t5a2vrrrvu2t7ell/TNC3LUr4g2xdaFIWNQW2++OWht+MfIUhMwAoY\nJCZYzVMIpVQcx3ZvjzzyiNpJYvbysOn+xijQE4kVEEVRHMfuh3l7e/vhhx++44475GvvvN/lWZYt\n2xbkifXuzt2v2NrXbVEUeZ5LRBj5NzExAStgkJigPKcQxhg35zh06JCcM+zx4mIfiQLhACvD9jjK\nr3fccYfW+kMf+tAHP/hBY0yWZdIsfZ95O4ygfYlyRmLH/ck5SpqmUlbzRMQYI1cUxnw3ATEBK6P/\nmGD5TiHKspTrHFrrRx55ZO9dkIMNd9Jahx6O8LNX+hjM+CvXnQldxHef/s3QRSgGM3qcveH6DtuI\nHbjU1Q7bG//YRq116OEIb77puaD7Fwcv/E7oInoazPj9lRjMqDsezHjPRjqqmCBN2w5gVDuDGTc3\nNzc2NuxmUmc3DrSPCUM+ZhpYK9wNCMDVSUyQL3t3J3a5mQfsLsVhCmegJ7VhTQDW3FRiAokCAADw\nGrLr4YX0SrvM9AkAnn/oarvM9AnASAyZKJAcAHCRHAAjRNcDAADwIlEAAABeJAoAAMCLRAEAAHiR\nKAAAAC8SBQAA4EWiAAAAvIZMFF5Ir7Q/A1YDaG+o+Vabj40xxmit3ZXykDrf9pPw/ENX25+h6wK0\nMkhMSNNUa+02efXGmLC5uSkbnDx5Uikly7uOCUMmCpem37Q/A1YDaEOe2Srts/ZgWaXUiRMn7BOf\nZUuxu6fH1mit7YPnhVSgqqosy+w2blVr20/F2z/yhP0Zui7AeQwVE4qiyLKsqqokSezeajFha2ur\nqqq77757a2vLGJMkifxpd2kNXQ9AK0VRyNPf8zwviiJNU3niu4SDY8eO1bavqsp9qluapvLs11On\nTp06dUopZRfsNvYpsc1d2YgjjDFlWdoYkSSJu0Ecx7XtAXRuqJhgjMnzXP5qg0Bt+cSJE0opOWGw\nBak3pjLtkSgArdjvZmm6tr1dd911s9lse3vb9yqJINJK4zhWSslD4t1Hxcs2cRy3bMYSoWTjU6dO\nHT16dHNzU5aNMZIlTOKpdMB0DRsT5CKirzfh8OHDsoHUUHYl6cUuDPmsB2BCjDFVVUnr1VrLmcG5\nc+dms9nW1tZsNmueQFi2g0AptW/fPqWUnDccOnRIVsqVySRJWlZGolKaprLnKIqOHj2qlJJ/1c6Z\nhBu8AHRrwJgg3/pu664ta61PnDhx+PBhpZQkJVK93SFRAFoxxsh3szRgu17OG3xnD/arWl4rO4mi\naGNjQ64BCDktyLLsvKONpAJyfiCx5tChQxJctNb2KkKzxxRAt4aKCe6lCLmyKJc0tNZZlkVRJAMY\njxw54r5KalhLL1oiUQBase1QKWXT/Mcee2w2m0kLnM1m7vayMkkSiSPyvS6dApubmxsbG+4phQxN\nksAxN1eoZQBKqeb5gbtmirc8ANMyVEyQKxnN+rgr93L9oIlEAWir1vbccUmuZjOurTl06NDcXTGq\nAJiWNYkJDGYEAABeQ15RcOdZYioFAO48S0ylAIzEkIkCyQEAF8kBMEJ0PQAAAC8SBQAA4EWiAAAA\nvEgUAACAF4kCAADwIlEAAABeJArAEkYyURqAkViHmECiALQi87rLY+Kaj1ySJ9C7WwoeywSsqmFj\ngjwGorbG1kQp5T4kQore9SNghkwUXkivtD8DVgNooyiKKIqKosjzXJ7fWJZlURQSDprPk62qyp34\nXRptURSnTp2S58naBbuNPAJubum1oCARodb45ZEz2jG5c53nH7ra/gxdF+A8BowJWmt5lLwl21dV\nJU+WMsbYR0wZY5IkkT/tLiYMmShcmn7T/gxYDaANY0xZlvaJrva04LrrrpvNZr5Hysr2Eg7UzpNh\nNzY27L9CmrTdrKYZFOTp8m7QsU+5lfV5nqsJPmb67R95wv4MXRfgPAaMCVVV2csVtcrIr0VR2Ada\n2oxE7TYm8PRIoBV52pu0cK21fEmfO3duNpttbW3NZrPmCYTlPj123759Sik5bzh06JCsjKLIno40\nXy5Pm51bJYkFm5ubtcCUpqnkCgACGTAmNMnlDUkXmvVM0zTLsl3HBBIFoBVjjLQ36W606+Xr2Xf2\nYM8z5LWykyiKNjY2Njc37WZpmsZxXDtFWKwoCgkiJ0+e3NraOnHixJEjR06ePHn48GH50+QuJwDT\nMqqYILuVhMC9vKF2LkvUHmO9FAYzAq0URZFlmfT922t6jz322Gw201o3Tx3swCW57ievlT9JOHBP\nKaRVLzXUyL20KGcwSin5N01T+ycAgYwkJki24e6wdpKQZVlZlnsZt6T3kmXshdY69NCEn72yP+j+\nxa9cdyZ0Ed99+jdDF6GUenHjd0IX8dT33xe6iOtf++1ud3j2hut7aCNFUcRxvKAge+4iJwdyBpPn\nuRsR7MXP5p/cv46W1jr00IQ33/Rc0P2Lgxd+J3QRX33Hl0IXoZS68fu/F7qIm/c9FbqIUr+r2x3e\ns5GOISbsXfuY0McVBXtnCNdCgbnOO6RA+kGVM7ipOXDBtnnfmAZphrfeemsndd4LYgKwWD/DjFrG\nhD7GKMRxLAccx7F7ZycA0c99jOO5okBMABYbVUwInii401CMJ04Ba+jBBx+86aabhq4FMQEYi5Yx\nIXi3pXu3hsxN8bcFO2NEay74cjf9lBee/aVO9rPYa5f9KHQRb7ukj47VGy/+r6GL+DfX3hu6iKfL\nD3e7w6uu+5PV+DKzLe6BBx4YNl3YRUy4+N4nOyn6wOVnO9nPYm+54OUeSunBg/v/U+gifuO9p0MX\n8c4v/Xm3O3whvXLdYkJPt0fK0CqZRc5eZuwqIQDQRlVV73//+++7774xXFeYGxO6SggAtNEyJgRP\nFOwNo+qNZw/AVCw4052ca6655r777hu2DsQETN26xYQ+EgV7b2hZltzejWl58i8+Pki50uXx308s\ncben20vy4IMPfuITn5Bfb7311vvuu0+WH3/88WuuuSZEhdsjJmDS5t7Y/+N//ELocn/48dleYsJX\nv/rVj370o7uLCX0kClEU2fyL4c1Az77whS88/vjj7sMghq0PMQEY1rIxoad5FOQpNYNHKGBN3HTT\nTW5z+8Y3vlFV1QMPPDCSNkhMAHp244037jom9DeFMzOrAMMawxhGFzEBGFbLmMCzHgAAgBeJAgAA\n8BryMdOvf+pqu8ycCgBeve0qu8ycCsBIDJkokBwAcJEcACNE1wMAAPAiUQAAAF4kCgAAwItEAQAA\neJEoAAAALxIFAADgRaIAAAC8mHAJGK+/3nfR0FXoFRMuAYsNEhOYcAnAWJAcACNE1wMAAPAiUQAA\nAF4kCgAAwItEAQAAeJEoAAAALxIFAADgRaIAAAC8SBQAAIAXMzMCGAtmZgRGiJkZAYwFyQEwQnQ9\nAAAALxIFAADgRaIAAAC8SBQAAIAXiQIAAPAiUQAAAF4kCgAAwIsJl4Dx+ut9Fw1dhV4x4RKw2CAx\ngQmXAIwFyQEwQnQ9AAAALxIFAADgRaIAAAC8SBQAAIBXH4mCdqRp2kOJAMaMmABMSE93PeR5bozp\npywA40dMAKYi+BWFoihqCwDWGTEBmJbgVxQkFsRxLL9WVWX/5E645OpqfoXXLvtRJ/tZ7D1//+nQ\nRfyXi/8wdBFKqW+/9g9CF/F0+eHQRfx69Gehi1BKfe8/X9tDKatqQUxwJ1xy/Z0/2e6k6H994FQn\n+1nsj/7mt0IX8cShT4cuQin156c/GrqIf/Tsr4Yu4r9F/yp0EUqpa1/+F6GL+GHoAvyCJwpmh1JK\na22MsacRTLgErKEFMaGrhABAh/pIFOxyFEWhiwMwcsQEYFqCj1FI01RrLctlWTJ8CVhzxARgWvpI\nFNTO3VBRFHErFLDmiAnAtPRxe6Q7WAkAiAnAhDAzIwAA8CJRAAAAXiQKAADAq6cpnOdyJ1xiTgWg\n6dnqwNBV6NUPPz6zy8ypADQNEhOGTBRIDgC4SA6AEaLrAQAAeJEoAAAALxIFAADgRaIAAAC8SBQA\nAIAXiQIAAPAiUQAAAF4kCgAAwIuZGQGMBTMzAiPEzIwAxoLkABghuh4AAIAXiQIAAPAiUQAAAF4k\nCsAKKopCa137VWudpulwlQIwmL3EhCEHMwIIwRhTlqW7Jo7jPM9lwRhjjBmmZgCGsMeYwBUFYNUY\nY6Iosr8WRSErZT0XFYB1s8eYwBUFYGLu2UgXb5CmaVEUcRzLrxIUhDEmy7JgVQMwgNAxgQmXgPF6\n9qdvba78yF/827kbP3TdvwxcneCYcAlYbJCYwIRLwBopisK9Ajk2JAdAz9rEBMYoACvO7YAsy5KR\njMCaWzYmMEYBWH1JksidUQxmBKCWjAlcUQBWkDGmqir7a5qmVVVVVeUOYgKwPvYSE0gUAACAF4kC\nAADwIlEAAABeJAoAAMCLCZcAjAUTLgEjxIRLAMaC5AAYIboeAACAF4kCAADwIlEAAABeJAoAAMCL\nRAEAAHj1lygYY3hsHQCLmABMQk+JQlEUZVn2UxaA8SMmAFPRU6IQx3E/BQGYBGICMBV9TLiktU6S\nRClVe5ylOzOj662//1edlLvvwE872c9i//upg8HL+Od/GLwIpX7jvadDF/Hc/3pf6CL0CxeHLkIp\n9a5LvttDKUqpZ356ST8F9cwXE9yZGV1dTcSUbP9uJ/tZ7Jf/yXdCF3HHo7eFLkIpFan/E7qIUz+6\nMnQRv/qz/xu6CKXUwQuD/6efVUoNFBOCJwppmsq/suDqKiEAMCELYgIzMwIjFDxRyLJMKaW1ll+1\n1lVVhS4UwGgRE4BpCZ4o2BAgw5trVxoBrBtiAjAtvd4e2VtZAMaPmABMQn9Pj2z2RwJYZ8QEYBKY\nmREAAHiRKAAAAC8SBQAA4NXfGIWmlz5/hV1mTgUA7oRLzKkAjMSQiQLJAW0UVD8AAAy5SURBVAAX\nyQEwQnQ9AAAALxIFAADgRaIAAAC8SBQAAIAXiQIAAPAiUQAAAF4kCgAAwIsJl4Dxevn1twxdhV4x\n4RKw2CAxgQmXAIwFyQEwQnQ9AAAALxIFAADgRaIAAAC8SBQAAIAXiQIAAPAiUQAAAF4kCgAAwIsJ\nlwCMBRMuASPEhEsAxoLkABghuh4AAIAXiQIAAPAiUQAAAF4kCgAAwItEAQAAeJEoAAAALxIFAADg\nRaIAAAC8mJkRGK+XXz8wdBV6xcyMwGKDxARmZgQwFiQHwAjR9QAAALxIFAAAgBeJAgAA8CJRAAAA\nXn0kCsYYrbXW2hjTQ3EARo6YAExI8EQhTdOyLKuqyvO8LMuiKEKXCGDMiAnAtPRxRSFJEqWUnDoQ\nFAAQE4AJ0VVV9VBMmqZZlimlbHFaa9/GF9/7ZCeFHrj8bCf7Wew/XvjvQxfx6C/8vdBFKKWerYLP\n43G5fiV0Ef34o7/5rdBF/OWHbqqq6uKvnG7/kh9+fNZPc+7EUjGhq/kV/uFbvtvJfhY7+6f/NHQR\nPz38XOgilFJ/8I7/ELqIlQk7qx0TeppwSU4dsiwrisL2SnaVEACYnLkxgQmXgBHqY4yCBII0TaMo\nStM0dIkAxoyYAExLH2MU4jiWhbIsGeQMgJgATEgfVxSUUnIrlP0VwNoiJgA9045dtLg+rijIfVBV\nVU1opBUwXXsMCj0gJgA9sy1uFzGh18GMAPqR5/nIG93IqwesDHsHsjtweClDPmYaQOf2HhQATMsP\nPz5b8FeJCXZg0C4u45EoABMTOigAmBbffcUSK8wOpZTMm77sLGdDJgqv3naVXWZOBaDp3P/75ebK\nC778xNyNX//U1aqLoDAgNwdiTgWgaW5MWMy9shhF0S4KHTJRIDkAOrf3oDAgkgOgczILqlxcLMtS\nJlBfCo+ZBlZKmqZ2LmRmKQDg3pC8uynOSBSAlbL3oABgxVQ7dtcRyWBGYNUwgBFAh7iiAAAAvEgU\nAACAF4kCAADwIlEAAABeTLgEYCyYcAkYISZcAjAWJAfACNH1AAAAvEgUAACAF4kCAADwIlEAAABe\nJAoAAMCLRAEAAHiRKAAAAC8SBQAA4MXMjMB4/eIrS7TQ18PVoy/MzAgsNkhMYGZGAGNBcgCMEF0P\nAADAi0QBAAB4kSgAAAAvEgUAAOBFogAAALxIFAAAgBeJAgAA8GLCJQBjwYRLwAgx4RKAsSA5AEaI\nrgcAAOBFogAAALxIFAAAgBeJAgAA8OojUUjTVGuttTbG9FAcgJEjJgATEjxRKIoiy7I8z/M8L8sy\nTdPQJQIYM2ICMC3Bb48siiKKIjlviKKoKIrQJQIYM2ICMC26qqp+SiqKIo7jPM8lQGitfVu+9ff/\nqp8qdeKi2TOhi/jBi+8MXYRS6m2XPBe6iKff/gehi7jsT/9d6CL68dLnr6iq6u9m/7P9S15Ir+yt\nOXeifUy4NP1mJyWeu/hcJ/tZ7MDlZ0MX8cqzl4Uuoh8XPPqT0EW8+uHQJSil1MV/FryI5x+6eqiY\n0NOES8aYsiyTJHG7JKeVEADo0NyY0FVCAKBDfSQKWusoiqZ1rgMgHGICMCHBEwUZqZSmqe2JZJwz\nsM6ICcC09DGYUSkVx7H8ytglYM0RE4Bp6SlRAABBTACmhZkZAQCAF4kCAADwIlEAAABePc2jMNdL\nn7/CLjOnAoAX0ivtMnMqACMxZKJAcgDARXIAjBBdDwAAwItEAQAAeJEoAAAALxIFAADgRaIAAAC8\nSBQAAIAXiQIAAPAiUQAAAF7MzAiM189e2T90FXrFzIzAYoPEBGZmBDAWJAfACNH1AAAAvEgUAACA\nF4kCAADwIlEAAABeJAoAAMCLRAEAAHiRKAAAAC8mXAIwFky4BIwQEy4BGAuSA2CE6HoAAGCVpWmq\ntdZap2m6i5cPeUUBAACElmVZnudKqTiOjTHGmKVezhUFAABWllxFsPlBURTL7oErCsCqSdM0yzKl\nVJIku7vSCGBC3DsDmoqiiKJIlqMoIlEAsNfLjACmxXdnwOIEoj26HoCVsvfLjABWiTGmLMu97IEr\nCsDEhL7MCGCVGGOkL1IpVZalXG5cChMuAeNVvbq/ufItn3pm7sYvf/k9gasTHBMuAYvNjQmLGWOi\nKNJaK6WiKNpFXyQTLgErxT17mBySAyCEPV5ZZIwCsFLc04WyLLnrAcAeMUYBWCl7v8wIAC4SBWDV\nMIARQIfoegAAAF69JgpFUcgVUQBQxARgCvrretj7nA8AVgkxAZiE/q4oyBir3ooDMHLEBGASdFVV\nvRVWFEUcx1LiguuNvvlklvWzK1/rZD+L/fjAT0IX8UtPXRS6CKXUvgM/DV3E/v/xo9BF/PitB0IX\noZTaf9mPQxfxQnplVVVv/d1vt3/Jy19+T5/NuRMtY8LF9z7ZSXEXPBq8tSql3nzTc6GLeOXZy0IX\noZR606tvCl3EpY/8ZegivndDN887WKyH92rAmDDkXQ9dJQQAVkNXCQGADnHXAwAA8CJRAAAAXiQK\nAADAq9dEwRgzucFWAMIhJgDjxxUFAADgRaIAAAC8SBQAAIAXiQIAAPAacsKll7/8HrvM5EtA0y++\n9MrQVejVq7ddZZeZfAloGiQmMDMjgLEgOQBGiK4HAADgRaIAAAC8SBQAAIAXiQIAAPAiUQAAAF4k\nCgAAwItEAQAAeDHhEoCxYMIlYISYcAnAWJAcACNE1wMAAPAiUQAAAF4kCgAAwItEAQAAeJEoAAAA\nLxIFAADgRaIAAAC8mHAJGK+3/ODb7Td+Plw9+sKES8Big8QEJlwCMBYkB8AI0fUAAAC8SBQAAIAX\niQIAAPAiUQAAAF4kCgAAwGuVEwX3VqtwXv/U1aGLeOnzV4QuQin1Qnpl6CKefyj4e+XecxtOD+8V\nQujhE6iUOnvD9aGL6Ce49fA5/9bpj4UuYmXeqwGtcqIAAAD2iAmXAIwFEy4BI8SESwDGguQAGCG6\nHgAAgBeJAgAA8BpXotAcsj53EHv7lU1zR8A2V7bcbK6590G0XNn+HormrRBzb45ov7Jp7jjelivb\njwFuDkSfOzS9/cqmlh+YvXyu+nmv1tBe2mbLBtvyo7WXT+Dc+yBarmx/D0UP71U/n/PmrRBzb45o\nv7Kphy+CVYoJ40oUAADAqJAoAAAArz4ShTRNtdZa6zRNeygOwMgRE4AJ6eP2yCzL8jxXSsVxbIwx\nxvRQKIDRIiYAExL8ioKcMdhYUBRF6BIBjBkxAZgWXVVV0ALcWOAua62DlgtM3bJtU+vgzbkTxARg\nd4aKCYPNzDiJiAZMyNTb1NTrD4xNV20qeNeDMaYsy9ClAJgKYgIwLX0kCna5LEsGOQNrjpgATEsf\nnZr2BCKKIgYuASAmABMyjdFPAABgEMzMCAAAvAZIFHqblK0oiqA3XNkDCTddjDEmdBFuWeFK0Y5A\n/+/y393Pf4cVopQePldjQ0xoj5jQHjGhM1XvlFJ5nsu8bHmeByoliqKgB2jrLwtJknReRJIkUv/Q\n75UtIoqiQPsPXf/qjZ+rEP8dzeJClFL7XIV+00aCmNASMWEXRRAT9q7veRTspGzya1EUgVIk2W24\nu7CKooiiSEoJNyBL4oKdlCZcOhnHcaA9K2fqvXCH4H6uqvDDbuSIwp3+9tBAxoOYsBRiQkvEhC71\nnJhEUWRTVHc5BMm/wu3fLSVclidxIeiBKKWSJEmSJNB/hz2EcAdiTxZVyHMgK+j/+IDNcxDEhGUR\nE9ogJnSIwYx7YoyJ4zhJkqB9YNKoAp2gSAoctG/YGGObkHrjbfTdklJC35qfpqk9ceyc/C9LjFY8\nB2GCiAltEBPaG0VM6DkxsX1s1fTPHlTgRDVJEtuWwr1XPX8kAh2Ie+oT+nOlQvZ39nl6PRLEhPaI\nCe0REzrU9xWFlZmUzSbdxY4QpdhuwrIsA6WrzY9j50XIkF1ZDnQg7qzA4d4rK2hPpHsggUoZFWLC\nUogJLRETutR3ZuJ0HYXOjIKePbgdYOGOpc//qXD9kZVzIOGKcP9HAhVRvfH0N5Bhm+cgiAntERPa\nIyZ0hZkZx24dxr13aGXerpU5EHSOz8ZSVubtGvBASBQAAIAXdz0AAAAvEgUAAOBFogAAALxIFAAA\ngBeJAgAA8CJRAAAAXiQKAADAi0QBAAB4kSgAAAAvEgUAAOBFogAAALxIFAAAgBeJAgAA8CJRAAAA\nXiQKAADAi0QBAAB4kSgAAAAvEgUAAOBFogAAALxIFAAAgBeJAgAA8CJRAAAAXiQKAADAi0QBAAB4\nkSgAAAAvEgUAAOBFogAAALxIFAAAgBeJAgAA8CJRAAAAXiQKAADAi0QBAAB4kSgAAAAvEgUAAOD1\n/wG9GUT4YCjcHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// book histogram \n",
    "auto hS = new TH2F(\"hs\",\"Signal image (first event)\",8,0,8,8,0,8); \n",
    "auto hB = new TH2F(\"hb\",\"Background image (first event)\",8,0,8,8,0,8);\n",
    "\n",
    "auto x0S = firstEventS.Reshape( { 8,8} );\n",
    "auto x0B = firstEventB.Reshape( { 8,8} );\n",
    "for (int i = 0; i < 8; ++i) { \n",
    "      for (int j = 0; j < 8; ++j) {\n",
    "         std::vector<size_t> index(2);\n",
    "         index[0] = i;\n",
    "         index[1] = j; \n",
    "         hS->Fill(i+0.2, j+0.2, x0S( index ) );\n",
    "         hB->Fill(i+0.2, j+0.2, x0B( index ) );\n",
    "      }\n",
    "}\n",
    "auto c = new TCanvas();\n",
    "c->Divide(2,1);\n",
    "c->cd(1);\n",
    "hS->Draw(\"COLZ\");\n",
    "c->cd(2);\n",
    "hB->Draw(\"COLZ\");\n",
    "c->Draw();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAHYCAIAAAApvgy/AAAABmJLR0QAAAAAAAD5Q7t/AAAgAElE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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//make a plot an average image\n",
    "auto hSa = new TH2F(\"hsa\",\"Signal image (average)\",8,0,8,8,0,8); \n",
    "auto hBa = new TH2F(\"hba\",\"Background image (average)\",8,0,8,8,0,8);\n",
    "int nevtS = shapeS[0];\n",
    "int nevtB = shapeB[0];\n",
    "int nevt = std::min(nevtS, nevtB);\n",
    "   for (int evt = 0; evt < nevt; ++evt) { \n",
    "      for (int i = 0; i < 8; ++i) { \n",
    "         for (int j = 0; j < 8; ++j) {\n",
    "            float * xS = signalTensor.GetData(); \n",
    "            float * xB = backgroundTensor.GetData();\n",
    "            size_t index = evt*64 + i *8 + j;\n",
    "            hSa->Fill(i+0.2, j+0.2, xS[index]/nevt );\n",
    "            hBa->Fill(i+0.2, j+0.2, xB[index]/nevt );\n",
    "         }\n",
    "      }\n",
    "   }\n",
    "\n",
    "c = new TCanvas();\n",
    "c->Divide(2,1);\n",
    "c->cd(1); \n",
    "hSa->Draw(\"COLZ\"); \n",
    "c->cd(2); \n",
    "hBa->Draw(\"COLZ\");\n",
    "c->Draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Booking Methods\n",
    "\n",
    "Here we book the TMVA methods. We book a Likelihood based on KDE, a Fischer discriminant and a BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mBDT\u001b[0m\n",
      "                         : \n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 5000\n",
      "                         : Signal     -- testing events             : 5000\n",
      "                         : Signal     -- training and testing events: 10000\n",
      "                         : Background -- training events            : 5000\n",
      "                         : Background -- testing events             : 5000\n",
      "                         : Background -- training and testing events: 10000\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "\n",
    "//Boosted Decision Trees\n",
    "factory.BookMethod(loader,TMVA::Types::kBDT, \"BDT\",\n",
    "                   \"!V:NTrees=800:MinNodeSize=2.5%:MaxDepth=2:BoostType=AdaBoost:AdaBoostBeta=0.5:UseBaggedBoost:BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20\" );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Booking Deep Neural Network\n",
    "\n",
    "Here we book the new DNN of TMVA. If using master version you can use the new DL method\n",
    "See the example TMVA_Higgs_Classification for a detailed description of the options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bool useDNN = true; \n",
    "bool useCNN = true; \n",
    "bool useKeras = false; // unfortunatly PyKeras does not work from C++ notebooks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_DENSE\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|1|64:BatchLayout=1|128|64:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|1|64:BatchLayout=1|128|64:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|1|64\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"1|128|64\" [The Layout of the batch]\n",
      "                         :     Layout: \"DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "                         : Will use now the CPU architecture !\n"
     ]
    }
   ],
   "source": [
    "if (useDNN) { \n",
    "    \n",
    "     TString inputLayoutString = \"InputLayout=1|1|64\"; \n",
    "     TString batchLayoutString= \"BatchLayout=1|128|64\";\n",
    "     TString layoutString (\"Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\");\n",
    "//                                                                                                                                                                                       \n",
    "      // Training strategies \n",
    "      // one can catenate several training strategies \n",
    "      TString training1(\"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"\n",
    "                        \"ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,\"\n",
    "                        \"MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,\"\n",
    "                        \"Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.\");\n",
    "  \n",
    "      TString trainingStrategyString (\"TrainingStrategy=\");\n",
    "      trainingStrategyString += training1; // + \"|\" + training2 + \"|\" + training3;\n",
    "\n",
    "      // General Options.                                                                                                                                                                \n",
    "      TString dnnOptions (\"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"\n",
    "                          \"WeightInitialization=XAVIERUNIFORM\");\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (inputLayoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (batchLayoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (layoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (trainingStrategyString);\n",
    "\n",
    "      dnnOptions += \":Architecture=CPU\";\n",
    "      factory.BookMethod(loader, TMVA::Types::kDL, \"DL_DENSE\", dnnOptions);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Convolutional Neural Network in TMVA\n",
    "\n",
    "   For building a CNN one needs to define \n",
    "\n",
    "   -  Input Layout :  number of channels (in this case = 1)  | image height | image width\n",
    "   -  Batch Layout :  batch size | number of channels | image size = (height*width)\n",
    "\n",
    "   Then one add Convolutional layers and MaxPool layers. \n",
    "\n",
    "   -  For Convolutional layer the option string has to be: \n",
    "      - CONV | number of units | filter height | filter width | stride height | stride width | padding height | paddig width | activation function \n",
    "\n",
    "      - note in this case we are using a filer 3x3 and padding=1 and stride=1 so we get the output dimension of the conv layer equal to the input\n",
    "\n",
    "    - For the MaxPool layer: \n",
    "       - MAXPOOL  | pool height | pool width | stride height | stride width\n",
    "       - note in this case we use a stride=2 (e.g. equal to the pool size). This is the default used in Keras\n",
    "\n",
    "   The RESHAPE layer is needed to flatten the output before the Dense layer\n",
    "\n",
    "\n",
    "   Note that to run the CNN is required to have CPU  or GPU support \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_CNN\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|8|8:BatchLayout=32|1|64:Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|2|2,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0:Architecture=GPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|8|8:BatchLayout=32|1|64:Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|2|2,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0:Architecture=GPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|8|8\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"32|1|64\" [The Layout of the batch]\n",
      "                         :     Layout: \"CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|2|2,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"GPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "\u001b[31m<ERROR>                         : CUDA backend not enabled. Please make sure you have CUDA installed and it was successfully detected by CMAKE by using -Dcuda=On \u001b[0m\n",
      "                         : Will use now the CPU architecture !\n"
     ]
    }
   ],
   "source": [
    "if (useCNN) { \n",
    "    TString inputLayoutString(\"InputLayout=1|8|8\");\n",
    "                                                                                                \n",
    "// Batch Layout                                                                                                                                     \n",
    "    TString batchLayoutString(\"BatchLayout=32|1|64\");\n",
    "                                                   \n",
    "\n",
    "TString layoutString(\"Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|2|2,\"\n",
    "                     \"RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR\");\n",
    "                                                                                                                                              \n",
    "\n",
    "\n",
    "   // Training strategies.                                                                                                                          \n",
    "   TString training0(\"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"\n",
    "                     \"ConvergenceSteps=10,BatchSize=32,TestRepetitions=1,\"\n",
    "                     \"MaxEpochs=30,WeightDecay=1e-4,Regularization=None,\"\n",
    "                     \"Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0\");\n",
    " \n",
    "   TString trainingStrategyString (\"TrainingStrategy=\");\n",
    "   trainingStrategyString += training0; // + \"|\" + training1 + \"|\" + training2;   }\n",
    "    \n",
    "// General Options.                                                                                                                              \n",
    "   TString cnnOptions (\"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"\n",
    "                       \"WeightInitialization=XAVIERUNIFORM\");\n",
    "\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(inputLayoutString);\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(batchLayoutString);\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(layoutString);\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(trainingStrategyString);\n",
    "   cnnOptions.Append(\":Architecture=GPU\");\n",
    "\n",
    "   //// New DL (CNN)                                                                                                                                \n",
    "\n",
    "\n",
    "  factory.BookMethod(loader, TMVA::Types::kDL, \"DL_CNN\", cnnOptions);\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Convolutional Neural Network in Keras using a generated model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (useKeras) { \n",
    "   factory.BookMethod(loader, TMVA::Types::kPyKeras, \n",
    "                       \"PyKeras\",\"H:!V:VarTransform=None:FilenameModel=model_cnn.h5:\"\n",
    "                       \"FilenameTrainedModel=trained_model_cnn.h5:NumEpochs=20:BatchSize=128\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "Factory                  : [dataset] : Create Transformation \"I\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var0' <---> Output : variable 'var0'\n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "                         : Input : variable 'var5' <---> Output : variable 'var5'\n",
      "                         : Input : variable 'var6' <---> Output : variable 'var6'\n",
      "                         : Input : variable 'var7' <---> Output : variable 'var7'\n",
      "                         : Input : variable 'var8' <---> Output : variable 'var8'\n",
      "                         : Input : variable 'var9' <---> Output : variable 'var9'\n",
      "                         : Input : variable 'var10' <---> Output : variable 'var10'\n",
      "                         : Input : variable 'var11' <---> Output : variable 'var11'\n",
      "                         : Input : variable 'var12' <---> Output : variable 'var12'\n",
      "                         : Input : variable 'var13' <---> Output : variable 'var13'\n",
      "                         : Input : variable 'var14' <---> Output : variable 'var14'\n",
      "                         : Input : variable 'var15' <---> Output : variable 'var15'\n",
      "                         : Input : variable 'var16' <---> Output : variable 'var16'\n",
      "                         : Input : variable 'var17' <---> Output : variable 'var17'\n",
      "                         : Input : variable 'var18' <---> Output : variable 'var18'\n",
      "                         : Input : variable 'var19' <---> Output : variable 'var19'\n",
      "                         : Input : variable 'var20' <---> Output : variable 'var20'\n",
      "                         : Input : variable 'var21' <---> Output : variable 'var21'\n",
      "                         : Input : variable 'var22' <---> Output : variable 'var22'\n",
      "                         : Input : variable 'var23' <---> Output : variable 'var23'\n",
      "                         : Input : variable 'var24' <---> Output : variable 'var24'\n",
      "                         : Input : variable 'var25' <---> Output : variable 'var25'\n",
      "                         : Input : variable 'var26' <---> Output : variable 'var26'\n",
      "                         : Input : variable 'var27' <---> Output : variable 'var27'\n",
      "                         : Input : variable 'var28' <---> Output : variable 'var28'\n",
      "                         : Input : variable 'var29' <---> Output : variable 'var29'\n",
      "                         : Input : variable 'var30' <---> Output : variable 'var30'\n",
      "                         : Input : variable 'var31' <---> Output : variable 'var31'\n",
      "                         : Input : variable 'var32' <---> Output : variable 'var32'\n",
      "                         : Input : variable 'var33' <---> Output : variable 'var33'\n",
      "                         : Input : variable 'var34' <---> Output : variable 'var34'\n",
      "                         : Input : variable 'var35' <---> Output : variable 'var35'\n",
      "                         : Input : variable 'var36' <---> Output : variable 'var36'\n",
      "                         : Input : variable 'var37' <---> Output : variable 'var37'\n",
      "                         : Input : variable 'var38' <---> Output : variable 'var38'\n",
      "                         : Input : variable 'var39' <---> Output : variable 'var39'\n",
      "                         : Input : variable 'var40' <---> Output : variable 'var40'\n",
      "                         : Input : variable 'var41' <---> Output : variable 'var41'\n",
      "                         : Input : variable 'var42' <---> Output : variable 'var42'\n",
      "                         : Input : variable 'var43' <---> Output : variable 'var43'\n",
      "                         : Input : variable 'var44' <---> Output : variable 'var44'\n",
      "                         : Input : variable 'var45' <---> Output : variable 'var45'\n",
      "                         : Input : variable 'var46' <---> Output : variable 'var46'\n",
      "                         : Input : variable 'var47' <---> Output : variable 'var47'\n",
      "                         : Input : variable 'var48' <---> Output : variable 'var48'\n",
      "                         : Input : variable 'var49' <---> Output : variable 'var49'\n",
      "                         : Input : variable 'var50' <---> Output : variable 'var50'\n",
      "                         : Input : variable 'var51' <---> Output : variable 'var51'\n",
      "                         : Input : variable 'var52' <---> Output : variable 'var52'\n",
      "                         : Input : variable 'var53' <---> Output : variable 'var53'\n",
      "                         : Input : variable 'var54' <---> Output : variable 'var54'\n",
      "                         : Input : variable 'var55' <---> Output : variable 'var55'\n",
      "                         : Input : variable 'var56' <---> Output : variable 'var56'\n",
      "                         : Input : variable 'var57' <---> Output : variable 'var57'\n",
      "                         : Input : variable 'var58' <---> Output : variable 'var58'\n",
      "                         : Input : variable 'var59' <---> Output : variable 'var59'\n",
      "                         : Input : variable 'var60' <---> Output : variable 'var60'\n",
      "                         : Input : variable 'var61' <---> Output : variable 'var61'\n",
      "                         : Input : variable 'var62' <---> Output : variable 'var62'\n",
      "                         : Input : variable 'var63' <---> Output : variable 'var63'\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:     2.4701     3.8623   [    -10.257     18.764 ]\n",
      "                         :     var1:     3.9681     4.4742   [    -9.3288     25.831 ]\n",
      "                         :     var2:     5.5276     4.8214   [    -9.4795     25.556 ]\n",
      "                         :     var3:     6.5247     5.0201   [    -7.6537     29.230 ]\n",
      "                         :     var4:     6.4129     5.0196   [    -10.282     27.355 ]\n",
      "                         :     var5:     5.4524     4.8577   [    -7.5877     27.156 ]\n",
      "                         :     var6:     3.9323     4.5203   [    -11.141     28.512 ]\n",
      "                         :     var7:     2.4199     3.9260   [    -9.8602     21.294 ]\n",
      "                         :     var8:     3.7393     4.3949   [    -9.6036     27.343 ]\n",
      "                         :     var9:     6.0779     5.1283   [    -9.2157     28.235 ]\n",
      "                         :    var10:     8.3410     5.4970   [    -7.7720     31.127 ]\n",
      "                         :    var11:     9.7506     5.4743   [    -6.0866     32.294 ]\n",
      "                         :    var12:     9.6127     5.5329   [    -9.2380     29.683 ]\n",
      "                         :    var13:     8.2307     5.5429   [    -7.1600     36.270 ]\n",
      "                         :    var14:     5.9661     5.0906   [    -9.2506     30.755 ]\n",
      "                         :    var15:     3.6163     4.4268   [    -9.8246     23.258 ]\n",
      "                         :    var16:     4.8768     4.7482   [    -11.709     26.243 ]\n",
      "                         :    var17:     7.9227     5.5269   [    -9.1076     30.527 ]\n",
      "                         :    var18:     10.915     5.7339   [    -6.2285     35.900 ]\n",
      "                         :    var19:     12.885     5.4738   [    -5.4607     34.438 ]\n",
      "                         :    var20:     12.837     5.4855   [    -4.9795     34.453 ]\n",
      "                         :    var21:     10.911     5.7875   [    -6.3943     38.104 ]\n",
      "                         :    var22:     7.8435     5.5336   [    -7.4259     35.488 ]\n",
      "                         :    var23:     4.7827     4.7420   [    -10.919     25.210 ]\n",
      "                         :    var24:     5.6673     4.9681   [    -9.3157     29.659 ]\n",
      "                         :    var25:     9.1214     5.6187   [    -7.8932     33.555 ]\n",
      "                         :    var26:     12.579     5.7177   [    -4.7632     38.462 ]\n",
      "                         :    var27:     14.711     5.0966   [    -2.1615     35.902 ]\n",
      "                         :    var28:     14.634     5.1859   [    -2.1573     33.831 ]\n",
      "                         :    var29:     12.373     5.6271   [    -4.6051     32.760 ]\n",
      "                         :    var30:     9.0234     5.6818   [    -10.813     32.022 ]\n",
      "                         :    var31:     5.5520     5.0224   [    -10.336     25.878 ]\n",
      "                         :    var32:     5.6652     5.0397   [    -11.560     27.428 ]\n",
      "                         :    var33:     9.2124     5.7022   [    -8.0987     32.849 ]\n",
      "                         :    var34:     12.650     5.6931   [    -8.4293     36.323 ]\n",
      "                         :    var35:     14.810     5.1596   [    -2.6615     34.607 ]\n",
      "                         :    var36:     14.725     5.1096   [    -2.8380     35.026 ]\n",
      "                         :    var37:     12.535     5.5816   [    -6.1929     33.836 ]\n",
      "                         :    var38:     8.9867     5.7043   [    -7.1232     32.626 ]\n",
      "                         :    var39:     5.5199     4.9405   [    -9.0285     29.784 ]\n",
      "                         :    var40:     5.0488     4.8433   [    -10.422     25.266 ]\n",
      "                         :    var41:     7.9399     5.6164   [    -7.8517     37.635 ]\n",
      "                         :    var42:     10.997     5.7916   [    -7.3053     36.124 ]\n",
      "                         :    var43:     12.806     5.4954   [    -6.6966     35.064 ]\n",
      "                         :    var44:     12.922     5.5352   [    -4.2441     36.017 ]\n",
      "                         :    var45:     10.977     5.7405   [    -8.1370     34.364 ]\n",
      "                         :    var46:     7.9028     5.5545   [    -10.776     32.909 ]\n",
      "                         :    var47:     4.8808     4.7925   [    -9.0932     26.816 ]\n",
      "                         :    var48:     3.7902     4.4039   [    -10.844     25.228 ]\n",
      "                         :    var49:     6.1485     5.1091   [    -8.8429     29.845 ]\n",
      "                         :    var50:     8.4125     5.4775   [    -8.2915     31.133 ]\n",
      "                         :    var51:     9.8682     5.5778   [    -6.8674     33.313 ]\n",
      "                         :    var52:     9.8212     5.5284   [    -6.0435     33.478 ]\n",
      "                         :    var53:     8.3884     5.5094   [    -9.7019     34.087 ]\n",
      "                         :    var54:     6.0209     5.1018   [    -8.5084     32.443 ]\n",
      "                         :    var55:     3.6421     4.3138   [    -10.585     26.869 ]\n",
      "                         :    var56:     2.5230     3.9446   [    -9.4698     21.372 ]\n",
      "                         :    var57:     4.0374     4.5043   [    -8.7161     26.215 ]\n",
      "                         :    var58:     5.6282     4.9041   [    -10.942     30.791 ]\n",
      "                         :    var59:     6.4932     5.0064   [    -9.0219     29.350 ]\n",
      "                         :    var60:     6.5388     5.0672   [    -8.4943     28.476 ]\n",
      "                         :    var61:     5.5954     4.8805   [    -9.6182     26.950 ]\n",
      "                         :    var62:     4.0401     4.4875   [    -11.569     26.781 ]\n",
      "                         :    var63:     2.5019     3.9016   [    -9.2495     22.465 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \u001b[32m\n",
      "                         : <PlotVariables> Will not produce scatter plots ==> \n",
      "                         : |  The number of 64 input variables and 0 target values would require 2016 two-dimensional\n",
      "                         : |  histograms, which would occupy the computer's memory. Note that this\n",
      "                         : |  suppression does not have any consequences for your analysis, other\n",
      "                         : |  than not disposing of these scatter plots. You can modify the maximum\n",
      "                         : |  number of input variables allowed to generate scatter plots in your\n",
      "                         : |  script via the command line:\n",
      "                         : |  \"(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;\"\u001b[0m\n",
      "                         : \n",
      "                         : Some more output\n",
      "                         : Ranking input variables (method unspecific)...\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : ------------------------------\n",
      "                         : Rank : Variable  : Separation\n",
      "                         : ------------------------------\n",
      "                         :    1 : var4      : 1.556e-02\n",
      "                         :    2 : var31     : 1.403e-02\n",
      "                         :    3 : var24     : 1.348e-02\n",
      "                         :    4 : var33     : 1.328e-02\n",
      "                         :    5 : var39     : 1.317e-02\n",
      "                         :    6 : var32     : 1.210e-02\n",
      "                         :    7 : var59     : 1.206e-02\n",
      "                         :    8 : var60     : 1.191e-02\n",
      "                         :    9 : var3      : 1.166e-02\n",
      "                         :   10 : var38     : 1.153e-02\n",
      "                         :   11 : var11     : 1.145e-02\n",
      "                         :   12 : var47     : 9.808e-03\n",
      "                         :   13 : var12     : 9.701e-03\n",
      "                         :   14 : var16     : 9.031e-03\n",
      "                         :   15 : var41     : 8.867e-03\n",
      "                         :   16 : var30     : 8.663e-03\n",
      "                         :   17 : var23     : 8.343e-03\n",
      "                         :   18 : var40     : 8.225e-03\n",
      "                         :   19 : var48     : 7.877e-03\n",
      "                         :   20 : var25     : 7.484e-03\n",
      "                         :   21 : var51     : 7.456e-03\n",
      "                         :   22 : var26     : 7.162e-03\n",
      "                         :   23 : var2      : 7.159e-03\n",
      "                         :   24 : var46     : 6.982e-03\n",
      "                         :   25 : var52     : 6.800e-03\n",
      "                         :   26 : var5      : 6.738e-03\n",
      "                         :   27 : var61     : 6.040e-03\n",
      "                         :   28 : var20     : 6.007e-03\n",
      "                         :   29 : var8      : 5.495e-03\n",
      "                         :   30 : var58     : 5.292e-03\n",
      "                         :   31 : var45     : 5.198e-03\n",
      "                         :   32 : var53     : 5.178e-03\n",
      "                         :   33 : var13     : 5.108e-03\n",
      "                         :   34 : var7      : 5.072e-03\n",
      "                         :   35 : var22     : 5.061e-03\n",
      "                         :   36 : var43     : 5.031e-03\n",
      "                         :   37 : var37     : 4.977e-03\n",
      "                         :   38 : var6      : 4.920e-03\n",
      "                         :   39 : var17     : 4.849e-03\n",
      "                         :   40 : var15     : 4.728e-03\n",
      "                         :   41 : var35     : 4.702e-03\n",
      "                         :   42 : var10     : 4.668e-03\n",
      "                         :   43 : var28     : 4.503e-03\n",
      "                         :   44 : var55     : 4.495e-03\n",
      "                         :   45 : var54     : 4.427e-03\n",
      "                         :   46 : var18     : 4.333e-03\n",
      "                         :   47 : var50     : 4.264e-03\n",
      "                         :   48 : var36     : 4.240e-03\n",
      "                         :   49 : var34     : 4.202e-03\n",
      "                         :   50 : var19     : 4.151e-03\n",
      "                         :   51 : var9      : 4.144e-03\n",
      "                         :   52 : var57     : 4.121e-03\n",
      "                         :   53 : var21     : 4.060e-03\n",
      "                         :   54 : var1      : 3.936e-03\n",
      "                         :   55 : var29     : 3.921e-03\n",
      "                         :   56 : var63     : 3.558e-03\n",
      "                         :   57 : var0      : 3.485e-03\n",
      "                         :   58 : var56     : 3.481e-03\n",
      "                         :   59 : var49     : 2.914e-03\n",
      "                         :   60 : var14     : 2.902e-03\n",
      "                         :   61 : var27     : 2.892e-03\n",
      "                         :   62 : var44     : 2.748e-03\n",
      "                         :   63 : var62     : 2.556e-03\n",
      "                         :   64 : var42     : 2.538e-03\n",
      "                         : ------------------------------\n",
      "Factory                  : Train method: BDT for Classification\n",
      "                         : \n",
      "BDT                      : #events: (reweighted) sig: 5000 bkg: 5000\n",
      "                         : #events: (unweighted) sig: 5000 bkg: 5000\n",
      "                         : Training 800 Decision Trees ... patience please\n",
      "                         : Elapsed time for training with 10000 events: 8.59 sec         \n",
      "BDT                      : [dataset] : Evaluation of BDT on training sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.389 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.class.C\u001b[0m\n",
      "                         : CNN_ClassificationOutput.root:/dataset/Method_BDT/BDT\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DL_DENSE for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU using (for ROOT-IMT) nthreads = 1\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 5  Input = ( 1, 1, 64 )  Batch size = 128  Loss function = C\n",
      "\tLayer 0\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 1\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 2\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 3\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 4\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,   128 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 8000 events for training and 2000 for testing\n",
      "                         : Training phase 1 of 1:  Optimizer ADAM Learning rate = 0.001 regularization 2 minimum error = 0.742147\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |      0.61986    0.647771    0.051694    0.021072      259160           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.589916    0.629443    0.053346    0.021111      246192           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |      0.56905    0.623715    0.056025    0.023204      241796           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |      0.55584    0.620662    0.052582    0.021075      251881           0\n",
      "                         :          5 Minimum Test error found - save the configuration \n",
      "                         :          5 |     0.545996    0.616876    0.051725    0.021001      258300           0\n",
      "                         :          6 |     0.540398    0.620473    0.051983    0.021041      256480           1\n",
      "                         :          7 |     0.533148    0.616887    0.054064    0.022053      247915           2\n",
      "                         :          8 |     0.527356     0.61765    0.053356    0.022402      256380           3\n",
      "                         :          9 |     0.520998     0.61888    0.053958    0.022304      250711           4\n",
      "                         :         10 |     0.516974    0.621106    0.052923    0.021675      253968           5\n",
      "                         :         11 |      0.51117     0.61894       0.057    0.022176      227889           6\n",
      "                         :         12 |     0.509111    0.623324    0.052099    0.021187      256729           7\n",
      "                         :         13 |     0.505509    0.619557    0.052135    0.021675      260538           8\n",
      "                         :         14 |     0.502628    0.620478    0.051545     0.02136      262912           9\n",
      "                         :         15 |     0.501091    0.620919    0.056408    0.023679      242476          10\n",
      "                         :         16 |     0.495931    0.624665    0.058167    0.025364      241929          11\n",
      "                         : \n",
      "                         : Elapsed time for training with 10000 events: 0.872 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 128\n",
      "                         : \n",
      "DL_DENSE                 : [dataset] : Evaluation of DL_DENSE on training sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.0256 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_DENSE.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_DENSE.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DL_CNN for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU using (for ROOT-IMT) nthreads = 1\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 6  Input = ( 1, 8, 8 )  Batch size = 32  Loss function = C\n",
      "\tLayer 0\t CONV LAYER: \t( W = 8 ,  H = 8 ,  D = 10 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 32 , 10 , 64 ) \t Activation Function = Relu\n",
      "\tLayer 1\t CONV LAYER: \t( W = 8 ,  H = 8 ,  D = 10 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 32 , 10 , 64 ) \t Activation Function = Relu\n",
      "\tLayer 2\t POOL Layer: \t( W = 4 ,  H = 4 ,  D = 10 ) \t Filter ( W = 2 ,  H = 2 ) \tOutput = ( 32 , 10 , 16 ) \n",
      "\tLayer 3\t RESHAPE Layer \t Input = ( 10 , 4 , 4 ) \tOutput = ( 1 , 32 , 160 ) \n",
      "\tLayer 4\t DENSE Layer: \t ( Input =   160 , Width =    64 ) \tOutput = (  1 ,    32 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 5\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,    32 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 8000 events for training and 2000 for testing\n",
      "                         : Training phase 1 of 1:  Optimizer ADAM Learning rate = 0.001 regularization 0 minimum error = 0.809085\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.632482    0.635441    0.676049    0.192362     16539.6           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.603301    0.608694    0.825106    0.251178       13939           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.585606    0.600775    0.802601     0.22885     13943.3           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.571362     0.59085    0.745912    0.206832     14840.1           0\n",
      "                         :          5 |     0.569004    0.592024    0.931551    0.222175     11277.5           1\n",
      "                         :          6 Minimum Test error found - save the configuration \n",
      "                         :          6 |     0.559349      0.5776    0.758528    0.223347     14948.2           0\n",
      "                         :          7 Minimum Test error found - save the configuration \n",
      "                         :          7 |     0.547809    0.573326     0.81054    0.237738     13966.4           0\n",
      "                         :          8 Minimum Test error found - save the configuration \n",
      "                         :          8 |     0.540522    0.567859    0.797163     0.22305     13934.5           0\n",
      "                         :          9 Minimum Test error found - save the configuration \n",
      "                         :          9 |     0.535161    0.566986    0.806371    0.218398     13606.1           0\n",
      "                         :         10 |     0.530318    0.567225    0.755659     0.20149       14436           1\n",
      "                         :         11 Minimum Test error found - save the configuration \n",
      "                         :         11 |     0.526637     0.56367    0.733146    0.197819     14944.1           0\n",
      "                         :         12 Minimum Test error found - save the configuration \n",
      "                         :         12 |     0.523852    0.562477     0.72118    0.197041     15263.1           0\n",
      "                         :         13 Minimum Test error found - save the configuration \n",
      "                         :         13 |     0.520122    0.562165    0.700131    0.193888     15802.7           0\n"
     ]
    }
   ],
   "source": [
    "factory.TrainAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Evaluate Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "factory.TestAllMethods();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "factory.EvaluateAllMethods();    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve\n",
    "We enable JavaScript visualisation for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//%jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1 = factory.GetROCCurve(loader);\n",
    "c1->Draw();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// close outputfile to save output file\n",
    "outputFile->Close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
